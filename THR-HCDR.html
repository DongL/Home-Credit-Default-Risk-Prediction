<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>THR-HCDR</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Home-Credit-Default-Risk-(HCDR)">Home Credit Default Risk (HCDR)<a class="anchor-link" href="#Home-Credit-Default-Risk-(HCDR)">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The course project is based on the <a href="https://www.kaggle.com/c/home-credit-default-risk/">Home Credit Default Risk (HCDR)  Kaggle Competition</a>. The goal of this project is to predict whether or not a client will repay a loan. In order to make sure that people who struggle to get loans due to insufficient or non-existent credit histories have a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities.</p>
<h2 id="Some-of-the-challenges">Some of the challenges<a class="anchor-link" href="#Some-of-the-challenges">&#182;</a></h2><ol>
<li>Dataset size <ul>
<li>(688 meg uncompressed) with millions of rows of data</li>
<li>2.71 Gig of data uncompressed</li>
</ul>
</li>
<li>Dealing with missing data</li>
<li>Imbalanced datasets</li>
<li>Summarizing transaction data</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Kaggle-API-setup">Kaggle API setup<a class="anchor-link" href="#Kaggle-API-setup">&#182;</a></h1><p>Kaggle is a Data Science Competition Platform which shares a lot of datasets. In the past, it was troublesome to submit your result as your have to go through the console in your browser and drag your files there. Now you can interact with Kaggle via the command line. E.g.,</p>
<div class="highlight"><pre><span></span>! kaggle competitions files home-credit-default-risk
</pre></div>
<p>It is quite easy to setup, it takes me less than 15 minutes to finish a submission.</p>
<ol>
<li>Install library</li>
<li>Create a API Token (edit your profile on <a href="https://www.kaggle.com/">Kaggle.com</a>); this produces <code>kaggle.json</code> file</li>
<li>Put your JSON <code>kaggle.json</code> in the right place</li>
<li>Access competition files; make submissions via the command (see examples below)</li>
<li>Submit result</li>
</ol>
<p>For more detailed information on setting the Kaggle API see <a href="https://medium.com/@nokkk/make-your-kaggle-submissions-with-kaggle-official-api-f49093c04f8a">here</a> and <a href="https://github.com/Kaggle/kaggle-api">here</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># !pip install kaggle</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># from google.colab import files</span>
<span class="c1"># files.upload()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># !mkdir -p ~/.kaggle</span>
<span class="c1"># !cp kaggle.json ~/.kaggle/</span>
<span class="c1"># !chmod 600 ~/.kaggle/kaggle.json</span>
<span class="c1"># !ls ~/.kaggle</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># !ls -l ~/.kaggle</span>
<span class="c1"># !cat ~/.kaggle/kaggle.json</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># ! kaggle competitions files home-credit-default-risk</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Dataset-and-how-to-download">Dataset and how to download<a class="anchor-link" href="#Dataset-and-how-to-download">&#182;</a></h1><h2 id="Back-ground-Home-Credit-Group">Back ground Home Credit Group<a class="anchor-link" href="#Back-ground-Home-Credit-Group">&#182;</a></h2><p>Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders.</p>
<h3 id="Home-Credit-Group">Home Credit Group<a class="anchor-link" href="#Home-Credit-Group">&#182;</a></h3><p>Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities.</p>
<p>While Home Credit is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful.</p>
<h2 id="Background-on-the-dataset">Background on the dataset<a class="anchor-link" href="#Background-on-the-dataset">&#182;</a></h2><p>Home Credit is a non-banking financial institution, founded in 1997 in the Czech Republic.</p>
<p>The company operates in 14 countries (including United States, Russia, Kazahstan, Belarus, China, India) and focuses on lending primarily to people with little or no credit history which will either not obtain loans or became victims of untrustworthly lenders.</p>
<p>Home Credit group has over 29 million customers, total assests of 21 billions Euro, over 160 millions loans, with the majority in Asia and and almost half of them in China (as of 19-05-2018).</p>
<p>While Home Credit is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful.</p>
<h2 id="Data-files-overview">Data files overview<a class="anchor-link" href="#Data-files-overview">&#182;</a></h2><p>There are 7 different sources of data:</p>
<ul>
<li><strong>application_train/application_test:</strong> the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature SK_ID_CURR. The training application data comes with the TARGET indicating <strong>0: the loan was repaid</strong> or <strong>1: the loan was not repaid</strong>. The target variable defines if the client had payment difficulties meaning he/she had late payment more than X days on at least one of the first Y installments of the loan. Such case is marked as 1 while other all other cases as 0.</li>
<li><strong>bureau:</strong> data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits.</li>
<li><strong>bureau_balance:</strong> monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length.</li>
<li><strong>previous_application:</strong> previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature SK_ID_PREV.</li>
<li><strong>POS_CASH_BALANCE:</strong> monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows.</li>
<li>credit_card_balance: monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows.</li>
<li><strong>installments_payment:</strong> payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="home_credit.png" alt="alt" title="Home credit"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Downloading-the-files-via-Kaggle-API">Downloading the files via Kaggle API<a class="anchor-link" href="#Downloading-the-files-via-Kaggle-API">&#182;</a></h2><p>Create a base directory:</p>
<div class="highlight"><pre><span></span><span class="nv">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;../../../Data/home-credit-default-risk&quot;</span>   <span class="c1">#same level as course repo in the data directory</span>
</pre></div>
<p>Please download the project data files and data dictionary and unzip them using either of the following approaches:</p>
<ol>
<li>Click on the <code>Download</code> button on the following <a href="https://www.kaggle.com/c/home-credit-default-risk/data">Data Webpage</a> and unzip the  zip file to the <code>BASE_DIR</code></li>
<li>If you plan to use the Kaggle API, please use the following steps.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># DATA_DIR = &quot;../../../Data/home-credit-default-risk&quot;   #same level as course repo in the data directory</span>
<span class="c1"># #DATA_DIR = os.path.join(&#39;./ddddd/&#39;)</span>
<span class="c1"># !mkdir $BASE_DIR</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># !ls $DATA_DIR</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># ! kaggle competitions download home-credit-default-risk -p $DATA_DIR</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Imports">Imports<a class="anchor-link" href="#Imports">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="k">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">FeatureUnion</span>
<span class="kn">from</span> <span class="nn">pandas.plotting</span> <span class="k">import</span> <span class="n">scatter_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="k">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># from google.colab import drive</span>
<span class="c1"># drive.mount(&#39;/content/gdrive&#39;)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># os.chdir(&#39;/content/gdrive/My Drive/Final project&#39;)</span>
<span class="c1"># DATA_DIR = &quot;/content/gdrive/My Drive/Final project/datasets&quot; </span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#this cell is required if using Kaggle API to download the data</span>

<span class="c1"># unzippingReq = False</span>
<span class="c1"># if unzippingReq: #please modify this code </span>
<span class="c1">#     zip_ref = zipfile.ZipFile(&#39;application_train.csv.zip&#39;, &#39;r&#39;)</span>
<span class="c1">#     zip_ref.extractall(&#39;datasets&#39;)</span>
<span class="c1">#     zip_ref.close()</span>
<span class="c1">#     zip_ref = zipfile.ZipFile(&#39;application_test.csv.zip&#39;, &#39;r&#39;)</span>
<span class="c1">#     zip_ref.extractall(&#39;datasets&#39;)</span>
<span class="c1">#     zip_ref.close()</span>
<span class="c1">#     zip_ref = zipfile.ZipFile(&#39;bureau_balance.csv.zip&#39;, &#39;r&#39;)</span>
<span class="c1">#     zip_ref.extractall(&#39;datasets&#39;)</span>
<span class="c1">#     zip_ref.close()</span>
<span class="c1">#     zip_ref = zipfile.ZipFile(&#39;bureau.csv.zip&#39;, &#39;r&#39;)</span>
<span class="c1">#     zip_ref.extractall(&#39;datasets&#39;)</span>
<span class="c1">#     zip_ref.close()</span>
<span class="c1">#     zip_ref = zipfile.ZipFile(&#39;credit_card_balance.csv.zip&#39;, &#39;r&#39;)</span>
<span class="c1">#     zip_ref.extractall(&#39;datasets&#39;)</span>
<span class="c1">#     zip_ref.close()</span>
<span class="c1">#     zip_ref = zipfile.ZipFile(&#39;installments_payments.csv.zip&#39;, &#39;r&#39;)</span>
<span class="c1">#     zip_ref.extractall(&#39;datasets&#39;)</span>
<span class="c1">#     zip_ref.close()</span>
<span class="c1">#     zip_ref = zipfile.ZipFile(&#39;POS_CASH_balance.csv.zip&#39;, &#39;r&#39;)</span>
<span class="c1">#     zip_ref.extractall(&#39;datasets&#39;)</span>
<span class="c1">#     zip_ref.close()</span>
<span class="c1">#     zip_ref = zipfile.ZipFile(&#39;previous_application.csv.zip&#39;, &#39;r&#39;)</span>
<span class="c1">#     zip_ref.extractall(&#39;datasets&#39;)</span>
<span class="c1">#     zip_ref.close()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-files-overview">Data files overview<a class="anchor-link" href="#Data-files-overview">&#182;</a></h2><h3 id="Data-Dictionary">Data Dictionary<a class="anchor-link" href="#Data-Dictionary">&#182;</a></h3><p>As part of the data download comes a  Data Dictionary. It named <code>HomeCredit_columns_description.csv</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="attachment:image.png" alt="image.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Application-train">Application train<a class="anchor-link" href="#Application-train">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="k">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">FeatureUnion</span>
<span class="kn">from</span> <span class="nn">pandas.plotting</span> <span class="k">import</span> <span class="n">scatter_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;workingdir.config&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">WORKING_DIR</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">WORKING_DIR</span><span class="p">,</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">in_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{name}</span><span class="s1">.csv&#39;</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">in_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;</span><span class="si">{name}</span><span class="s2">: shape is </span><span class="si">{df.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
    <span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="n">datasets</span><span class="o">=</span><span class="p">{}</span>  <span class="c1"># lets store the datasets in a dictionary so we can keep track of them easily</span>
<span class="n">ds_name</span> <span class="o">=</span> <span class="s1">&#39;application_train&#39;</span>
<span class="n">datasets</span><span class="p">[</span><span class="n">ds_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">ds_name</span><span class="p">)</span>

<span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>application_train: shape is (307511, 122)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 307511 entries, 0 to 307510
Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR
dtypes: float64(65), int64(41), object(16)
memory usage: 286.2+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100002</td>
      <td>1</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100003</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100004</td>
      <td>0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100006</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100007</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 122 columns</p>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt output_prompt">Out[5]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(307511, 122)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Application-test">Application test<a class="anchor-link" href="#Application-test">&#182;</a></h3><ul>
<li><strong>application_train/application_test:</strong> the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature SK_ID_CURR. The training application data comes with the TARGET indicating <strong>0: the loan was repaid</strong> or <strong>1: the loan was not repaid</strong>. The target variable defines if the client had payment difficulties meaning he/she had late payment more than X days on at least one of the first Y installments of the loan. Such case is marked as 1 while other all other cases as 0.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds_name</span> <span class="o">=</span> <span class="s1">&#39;application_test&#39;</span>
<span class="n">datasets</span><span class="p">[</span><span class="n">ds_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">ds_name</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>application_test: shape is (48744, 121)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 48744 entries, 0 to 48743
Columns: 121 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR
dtypes: float64(65), int64(40), object(16)
memory usage: 45.0+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>AMT_GOODS_PRICE</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100001</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>568800.0</td>
      <td>20560.5</td>
      <td>450000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100005</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>99000.0</td>
      <td>222768.0</td>
      <td>17370.0</td>
      <td>180000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100013</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>663264.0</td>
      <td>69777.0</td>
      <td>630000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100028</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>2</td>
      <td>315000.0</td>
      <td>1575000.0</td>
      <td>49018.5</td>
      <td>1575000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100038</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>Y</td>
      <td>N</td>
      <td>1</td>
      <td>180000.0</td>
      <td>625500.0</td>
      <td>32067.0</td>
      <td>625500.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 121 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The application dataset has the most information about the client: Gender, income, family status, education ...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Other-datasets">The Other datasets<a class="anchor-link" href="#The-Other-datasets">&#182;</a></h3><ul>
<li><strong>bureau:</strong> data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits.</li>
<li><strong>bureau_balance:</strong> monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length.</li>
<li><strong>previous_application:</strong> previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature SK_ID_PREV.</li>
<li><strong>POS_CASH_BALANCE:</strong> monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows.</li>
<li>credit_card_balance: monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows.</li>
<li><strong>installments_payment:</strong> payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>
ds_names = (&quot;application_train&quot;, &quot;application_test&quot;, &quot;bureau&quot;,&quot;bureau_balance&quot;,&quot;credit_card_balance&quot;,&quot;installments_payments&quot;,
            &quot;previous_application&quot;,&quot;POS_CASH_balance&quot;)
for ds_name in ds_names:
    datasets[ds_name] = load_data(ds_name)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>application_train: shape is (307511, 122)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 307511 entries, 0 to 307510
Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR
dtypes: float64(65), int64(41), object(16)
memory usage: 286.2+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100002</td>
      <td>1</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100003</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100004</td>
      <td>0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100006</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100007</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 122 columns</p>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>application_test: shape is (48744, 121)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 48744 entries, 0 to 48743
Columns: 121 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR
dtypes: float64(65), int64(40), object(16)
memory usage: 45.0+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>AMT_GOODS_PRICE</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100001</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>568800.0</td>
      <td>20560.5</td>
      <td>450000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100005</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>99000.0</td>
      <td>222768.0</td>
      <td>17370.0</td>
      <td>180000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100013</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>663264.0</td>
      <td>69777.0</td>
      <td>630000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100028</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>2</td>
      <td>315000.0</td>
      <td>1575000.0</td>
      <td>49018.5</td>
      <td>1575000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100038</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>Y</td>
      <td>N</td>
      <td>1</td>
      <td>180000.0</td>
      <td>625500.0</td>
      <td>32067.0</td>
      <td>625500.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 121 columns</p>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>bureau: shape is (1716428, 17)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1716428 entries, 0 to 1716427
Data columns (total 17 columns):
SK_ID_CURR                int64
SK_ID_BUREAU              int64
CREDIT_ACTIVE             object
CREDIT_CURRENCY           object
DAYS_CREDIT               int64
CREDIT_DAY_OVERDUE        int64
DAYS_CREDIT_ENDDATE       float64
DAYS_ENDDATE_FACT         float64
AMT_CREDIT_MAX_OVERDUE    float64
CNT_CREDIT_PROLONG        int64
AMT_CREDIT_SUM            float64
AMT_CREDIT_SUM_DEBT       float64
AMT_CREDIT_SUM_LIMIT      float64
AMT_CREDIT_SUM_OVERDUE    float64
CREDIT_TYPE               object
DAYS_CREDIT_UPDATE        int64
AMT_ANNUITY               float64
dtypes: float64(8), int64(6), object(3)
memory usage: 222.6+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>SK_ID_BUREAU</th>
      <th>CREDIT_ACTIVE</th>
      <th>CREDIT_CURRENCY</th>
      <th>DAYS_CREDIT</th>
      <th>CREDIT_DAY_OVERDUE</th>
      <th>DAYS_CREDIT_ENDDATE</th>
      <th>DAYS_ENDDATE_FACT</th>
      <th>AMT_CREDIT_MAX_OVERDUE</th>
      <th>CNT_CREDIT_PROLONG</th>
      <th>AMT_CREDIT_SUM</th>
      <th>AMT_CREDIT_SUM_DEBT</th>
      <th>AMT_CREDIT_SUM_LIMIT</th>
      <th>AMT_CREDIT_SUM_OVERDUE</th>
      <th>CREDIT_TYPE</th>
      <th>DAYS_CREDIT_UPDATE</th>
      <th>AMT_ANNUITY</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>215354</td>
      <td>5714462</td>
      <td>Closed</td>
      <td>currency 1</td>
      <td>-497</td>
      <td>0</td>
      <td>-153.0</td>
      <td>-153.0</td>
      <td>NaN</td>
      <td>0</td>
      <td>91323.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-131</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>215354</td>
      <td>5714463</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-208</td>
      <td>0</td>
      <td>1075.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>225000.0</td>
      <td>171342.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Credit card</td>
      <td>-20</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>215354</td>
      <td>5714464</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>528.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>464323.5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-16</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>215354</td>
      <td>5714465</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>90000.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Credit card</td>
      <td>-16</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>215354</td>
      <td>5714466</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-629</td>
      <td>0</td>
      <td>1197.0</td>
      <td>NaN</td>
      <td>77674.5</td>
      <td>0</td>
      <td>2700000.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-21</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>bureau_balance: shape is (27299925, 3)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 27299925 entries, 0 to 27299924
Data columns (total 3 columns):
SK_ID_BUREAU      int64
MONTHS_BALANCE    int64
STATUS            object
dtypes: int64(2), object(1)
memory usage: 624.8+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_BUREAU</th>
      <th>MONTHS_BALANCE</th>
      <th>STATUS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5715448</td>
      <td>0</td>
      <td>C</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5715448</td>
      <td>-1</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5715448</td>
      <td>-2</td>
      <td>C</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5715448</td>
      <td>-3</td>
      <td>C</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5715448</td>
      <td>-4</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>credit_card_balance: shape is (3840312, 23)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 3840312 entries, 0 to 3840311
Data columns (total 23 columns):
SK_ID_PREV                    int64
SK_ID_CURR                    int64
MONTHS_BALANCE                int64
AMT_BALANCE                   float64
AMT_CREDIT_LIMIT_ACTUAL       int64
AMT_DRAWINGS_ATM_CURRENT      float64
AMT_DRAWINGS_CURRENT          float64
AMT_DRAWINGS_OTHER_CURRENT    float64
AMT_DRAWINGS_POS_CURRENT      float64
AMT_INST_MIN_REGULARITY       float64
AMT_PAYMENT_CURRENT           float64
AMT_PAYMENT_TOTAL_CURRENT     float64
AMT_RECEIVABLE_PRINCIPAL      float64
AMT_RECIVABLE                 float64
AMT_TOTAL_RECEIVABLE          float64
CNT_DRAWINGS_ATM_CURRENT      float64
CNT_DRAWINGS_CURRENT          int64
CNT_DRAWINGS_OTHER_CURRENT    float64
CNT_DRAWINGS_POS_CURRENT      float64
CNT_INSTALMENT_MATURE_CUM     float64
NAME_CONTRACT_STATUS          object
SK_DPD                        int64
SK_DPD_DEF                    int64
dtypes: float64(15), int64(7), object(1)
memory usage: 673.9+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>MONTHS_BALANCE</th>
      <th>AMT_BALANCE</th>
      <th>AMT_CREDIT_LIMIT_ACTUAL</th>
      <th>AMT_DRAWINGS_ATM_CURRENT</th>
      <th>AMT_DRAWINGS_CURRENT</th>
      <th>AMT_DRAWINGS_OTHER_CURRENT</th>
      <th>AMT_DRAWINGS_POS_CURRENT</th>
      <th>AMT_INST_MIN_REGULARITY</th>
      <th>...</th>
      <th>AMT_RECIVABLE</th>
      <th>AMT_TOTAL_RECEIVABLE</th>
      <th>CNT_DRAWINGS_ATM_CURRENT</th>
      <th>CNT_DRAWINGS_CURRENT</th>
      <th>CNT_DRAWINGS_OTHER_CURRENT</th>
      <th>CNT_DRAWINGS_POS_CURRENT</th>
      <th>CNT_INSTALMENT_MATURE_CUM</th>
      <th>NAME_CONTRACT_STATUS</th>
      <th>SK_DPD</th>
      <th>SK_DPD_DEF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2562384</td>
      <td>378907</td>
      <td>-6</td>
      <td>56.970</td>
      <td>135000</td>
      <td>0.0</td>
      <td>877.5</td>
      <td>0.0</td>
      <td>877.5</td>
      <td>1700.325</td>
      <td>...</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>35.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2582071</td>
      <td>363914</td>
      <td>-1</td>
      <td>63975.555</td>
      <td>45000</td>
      <td>2250.0</td>
      <td>2250.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2250.000</td>
      <td>...</td>
      <td>64875.555</td>
      <td>64875.555</td>
      <td>1.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>69.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1740877</td>
      <td>371185</td>
      <td>-7</td>
      <td>31815.225</td>
      <td>450000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2250.000</td>
      <td>...</td>
      <td>31460.085</td>
      <td>31460.085</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1389973</td>
      <td>337855</td>
      <td>-4</td>
      <td>236572.110</td>
      <td>225000</td>
      <td>2250.0</td>
      <td>2250.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>11795.760</td>
      <td>...</td>
      <td>233048.970</td>
      <td>233048.970</td>
      <td>1.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1891521</td>
      <td>126868</td>
      <td>-1</td>
      <td>453919.455</td>
      <td>450000</td>
      <td>0.0</td>
      <td>11547.0</td>
      <td>0.0</td>
      <td>11547.0</td>
      <td>22924.890</td>
      <td>...</td>
      <td>453919.455</td>
      <td>453919.455</td>
      <td>0.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>101.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 23 columns</p>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>installments_payments: shape is (13605401, 8)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 13605401 entries, 0 to 13605400
Data columns (total 8 columns):
SK_ID_PREV                int64
SK_ID_CURR                int64
NUM_INSTALMENT_VERSION    float64
NUM_INSTALMENT_NUMBER     int64
DAYS_INSTALMENT           float64
DAYS_ENTRY_PAYMENT        float64
AMT_INSTALMENT            float64
AMT_PAYMENT               float64
dtypes: float64(5), int64(3)
memory usage: 830.4 MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>NUM_INSTALMENT_VERSION</th>
      <th>NUM_INSTALMENT_NUMBER</th>
      <th>DAYS_INSTALMENT</th>
      <th>DAYS_ENTRY_PAYMENT</th>
      <th>AMT_INSTALMENT</th>
      <th>AMT_PAYMENT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1054186</td>
      <td>161674</td>
      <td>1.0</td>
      <td>6</td>
      <td>-1180.0</td>
      <td>-1187.0</td>
      <td>6948.360</td>
      <td>6948.360</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1330831</td>
      <td>151639</td>
      <td>0.0</td>
      <td>34</td>
      <td>-2156.0</td>
      <td>-2156.0</td>
      <td>1716.525</td>
      <td>1716.525</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2085231</td>
      <td>193053</td>
      <td>2.0</td>
      <td>1</td>
      <td>-63.0</td>
      <td>-63.0</td>
      <td>25425.000</td>
      <td>25425.000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2452527</td>
      <td>199697</td>
      <td>1.0</td>
      <td>3</td>
      <td>-2418.0</td>
      <td>-2426.0</td>
      <td>24350.130</td>
      <td>24350.130</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2714724</td>
      <td>167756</td>
      <td>1.0</td>
      <td>2</td>
      <td>-1383.0</td>
      <td>-1366.0</td>
      <td>2165.040</td>
      <td>2160.585</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>previous_application: shape is (1670214, 37)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1670214 entries, 0 to 1670213
Data columns (total 37 columns):
SK_ID_PREV                     1670214 non-null int64
SK_ID_CURR                     1670214 non-null int64
NAME_CONTRACT_TYPE             1670214 non-null object
AMT_ANNUITY                    1297979 non-null float64
AMT_APPLICATION                1670214 non-null float64
AMT_CREDIT                     1670213 non-null float64
AMT_DOWN_PAYMENT               774370 non-null float64
AMT_GOODS_PRICE                1284699 non-null float64
WEEKDAY_APPR_PROCESS_START     1670214 non-null object
HOUR_APPR_PROCESS_START        1670214 non-null int64
FLAG_LAST_APPL_PER_CONTRACT    1670214 non-null object
NFLAG_LAST_APPL_IN_DAY         1670214 non-null int64
RATE_DOWN_PAYMENT              774370 non-null float64
RATE_INTEREST_PRIMARY          5951 non-null float64
RATE_INTEREST_PRIVILEGED       5951 non-null float64
NAME_CASH_LOAN_PURPOSE         1670214 non-null object
NAME_CONTRACT_STATUS           1670214 non-null object
DAYS_DECISION                  1670214 non-null int64
NAME_PAYMENT_TYPE              1670214 non-null object
CODE_REJECT_REASON             1670214 non-null object
NAME_TYPE_SUITE                849809 non-null object
NAME_CLIENT_TYPE               1670214 non-null object
NAME_GOODS_CATEGORY            1670214 non-null object
NAME_PORTFOLIO                 1670214 non-null object
NAME_PRODUCT_TYPE              1670214 non-null object
CHANNEL_TYPE                   1670214 non-null object
SELLERPLACE_AREA               1670214 non-null int64
NAME_SELLER_INDUSTRY           1670214 non-null object
CNT_PAYMENT                    1297984 non-null float64
NAME_YIELD_GROUP               1670214 non-null object
PRODUCT_COMBINATION            1669868 non-null object
DAYS_FIRST_DRAWING             997149 non-null float64
DAYS_FIRST_DUE                 997149 non-null float64
DAYS_LAST_DUE_1ST_VERSION      997149 non-null float64
DAYS_LAST_DUE                  997149 non-null float64
DAYS_TERMINATION               997149 non-null float64
NFLAG_INSURED_ON_APPROVAL      997149 non-null float64
dtypes: float64(15), int64(6), object(16)
memory usage: 471.5+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>AMT_ANNUITY</th>
      <th>AMT_APPLICATION</th>
      <th>AMT_CREDIT</th>
      <th>AMT_DOWN_PAYMENT</th>
      <th>AMT_GOODS_PRICE</th>
      <th>WEEKDAY_APPR_PROCESS_START</th>
      <th>HOUR_APPR_PROCESS_START</th>
      <th>...</th>
      <th>NAME_SELLER_INDUSTRY</th>
      <th>CNT_PAYMENT</th>
      <th>NAME_YIELD_GROUP</th>
      <th>PRODUCT_COMBINATION</th>
      <th>DAYS_FIRST_DRAWING</th>
      <th>DAYS_FIRST_DUE</th>
      <th>DAYS_LAST_DUE_1ST_VERSION</th>
      <th>DAYS_LAST_DUE</th>
      <th>DAYS_TERMINATION</th>
      <th>NFLAG_INSURED_ON_APPROVAL</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2030495</td>
      <td>271877</td>
      <td>Consumer loans</td>
      <td>1730.430</td>
      <td>17145.0</td>
      <td>17145.0</td>
      <td>0.0</td>
      <td>17145.0</td>
      <td>SATURDAY</td>
      <td>15</td>
      <td>...</td>
      <td>Connectivity</td>
      <td>12.0</td>
      <td>middle</td>
      <td>POS mobile with interest</td>
      <td>365243.0</td>
      <td>-42.0</td>
      <td>300.0</td>
      <td>-42.0</td>
      <td>-37.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2802425</td>
      <td>108129</td>
      <td>Cash loans</td>
      <td>25188.615</td>
      <td>607500.0</td>
      <td>679671.0</td>
      <td>NaN</td>
      <td>607500.0</td>
      <td>THURSDAY</td>
      <td>11</td>
      <td>...</td>
      <td>XNA</td>
      <td>36.0</td>
      <td>low_action</td>
      <td>Cash X-Sell: low</td>
      <td>365243.0</td>
      <td>-134.0</td>
      <td>916.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2523466</td>
      <td>122040</td>
      <td>Cash loans</td>
      <td>15060.735</td>
      <td>112500.0</td>
      <td>136444.5</td>
      <td>NaN</td>
      <td>112500.0</td>
      <td>TUESDAY</td>
      <td>11</td>
      <td>...</td>
      <td>XNA</td>
      <td>12.0</td>
      <td>high</td>
      <td>Cash X-Sell: high</td>
      <td>365243.0</td>
      <td>-271.0</td>
      <td>59.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2819243</td>
      <td>176158</td>
      <td>Cash loans</td>
      <td>47041.335</td>
      <td>450000.0</td>
      <td>470790.0</td>
      <td>NaN</td>
      <td>450000.0</td>
      <td>MONDAY</td>
      <td>7</td>
      <td>...</td>
      <td>XNA</td>
      <td>12.0</td>
      <td>middle</td>
      <td>Cash X-Sell: middle</td>
      <td>365243.0</td>
      <td>-482.0</td>
      <td>-152.0</td>
      <td>-182.0</td>
      <td>-177.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1784265</td>
      <td>202054</td>
      <td>Cash loans</td>
      <td>31924.395</td>
      <td>337500.0</td>
      <td>404055.0</td>
      <td>NaN</td>
      <td>337500.0</td>
      <td>THURSDAY</td>
      <td>9</td>
      <td>...</td>
      <td>XNA</td>
      <td>24.0</td>
      <td>high</td>
      <td>Cash Street: high</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 37 columns</p>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>POS_CASH_balance: shape is (10001358, 8)
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 10001358 entries, 0 to 10001357
Data columns (total 8 columns):
SK_ID_PREV               int64
SK_ID_CURR               int64
MONTHS_BALANCE           int64
CNT_INSTALMENT           float64
CNT_INSTALMENT_FUTURE    float64
NAME_CONTRACT_STATUS     object
SK_DPD                   int64
SK_DPD_DEF               int64
dtypes: float64(2), int64(5), object(1)
memory usage: 610.4+ MB
None
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>MONTHS_BALANCE</th>
      <th>CNT_INSTALMENT</th>
      <th>CNT_INSTALMENT_FUTURE</th>
      <th>NAME_CONTRACT_STATUS</th>
      <th>SK_DPD</th>
      <th>SK_DPD_DEF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1803195</td>
      <td>182943</td>
      <td>-31</td>
      <td>48.0</td>
      <td>45.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1715348</td>
      <td>367990</td>
      <td>-33</td>
      <td>36.0</td>
      <td>35.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1784872</td>
      <td>397406</td>
      <td>-32</td>
      <td>12.0</td>
      <td>9.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1903291</td>
      <td>269225</td>
      <td>-35</td>
      <td>48.0</td>
      <td>42.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2341044</td>
      <td>334279</td>
      <td>-35</td>
      <td>36.0</td>
      <td>35.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wall time: 1min 5s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">ds_name</span> <span class="ow">in</span> <span class="n">ds_names</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;dataset </span><span class="si">{ds_name:24}</span><span class="s1">: [ </span><span class="si">{datasets[ds_name].shape[0]:10,}</span><span class="s1">, </span><span class="si">{datasets[ds_name].shape[1]}</span><span class="s1">]&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>dataset application_train       : [    307,511, 122]
dataset application_test        : [     48,744, 121]
dataset bureau                  : [  1,716,428, 17]
dataset bureau_balance          : [ 27,299,925, 3]
dataset credit_card_balance     : [  3,840,312, 23]
dataset installments_payments   : [ 13,605,401, 8]
dataset previous_application    : [  1,670,214, 37]
dataset POS_CASH_balance        : [ 10,001,358, 8]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Exploratory-Data-Analysis">Exploratory Data Analysis<a class="anchor-link" href="#Exploratory-Data-Analysis">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary-of-Application-train">Summary of Application train<a class="anchor-link" href="#Summary-of-Application-train">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 307511 entries, 0 to 307510
Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR
dtypes: float64(65), int64(41), object(16)
memory usage: 286.2+ MB
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[10]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>AMT_GOODS_PRICE</th>
      <th>REGION_POPULATION_RELATIVE</th>
      <th>DAYS_BIRTH</th>
      <th>DAYS_EMPLOYED</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>307511.000000</td>
      <td>307511.000000</td>
      <td>307511.000000</td>
      <td>3.075110e+05</td>
      <td>3.075110e+05</td>
      <td>307499.000000</td>
      <td>3.072330e+05</td>
      <td>307511.000000</td>
      <td>307511.000000</td>
      <td>307511.000000</td>
      <td>...</td>
      <td>307511.000000</td>
      <td>307511.000000</td>
      <td>307511.000000</td>
      <td>307511.000000</td>
      <td>265992.000000</td>
      <td>265992.000000</td>
      <td>265992.000000</td>
      <td>265992.000000</td>
      <td>265992.000000</td>
      <td>265992.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>278180.518577</td>
      <td>0.080729</td>
      <td>0.417052</td>
      <td>1.687979e+05</td>
      <td>5.990260e+05</td>
      <td>27108.573909</td>
      <td>5.383962e+05</td>
      <td>0.020868</td>
      <td>-16036.995067</td>
      <td>63815.045904</td>
      <td>...</td>
      <td>0.008130</td>
      <td>0.000595</td>
      <td>0.000507</td>
      <td>0.000335</td>
      <td>0.006402</td>
      <td>0.007000</td>
      <td>0.034362</td>
      <td>0.267395</td>
      <td>0.265474</td>
      <td>1.899974</td>
    </tr>
    <tr>
      <th>std</th>
      <td>102790.175348</td>
      <td>0.272419</td>
      <td>0.722121</td>
      <td>2.371231e+05</td>
      <td>4.024908e+05</td>
      <td>14493.737315</td>
      <td>3.694465e+05</td>
      <td>0.013831</td>
      <td>4363.988632</td>
      <td>141275.766519</td>
      <td>...</td>
      <td>0.089798</td>
      <td>0.024387</td>
      <td>0.022518</td>
      <td>0.018299</td>
      <td>0.083849</td>
      <td>0.110757</td>
      <td>0.204685</td>
      <td>0.916002</td>
      <td>0.794056</td>
      <td>1.869295</td>
    </tr>
    <tr>
      <th>min</th>
      <td>100002.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.565000e+04</td>
      <td>4.500000e+04</td>
      <td>1615.500000</td>
      <td>4.050000e+04</td>
      <td>0.000290</td>
      <td>-25229.000000</td>
      <td>-17912.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>189145.500000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.125000e+05</td>
      <td>2.700000e+05</td>
      <td>16524.000000</td>
      <td>2.385000e+05</td>
      <td>0.010006</td>
      <td>-19682.000000</td>
      <td>-2760.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>278202.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.471500e+05</td>
      <td>5.135310e+05</td>
      <td>24903.000000</td>
      <td>4.500000e+05</td>
      <td>0.018850</td>
      <td>-15750.000000</td>
      <td>-1213.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>367142.500000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>2.025000e+05</td>
      <td>8.086500e+05</td>
      <td>34596.000000</td>
      <td>6.795000e+05</td>
      <td>0.028663</td>
      <td>-12413.000000</td>
      <td>-289.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>456255.000000</td>
      <td>1.000000</td>
      <td>19.000000</td>
      <td>1.170000e+08</td>
      <td>4.050000e+06</td>
      <td>258025.500000</td>
      <td>4.050000e+06</td>
      <td>0.072508</td>
      <td>-7489.000000</td>
      <td>365243.000000</td>
      <td>...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>9.000000</td>
      <td>8.000000</td>
      <td>27.000000</td>
      <td>261.000000</td>
      <td>25.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 106 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Missing-data-for-application-train">Missing data for application train<a class="anchor-link" href="#Missing-data-for-application-train">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">total</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">percent</span> <span class="o">=</span> <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">missing_application_train_data</span>  <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">total</span><span class="p">,</span> <span class="n">percent</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Count&#39;</span><span class="p">,</span> <span class="s1">&#39;Percent&#39;</span><span class="p">])</span>
<span class="n">missing_application_train_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[11]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Count</th>
      <th>Percent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>COMMONAREA_MEDI</th>
      <td>214865</td>
      <td>69.87</td>
    </tr>
    <tr>
      <th>COMMONAREA_AVG</th>
      <td>214865</td>
      <td>69.87</td>
    </tr>
    <tr>
      <th>COMMONAREA_MODE</th>
      <td>214865</td>
      <td>69.87</td>
    </tr>
    <tr>
      <th>NONLIVINGAPARTMENTS_MODE</th>
      <td>213514</td>
      <td>69.43</td>
    </tr>
    <tr>
      <th>NONLIVINGAPARTMENTS_MEDI</th>
      <td>213514</td>
      <td>69.43</td>
    </tr>
    <tr>
      <th>NONLIVINGAPARTMENTS_AVG</th>
      <td>213514</td>
      <td>69.43</td>
    </tr>
    <tr>
      <th>FONDKAPREMONT_MODE</th>
      <td>210295</td>
      <td>68.39</td>
    </tr>
    <tr>
      <th>LIVINGAPARTMENTS_MEDI</th>
      <td>210199</td>
      <td>68.35</td>
    </tr>
    <tr>
      <th>LIVINGAPARTMENTS_MODE</th>
      <td>210199</td>
      <td>68.35</td>
    </tr>
    <tr>
      <th>LIVINGAPARTMENTS_AVG</th>
      <td>210199</td>
      <td>68.35</td>
    </tr>
    <tr>
      <th>FLOORSMIN_MEDI</th>
      <td>208642</td>
      <td>67.85</td>
    </tr>
    <tr>
      <th>FLOORSMIN_MODE</th>
      <td>208642</td>
      <td>67.85</td>
    </tr>
    <tr>
      <th>FLOORSMIN_AVG</th>
      <td>208642</td>
      <td>67.85</td>
    </tr>
    <tr>
      <th>YEARS_BUILD_MEDI</th>
      <td>204488</td>
      <td>66.50</td>
    </tr>
    <tr>
      <th>YEARS_BUILD_AVG</th>
      <td>204488</td>
      <td>66.50</td>
    </tr>
    <tr>
      <th>YEARS_BUILD_MODE</th>
      <td>204488</td>
      <td>66.50</td>
    </tr>
    <tr>
      <th>OWN_CAR_AGE</th>
      <td>202929</td>
      <td>65.99</td>
    </tr>
    <tr>
      <th>LANDAREA_MODE</th>
      <td>182590</td>
      <td>59.38</td>
    </tr>
    <tr>
      <th>LANDAREA_AVG</th>
      <td>182590</td>
      <td>59.38</td>
    </tr>
    <tr>
      <th>LANDAREA_MEDI</th>
      <td>182590</td>
      <td>59.38</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Features-having-missing-percent-&lt;=-25%">Features having missing percent &lt;= 25%<a class="anchor-link" href="#Features-having-missing-percent-&lt;=-25%">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">missing_application_train_data</span><span class="p">[</span><span class="n">missing_application_train_data</span><span class="o">.</span><span class="n">Percent</span> <span class="o">&lt;=</span> <span class="mi">25</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[12]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Count</th>
      <th>Percent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>EXT_SOURCE_3</th>
      <td>60965</td>
      <td>19.83</td>
    </tr>
    <tr>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <td>41519</td>
      <td>13.50</td>
    </tr>
    <tr>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
      <td>41519</td>
      <td>13.50</td>
    </tr>
    <tr>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <td>41519</td>
      <td>13.50</td>
    </tr>
    <tr>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <td>41519</td>
      <td>13.50</td>
    </tr>
    <tr>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <td>41519</td>
      <td>13.50</td>
    </tr>
    <tr>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <td>41519</td>
      <td>13.50</td>
    </tr>
    <tr>
      <th>NAME_TYPE_SUITE</th>
      <td>1292</td>
      <td>0.42</td>
    </tr>
    <tr>
      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>
      <td>1021</td>
      <td>0.33</td>
    </tr>
    <tr>
      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>
      <td>1021</td>
      <td>0.33</td>
    </tr>
    <tr>
      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>
      <td>1021</td>
      <td>0.33</td>
    </tr>
    <tr>
      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>
      <td>1021</td>
      <td>0.33</td>
    </tr>
    <tr>
      <th>EXT_SOURCE_2</th>
      <td>660</td>
      <td>0.21</td>
    </tr>
    <tr>
      <th>AMT_GOODS_PRICE</th>
      <td>278</td>
      <td>0.09</td>
    </tr>
    <tr>
      <th>AMT_ANNUITY</th>
      <td>12</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>CNT_FAM_MEMBERS</th>
      <td>2</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>DAYS_LAST_PHONE_CHANGE</th>
      <td>1</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>AMT_CREDIT</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_OWN_CAR</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_EMAIL</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>TARGET</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_PHONE</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_CONT_MOBILE</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_WORK_PHONE</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_EMP_PHONE</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_MOBIL</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>NAME_CONTRACT_TYPE</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>CODE_GENDER</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_OWN_REALTY</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>AMT_INCOME_TOTAL</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>REGION_RATING_CLIENT_W_CITY</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>WEEKDAY_APPR_PROCESS_START</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_2</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_3</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_4</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_5</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_6</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_7</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_8</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_9</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_10</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_11</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_12</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_13</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_14</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_15</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_16</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_17</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_18</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_19</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_20</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_21</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>ORGANIZATION_TYPE</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>LIVE_CITY_NOT_WORK_CITY</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>REG_CITY_NOT_WORK_CITY</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>REG_CITY_NOT_LIVE_CITY</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>LIVE_REGION_NOT_WORK_REGION</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>REG_REGION_NOT_WORK_REGION</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>HOUR_APPR_PROCESS_START</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>SK_ID_CURR</th>
      <td>0</td>
      <td>0.00</td>
    </tr>
  </tbody>
</table>
<p>72 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Distribution-of-the-target-column">Distribution of the target column<a class="anchor-link" href="#Distribution-of-the-target-column">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">hist</span><span class="p">();</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Correlation-with--the-target-column">Correlation with  the target column<a class="anchor-link" href="#Correlation-with--the-target-column">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">correlations</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">()[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Most Positive Correlations:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">correlations</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Most Negative Correlations:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">correlations</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Most Positive Correlations:
 FLAG_DOCUMENT_3                0.044346
REG_CITY_NOT_LIVE_CITY         0.044395
FLAG_EMP_PHONE                 0.045982
REG_CITY_NOT_WORK_CITY         0.050994
DAYS_ID_PUBLISH                0.051457
DAYS_LAST_PHONE_CHANGE         0.055218
REGION_RATING_CLIENT           0.058899
REGION_RATING_CLIENT_W_CITY    0.060893
DAYS_BIRTH                     0.078239
TARGET                         1.000000
Name: TARGET, dtype: float64

Most Negative Correlations:
 EXT_SOURCE_3                 -0.178919
EXT_SOURCE_2                 -0.160472
EXT_SOURCE_1                 -0.155317
DAYS_EMPLOYED                -0.044932
FLOORSMAX_AVG                -0.044003
FLOORSMAX_MEDI               -0.043768
FLOORSMAX_MODE               -0.043226
AMT_GOODS_PRICE              -0.039645
REGION_POPULATION_RELATIVE   -0.037227
ELEVATORS_AVG                -0.034199
Name: TARGET, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Out of the three strongest numerical features, <strong>EXT_SOURCE_1</strong> has more than 50% missing value. So we will try the option of only using the other two.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][[</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[15]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>EXT_SOURCE_1    0.563811
EXT_SOURCE_2    0.002146
EXT_SOURCE_3    0.198253
dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][[</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[16]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EXT_SOURCE_1</th>
      <th>EXT_SOURCE_2</th>
      <th>EXT_SOURCE_3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>EXT_SOURCE_1</th>
      <td>1.000000</td>
      <td>0.213982</td>
      <td>0.186846</td>
    </tr>
    <tr>
      <th>EXT_SOURCE_2</th>
      <td>0.213982</td>
      <td>1.000000</td>
      <td>0.109167</td>
    </tr>
    <tr>
      <th>EXT_SOURCE_3</th>
      <td>0.186846</td>
      <td>0.109167</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Applicants-Age">Applicants Age<a class="anchor-link" href="#Applicants-Age">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">][</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="o">-</span><span class="mi">365</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Age of Client&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Age (years)&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">);</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Applicants-occupations">Applicants occupations<a class="anchor-link" href="#Applicants-occupations">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Applicants Occupation&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">);</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="FLAG_OWN_REALTY">FLAG_OWN_REALTY<a class="anchor-link" href="#FLAG_OWN_REALTY">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[19]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Y    213312
N     94199
Name: FLAG_OWN_REALTY, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It seems like there is no big difference in default ratios between male and female.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Is owning real estate a good predictor of credit risk? First let's look at the default rate among those who own real estate:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Y&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> 
         <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[21]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.07961577407740775</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And now among those who do not own real estate:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;N&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> 
         <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[22]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.08324929139375152</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There is a difference, but it's rather subtle.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="REGION_POPULATION_RELATIVE">REGION_POPULATION_RELATIVE<a class="anchor-link" href="#REGION_POPULATION_RELATIVE">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[23]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.035792    16408
0.046220    13442
0.030755    12163
0.025164    11950
0.026392    11601
0.031329    11321
0.028663    11157
0.019101     8694
0.072508     8412
0.020713     8066
0.018850     7668
0.020246     7178
0.018634     7038
0.022625     6943
0.015221     6824
0.032561     6636
0.024610     6404
0.019689     6172
0.018029     6167
0.018801     6108
0.018209     6052
0.014520     4785
0.016612     4408
0.007020     4105
0.022800     3807
0.010032     3570
0.010006     3563
0.014464     3422
0.004960     3300
0.011703     3252
            ...  
0.006008     1796
0.003069     1783
0.008575     1763
0.008474     1740
0.007274     1724
0.007114     1684
0.006305     1672
0.008068     1668
0.008866     1654
0.006671     1653
0.002042     1642
0.003813     1616
0.005084     1482
0.006296     1225
0.005313     1218
0.003818     1212
0.003122     1147
0.006233     1087
0.005002     1068
0.002134     1051
0.004849     1038
0.005144      967
0.002506      944
0.003541      627
0.001276      558
0.001417      467
0.001333      235
0.000533       39
0.000938       28
0.000290        2
Name: REGION_POPULATION_RELATIVE, Length: 81, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We may segment this variable as it clearly seperates the default rate</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">target_1_ratio</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">region_pop_relative</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">region_pop_relative</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;target_1_ratio&#39;</span><span class="p">]</span>
<span class="n">region_pop_relative</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">region_pop_relative</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;target_1_ratio&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">region_pop_relative</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[25]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>REGION_POPULATION_RELATIVE</th>
      <th>target_1_ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000290</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>80</th>
      <td>0.072508</td>
      <td>0.039705</td>
    </tr>
    <tr>
      <th>77</th>
      <td>0.032561</td>
      <td>0.045660</td>
    </tr>
    <tr>
      <th>79</th>
      <td>0.046220</td>
      <td>0.049323</td>
    </tr>
    <tr>
      <th>41</th>
      <td>0.009175</td>
      <td>0.054152</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.006008</td>
      <td>0.057906</td>
    </tr>
    <tr>
      <th>55</th>
      <td>0.011703</td>
      <td>0.059348</td>
    </tr>
    <tr>
      <th>46</th>
      <td>0.010006</td>
      <td>0.059781</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.001276</td>
      <td>0.060932</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.006233</td>
      <td>0.061638</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.003541</td>
      <td>0.062201</td>
    </tr>
    <tr>
      <th>73</th>
      <td>0.026392</td>
      <td>0.062236</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.002506</td>
      <td>0.063559</td>
    </tr>
    <tr>
      <th>64</th>
      <td>0.018850</td>
      <td>0.065728</td>
    </tr>
    <tr>
      <th>25</th>
      <td>0.006629</td>
      <td>0.066359</td>
    </tr>
    <tr>
      <th>54</th>
      <td>0.011657</td>
      <td>0.069156</td>
    </tr>
    <tr>
      <th>78</th>
      <td>0.035792</td>
      <td>0.070088</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.006207</td>
      <td>0.070248</td>
    </tr>
    <tr>
      <th>71</th>
      <td>0.024610</td>
      <td>0.070269</td>
    </tr>
    <tr>
      <th>26</th>
      <td>0.006671</td>
      <td>0.071990</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.004960</td>
      <td>0.072121</td>
    </tr>
    <tr>
      <th>52</th>
      <td>0.010643</td>
      <td>0.072377</td>
    </tr>
    <tr>
      <th>38</th>
      <td>0.008575</td>
      <td>0.073171</td>
    </tr>
    <tr>
      <th>42</th>
      <td>0.009334</td>
      <td>0.073452</td>
    </tr>
    <tr>
      <th>33</th>
      <td>0.007330</td>
      <td>0.073826</td>
    </tr>
    <tr>
      <th>28</th>
      <td>0.007020</td>
      <td>0.074056</td>
    </tr>
    <tr>
      <th>65</th>
      <td>0.019101</td>
      <td>0.074419</td>
    </tr>
    <tr>
      <th>43</th>
      <td>0.009549</td>
      <td>0.074700</td>
    </tr>
    <tr>
      <th>49</th>
      <td>0.010276</td>
      <td>0.075740</td>
    </tr>
    <tr>
      <th>48</th>
      <td>0.010147</td>
      <td>0.075999</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>36</th>
      <td>0.008230</td>
      <td>0.089246</td>
    </tr>
    <tr>
      <th>50</th>
      <td>0.010500</td>
      <td>0.089552</td>
    </tr>
    <tr>
      <th>51</th>
      <td>0.010556</td>
      <td>0.089573</td>
    </tr>
    <tr>
      <th>62</th>
      <td>0.018634</td>
      <td>0.089798</td>
    </tr>
    <tr>
      <th>66</th>
      <td>0.019689</td>
      <td>0.091056</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.003122</td>
      <td>0.091543</td>
    </tr>
    <tr>
      <th>30</th>
      <td>0.007120</td>
      <td>0.091576</td>
    </tr>
    <tr>
      <th>57</th>
      <td>0.014520</td>
      <td>0.092581</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.005002</td>
      <td>0.093633</td>
    </tr>
    <tr>
      <th>45</th>
      <td>0.009657</td>
      <td>0.094447</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.006296</td>
      <td>0.097959</td>
    </tr>
    <tr>
      <th>32</th>
      <td>0.007305</td>
      <td>0.098661</td>
    </tr>
    <tr>
      <th>37</th>
      <td>0.008474</td>
      <td>0.099425</td>
    </tr>
    <tr>
      <th>63</th>
      <td>0.018801</td>
      <td>0.100851</td>
    </tr>
    <tr>
      <th>40</th>
      <td>0.008866</td>
      <td>0.100967</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.002042</td>
      <td>0.103532</td>
    </tr>
    <tr>
      <th>61</th>
      <td>0.018209</td>
      <td>0.103602</td>
    </tr>
    <tr>
      <th>68</th>
      <td>0.020713</td>
      <td>0.105009</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.004849</td>
      <td>0.105010</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000938</td>
      <td>0.107143</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.003813</td>
      <td>0.115718</td>
    </tr>
    <tr>
      <th>67</th>
      <td>0.020246</td>
      <td>0.118696</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.006305</td>
      <td>0.119617</td>
    </tr>
    <tr>
      <th>60</th>
      <td>0.018029</td>
      <td>0.120156</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.001333</td>
      <td>0.123404</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.001417</td>
      <td>0.128480</td>
    </tr>
    <tr>
      <th>35</th>
      <td>0.008068</td>
      <td>0.136091</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.002134</td>
      <td>0.158896</td>
    </tr>
    <tr>
      <th>27</th>
      <td>0.006852</td>
      <td>0.161396</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000533</td>
      <td>0.205128</td>
    </tr>
  </tbody>
</table>
<p>81 rows × 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It will require some work to find the best 'cut' to bin the <strong>REGION_POPULATION_RELATIVE</strong> feature, so we will just divide the variable into three bins: [0, 0.07), [0.07, 0.1)] and [0.1, 1] and create a new feature in the feature engineering section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="FLAG_EMP_PHONE">FLAG_EMP_PHONE<a class="anchor-link" href="#FLAG_EMP_PHONE">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>FLAG_EMP_PHONE</strong> seems to have some separating power, so we will use this feature.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[27]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>FLAG_EMP_PHONE</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.054003</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.086600</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="FLAG_WORK_PHONE">FLAG_WORK_PHONE<a class="anchor-link" href="#FLAG_WORK_PHONE">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>FLAG_WORK_PHONE</strong> seems to have some separating power. So we will use this feature.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[29]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>FLAG_WORK_PHONE</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.076851</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.096301</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="REGION_RATING_CLIENT">REGION_RATING_CLIENT<a class="anchor-link" href="#REGION_RATING_CLIENT">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>REGION_RATING_CLIENT</strong> seems to have some separating power, so we will use this feature.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[31]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>REGION_RATING_CLIENT</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.048203</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.078891</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.111028</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="HOUR_APPR_PROCESS_START">HOUR_APPR_PROCESS_START<a class="anchor-link" href="#HOUR_APPR_PROCESS_START">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It seems like applications in the evening (5pm-9pm) have a lower default rate but the volumne in this time frame is relatively small.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[33]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>HOUR_APPR_PROCESS_START</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.150000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.081395</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.098361</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.086992</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.082775</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.105827</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.110407</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.100427</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.090765</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.082055</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.080218</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.080744</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.082581</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.080267</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.079077</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.075929</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.074614</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.064899</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.070173</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.068607</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.070234</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.061728</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.100000</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.121951</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ORGANIZATION_TYPE">ORGANIZATION_TYPE<a class="anchor-link" href="#ORGANIZATION_TYPE">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>ORGANIZATION_TYPE</strong> seems to have some separating power, so we will use this feature.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[35]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>ORGANIZATION_TYPE</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Advertising</th>
      <td>0.081585</td>
    </tr>
    <tr>
      <th>Agriculture</th>
      <td>0.104727</td>
    </tr>
    <tr>
      <th>Bank</th>
      <td>0.051855</td>
    </tr>
    <tr>
      <th>Business Entity Type 1</th>
      <td>0.081384</td>
    </tr>
    <tr>
      <th>Business Entity Type 2</th>
      <td>0.085284</td>
    </tr>
    <tr>
      <th>Business Entity Type 3</th>
      <td>0.092996</td>
    </tr>
    <tr>
      <th>Cleaning</th>
      <td>0.111538</td>
    </tr>
    <tr>
      <th>Construction</th>
      <td>0.116798</td>
    </tr>
    <tr>
      <th>Culture</th>
      <td>0.055409</td>
    </tr>
    <tr>
      <th>Electricity</th>
      <td>0.066316</td>
    </tr>
    <tr>
      <th>Emergency</th>
      <td>0.071429</td>
    </tr>
    <tr>
      <th>Government</th>
      <td>0.069781</td>
    </tr>
    <tr>
      <th>Hotel</th>
      <td>0.064182</td>
    </tr>
    <tr>
      <th>Housing</th>
      <td>0.079446</td>
    </tr>
    <tr>
      <th>Industry: type 1</th>
      <td>0.110683</td>
    </tr>
    <tr>
      <th>Industry: type 10</th>
      <td>0.064220</td>
    </tr>
    <tr>
      <th>Industry: type 11</th>
      <td>0.086538</td>
    </tr>
    <tr>
      <th>Industry: type 12</th>
      <td>0.037940</td>
    </tr>
    <tr>
      <th>Industry: type 13</th>
      <td>0.134328</td>
    </tr>
    <tr>
      <th>Industry: type 2</th>
      <td>0.072052</td>
    </tr>
    <tr>
      <th>Industry: type 3</th>
      <td>0.106162</td>
    </tr>
    <tr>
      <th>Industry: type 4</th>
      <td>0.101482</td>
    </tr>
    <tr>
      <th>Industry: type 5</th>
      <td>0.068447</td>
    </tr>
    <tr>
      <th>Industry: type 6</th>
      <td>0.071429</td>
    </tr>
    <tr>
      <th>Industry: type 7</th>
      <td>0.080337</td>
    </tr>
    <tr>
      <th>Industry: type 8</th>
      <td>0.125000</td>
    </tr>
    <tr>
      <th>Industry: type 9</th>
      <td>0.066805</td>
    </tr>
    <tr>
      <th>Insurance</th>
      <td>0.056951</td>
    </tr>
    <tr>
      <th>Kindergarten</th>
      <td>0.070349</td>
    </tr>
    <tr>
      <th>Legal Services</th>
      <td>0.078689</td>
    </tr>
    <tr>
      <th>Medicine</th>
      <td>0.065845</td>
    </tr>
    <tr>
      <th>Military</th>
      <td>0.051253</td>
    </tr>
    <tr>
      <th>Mobile</th>
      <td>0.091483</td>
    </tr>
    <tr>
      <th>Other</th>
      <td>0.076425</td>
    </tr>
    <tr>
      <th>Police</th>
      <td>0.049979</td>
    </tr>
    <tr>
      <th>Postal</th>
      <td>0.084376</td>
    </tr>
    <tr>
      <th>Realtor</th>
      <td>0.106061</td>
    </tr>
    <tr>
      <th>Religion</th>
      <td>0.058824</td>
    </tr>
    <tr>
      <th>Restaurant</th>
      <td>0.117062</td>
    </tr>
    <tr>
      <th>School</th>
      <td>0.059148</td>
    </tr>
    <tr>
      <th>Security</th>
      <td>0.099784</td>
    </tr>
    <tr>
      <th>Security Ministries</th>
      <td>0.048632</td>
    </tr>
    <tr>
      <th>Self-employed</th>
      <td>0.101739</td>
    </tr>
    <tr>
      <th>Services</th>
      <td>0.066032</td>
    </tr>
    <tr>
      <th>Telecom</th>
      <td>0.076256</td>
    </tr>
    <tr>
      <th>Trade: type 1</th>
      <td>0.089080</td>
    </tr>
    <tr>
      <th>Trade: type 2</th>
      <td>0.070000</td>
    </tr>
    <tr>
      <th>Trade: type 3</th>
      <td>0.103379</td>
    </tr>
    <tr>
      <th>Trade: type 4</th>
      <td>0.031250</td>
    </tr>
    <tr>
      <th>Trade: type 5</th>
      <td>0.061224</td>
    </tr>
    <tr>
      <th>Trade: type 6</th>
      <td>0.045959</td>
    </tr>
    <tr>
      <th>Trade: type 7</th>
      <td>0.094496</td>
    </tr>
    <tr>
      <th>Transport: type 1</th>
      <td>0.044776</td>
    </tr>
    <tr>
      <th>Transport: type 2</th>
      <td>0.078040</td>
    </tr>
    <tr>
      <th>Transport: type 3</th>
      <td>0.157540</td>
    </tr>
    <tr>
      <th>Transport: type 4</th>
      <td>0.092812</td>
    </tr>
    <tr>
      <th>University</th>
      <td>0.048983</td>
    </tr>
    <tr>
      <th>XNA</th>
      <td>0.053996</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="FLAG_DOCUMENT_3">FLAG_DOCUMENT_3<a class="anchor-link" href="#FLAG_DOCUMENT_3">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>FLAG_DOCUMENT_3</strong> seems to have some separating power, so we will use this feature.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[37]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>FLAG_DOCUMENT_3</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.061825</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.088449</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="FONDKAPREMONT_MODE">FONDKAPREMONT_MODE<a class="anchor-link" href="#FONDKAPREMONT_MODE">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>FONDKAPREMONT_MODE</strong> seems to have some separating power, so we will use this feature.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[39]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>FONDKAPREMONT_MODE</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>not specified</th>
      <td>0.075435</td>
    </tr>
    <tr>
      <th>org spec account</th>
      <td>0.058195</td>
    </tr>
    <tr>
      <th>reg oper account</th>
      <td>0.069782</td>
    </tr>
    <tr>
      <th>reg oper spec account</th>
      <td>0.065563</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="WALLSMATERIAL_MODE">WALLSMATERIAL_MODE<a class="anchor-link" href="#WALLSMATERIAL_MODE">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>WALLSMATERIAL_MODE</strong> seems to have some separating power, so we will use this feature.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">target_1_ratio</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[41]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>WALLSMATERIAL_MODE</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Block</th>
      <td>0.070247</td>
    </tr>
    <tr>
      <th>Mixed</th>
      <td>0.075348</td>
    </tr>
    <tr>
      <th>Monolithic</th>
      <td>0.047218</td>
    </tr>
    <tr>
      <th>Others</th>
      <td>0.083077</td>
    </tr>
    <tr>
      <th>Panel</th>
      <td>0.063477</td>
    </tr>
    <tr>
      <th>Stone, brick</th>
      <td>0.074057</td>
    </tr>
    <tr>
      <th>Wooden</th>
      <td>0.096979</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary-of-previous_application">Summary of previous_application<a class="anchor-link" href="#Summary-of-previous_application">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Explore which column to use for indicating the application days within 24 months/365 days</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[42]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>AMT_ANNUITY</th>
      <th>AMT_APPLICATION</th>
      <th>AMT_CREDIT</th>
      <th>AMT_DOWN_PAYMENT</th>
      <th>AMT_GOODS_PRICE</th>
      <th>WEEKDAY_APPR_PROCESS_START</th>
      <th>HOUR_APPR_PROCESS_START</th>
      <th>...</th>
      <th>NAME_SELLER_INDUSTRY</th>
      <th>CNT_PAYMENT</th>
      <th>NAME_YIELD_GROUP</th>
      <th>PRODUCT_COMBINATION</th>
      <th>DAYS_FIRST_DRAWING</th>
      <th>DAYS_FIRST_DUE</th>
      <th>DAYS_LAST_DUE_1ST_VERSION</th>
      <th>DAYS_LAST_DUE</th>
      <th>DAYS_TERMINATION</th>
      <th>NFLAG_INSURED_ON_APPROVAL</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2030495</td>
      <td>271877</td>
      <td>Consumer loans</td>
      <td>1730.430</td>
      <td>17145.0</td>
      <td>17145.0</td>
      <td>0.0</td>
      <td>17145.0</td>
      <td>SATURDAY</td>
      <td>15</td>
      <td>...</td>
      <td>Connectivity</td>
      <td>12.0</td>
      <td>middle</td>
      <td>POS mobile with interest</td>
      <td>365243.0</td>
      <td>-42.0</td>
      <td>300.0</td>
      <td>-42.0</td>
      <td>-37.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2802425</td>
      <td>108129</td>
      <td>Cash loans</td>
      <td>25188.615</td>
      <td>607500.0</td>
      <td>679671.0</td>
      <td>NaN</td>
      <td>607500.0</td>
      <td>THURSDAY</td>
      <td>11</td>
      <td>...</td>
      <td>XNA</td>
      <td>36.0</td>
      <td>low_action</td>
      <td>Cash X-Sell: low</td>
      <td>365243.0</td>
      <td>-134.0</td>
      <td>916.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2523466</td>
      <td>122040</td>
      <td>Cash loans</td>
      <td>15060.735</td>
      <td>112500.0</td>
      <td>136444.5</td>
      <td>NaN</td>
      <td>112500.0</td>
      <td>TUESDAY</td>
      <td>11</td>
      <td>...</td>
      <td>XNA</td>
      <td>12.0</td>
      <td>high</td>
      <td>Cash X-Sell: high</td>
      <td>365243.0</td>
      <td>-271.0</td>
      <td>59.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2819243</td>
      <td>176158</td>
      <td>Cash loans</td>
      <td>47041.335</td>
      <td>450000.0</td>
      <td>470790.0</td>
      <td>NaN</td>
      <td>450000.0</td>
      <td>MONDAY</td>
      <td>7</td>
      <td>...</td>
      <td>XNA</td>
      <td>12.0</td>
      <td>middle</td>
      <td>Cash X-Sell: middle</td>
      <td>365243.0</td>
      <td>-482.0</td>
      <td>-152.0</td>
      <td>-182.0</td>
      <td>-177.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1784265</td>
      <td>202054</td>
      <td>Cash loans</td>
      <td>31924.395</td>
      <td>337500.0</td>
      <td>404055.0</td>
      <td>NaN</td>
      <td>337500.0</td>
      <td>THURSDAY</td>
      <td>9</td>
      <td>...</td>
      <td>XNA</td>
      <td>24.0</td>
      <td>high</td>
      <td>Cash Street: high</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 37 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[43]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1670214, 37)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Explore which column to use for indicating the application days within 24 months/365 days</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;DAYS&#39;</span><span class="p">)]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[44]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;DAYS_DECISION&#39;, &#39;DAYS_FIRST_DRAWING&#39;, &#39;DAYS_FIRST_DUE&#39;,
       &#39;DAYS_LAST_DUE_1ST_VERSION&#39;, &#39;DAYS_LAST_DUE&#39;, &#39;DAYS_TERMINATION&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">][[</span><span class="s1">&#39;DAYS_DECISION&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_FIRST_DRAWING&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_FIRST_DUE&#39;</span><span class="p">,</span>
       <span class="s1">&#39;DAYS_LAST_DUE_1ST_VERSION&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_LAST_DUE&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_TERMINATION&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[45]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DAYS_DECISION</th>
      <th>DAYS_FIRST_DRAWING</th>
      <th>DAYS_FIRST_DUE</th>
      <th>DAYS_LAST_DUE_1ST_VERSION</th>
      <th>DAYS_LAST_DUE</th>
      <th>DAYS_TERMINATION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-73</td>
      <td>365243.0</td>
      <td>-42.0</td>
      <td>300.0</td>
      <td>-42.0</td>
      <td>-37.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-164</td>
      <td>365243.0</td>
      <td>-134.0</td>
      <td>916.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-301</td>
      <td>365243.0</td>
      <td>-271.0</td>
      <td>59.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-512</td>
      <td>365243.0</td>
      <td>-482.0</td>
      <td>-152.0</td>
      <td>-182.0</td>
      <td>-177.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-781</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-684</td>
      <td>365243.0</td>
      <td>-654.0</td>
      <td>-144.0</td>
      <td>-144.0</td>
      <td>-137.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-14</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-21</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-386</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-57</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-735</td>
      <td>365243.0</td>
      <td>-705.0</td>
      <td>885.0</td>
      <td>-345.0</td>
      <td>-334.0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-815</td>
      <td>365243.0</td>
      <td>-785.0</td>
      <td>85.0</td>
      <td>-725.0</td>
      <td>-721.0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-860</td>
      <td>365243.0</td>
      <td>-830.0</td>
      <td>-140.0</td>
      <td>-200.0</td>
      <td>-197.0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-408</td>
      <td>365243.0</td>
      <td>-378.0</td>
      <td>-168.0</td>
      <td>-168.0</td>
      <td>-163.0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-726</td>
      <td>365243.0</td>
      <td>-693.0</td>
      <td>-633.0</td>
      <td>-633.0</td>
      <td>-627.0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-699</td>
      <td>365243.0</td>
      <td>-668.0</td>
      <td>-518.0</td>
      <td>-518.0</td>
      <td>-512.0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-1473</td>
      <td>365243.0</td>
      <td>-1440.0</td>
      <td>-1230.0</td>
      <td>-1230.0</td>
      <td>-1226.0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-336</td>
      <td>-277.0</td>
      <td>-257.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
      <td>365243.0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-700</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-584</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks like we will have to choose <em>DAYS_DECISION</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">][[</span><span class="s1">&#39;DAYS_DECISION&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_FIRST_DRAWING&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_FIRST_DUE&#39;</span><span class="p">,</span>
       <span class="s1">&#39;DAYS_LAST_DUE_1ST_VERSION&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_LAST_DUE&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_TERMINATION&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[46]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>DAYS_DECISION                0.000000
DAYS_FIRST_DRAWING           0.402981
DAYS_FIRST_DUE               0.402981
DAYS_LAST_DUE_1ST_VERSION    0.402981
DAYS_LAST_DUE                0.402981
DAYS_TERMINATION             0.402981
dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A small portion of the population had more than 1 applications. We will create a variable <strong>no_prev_appl</strong> to show the no of previous applications from a customer in the past 12 months.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">no_app_customer</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">DAYS_DECISION</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">365</span><span class="p">)</span> <span class="o">&amp;</span> 
           <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">!=</span> <span class="s1">&#39;Canceled&#39;</span><span class="p">),</span> <span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_PREV</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># only select the applications in the past 12 months</span>
<span class="n">no_app_customer</span> <span class="o">=</span> <span class="n">no_app_customer</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">no_app_customer</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">no_app_customer</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;SK_ID_PREV&#39;</span><span class="p">:</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">no_app_customer</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[47]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>no_prev_appl</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>133023</td>
      <td>54</td>
    </tr>
    <tr>
      <th>1</th>
      <td>401563</td>
      <td>50</td>
    </tr>
    <tr>
      <th>2</th>
      <td>167400</td>
      <td>36</td>
    </tr>
    <tr>
      <th>3</th>
      <td>345161</td>
      <td>33</td>
    </tr>
    <tr>
      <th>4</th>
      <td>205430</td>
      <td>33</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>distribution of no of previous applications within 12 months from bureau data. We will merge this new data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">no_app_customer</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">no_app_customer</span><span class="o">.</span><span class="n">no_prev_appl</span> <span class="o">&lt;=</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Merge <em>no_app_customer</em> with train and test data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_train&#39;</span><span class="p">],</span> <span class="n">no_app_customer</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application_test&#39;</span><span class="p">],</span> <span class="n">no_app_customer</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>About 53% current applicants don't have any previous applications.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">no_prev_appl</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">test</span><span class="o">.</span><span class="n">no_prev_appl</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[50]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(0.5288656340748786, 0.5370917446249794)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>now create <strong>no_approved_prev_appl</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">no_approved_app_customer</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">DAYS_DECISION</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">365</span><span class="p">)</span> <span class="o">&amp;</span> 
           <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">==</span> <span class="s1">&#39;Approved&#39;</span><span class="p">),</span> <span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_PREV</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># only select the applications in the past 12 months</span>
<span class="n">no_approved_app_customer</span> <span class="o">=</span> <span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;SK_ID_PREV&#39;</span><span class="p">:</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[51]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>no_approved_prev_appl</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>271000</td>
      <td>8</td>
    </tr>
    <tr>
      <th>1</th>
      <td>237145</td>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>407501</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>304969</td>
      <td>7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>357741</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">no_approved_prev_appl</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Merge <em>no_approved_app_customer</em> with train and test data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">no_approved_app_customer</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">no_approved_app_customer</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>About 60% percent current customers don't have any previous application info.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">no_approved_prev_appl</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[54]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.6023426804244401</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test</span><span class="o">.</span><span class="n">no_approved_prev_appl</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[55]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.618373543410471</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>fill NA for the 2 newly created features</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">[[</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[[</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[[</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[[</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>distribution of the two newly created features</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">no_approved_prev_appl</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of No of Approved Previous Applications&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEJCAYAAABL3SrKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XucXVV5//HPIjOkeEGIo5ALGqgRJWmNgkAVKYJgQGqwxcdQTYJSIxQQLFSBUkFBhVaNebWKBowJXghPUUt+GoyIItqCgAjKzRJCkCExYQggEk0mYf/+WOuQPTtnzpzLzD5n4vf9ep3XnLP22ms9e5+997MvKychyzJERETKtFO7AxARkT89Sj4iIlI6JR8RESmdko+IiJROyUdEREqn5CMiIqUbVcknhHBhCGHlCLV9WAghCyFMqvZ5BPo7MYSwZSTabkYIYa8Qwg0hhGdCCB09/j6E8M4QwoMhhK0hhMXtjqdThRAWhxB+0O44BhNCmJz2sUPaHUvZ0nK/J/d5dQjh/BL6HbFjaKPannzSDpKl15YQwoYQws0hhAtCCOMK1T8NHNxA2ytDCBfWWf1/gfHAmnrbrzOGSWnZDitMuhqYOJx9teg84KXAdOJ62E4uIfeGEJ5XmFbKgS6EMAZYBDjwMuCMIervGUL4YwjhtyGE7pGOb7TJ7XtZCOH3IYS7QggnldT9I8Rt7Wcl9TekEMLx6aTmWyV3/Xpg/nA1FkI4JH2nkwuTGjqGjqS2J5/kJ8SN8GXAm4DLgROAe0IIr6xUyrLs91mW9Q135yGEnbMs25xl2W+zLHt2uNuvJsuyP2RZtq6Mvuo0Bbg1y7IHsiz77RB1xwEfLiGmasYDLwCWZ1n2aJZlTw1R/33Ad4HHgZkjHVxFCGHnsvoaBqcR1+trgeuAK0II76xWMYSwUzoBaFmWZVvTPtc/HO0Nk3nApcDRIYQ9y+o0y7LHsix7poR+RuQY2pQsy9r6AhYDP6hSvivwIPDDXNmFwMrc50nAN4E+4A/AKuCf07Qbgazwmgwclt6/Dfgp8Efizlcpn5Tmr3z+G+DWVO8e4Mhc/wPmyZVvAU5M74sxrE7lJwJbCvMdA/wc2ASsB74APL+4rog7yMPA74BrgZcMsY5fCHwJeCwtx+3AUbnpxRgXD9JOZXkvBp4BJg72PQIBODt9J5vTd3lmHdvDwcBN6ft8AvgG8NLcOivGeliNtnYCHkrf4YeB71epsxr4BHBFWp99xIPPTk3UuTh9Z48Dt6Xy8cBS4Mm0TDcCB+Ti+w1wXiGmsWnZT86VnQ7cn76/B4B/Abpy03cnXk0/A6xLsSyhyr5V6CsD3lMoewC4Kr/PAe9K/W8BpqVps4A7U0yrgc+Stlfg/cBTwC6Ftj8CPJqWfXLq/5Dc9H2JJwu/T6//B7wiN/1Ett9vJuW3BaA7xdJL3JfWAkvr2Pb2ScvSAyyv8r1U4p0N3JC+z4eAdzdSp9p6T+vv/NznLuCjxP1mU1pn/5GbfkZa978Hfpu2sfGFGPKvG6sdQ1PZXODe1E9v2nby29aNxG3/X1NfG4j7e/7YNBVYQdzOnwHuA2bXXN9DfSEj/WKQ5JOmnQ08Szq4FlccsIx4MJ6eVvibgRPStHHpS/80sGd6jWHbAfR+4O3A3mnjrZQXk88DwLHAq4Evp41pYqFOreTz2lTnb1MMlWU5kdxOBPxlmm9+6uto4oHpq4V19RRwFTANeAMxCS0ZYh3/F3HjfmtqewExIbwqTd+TeNvx6+n9iwZpp7K8Lwfuzvdb/B6BU9O6mke8qjqZuGOfVCPOPYkH928AfwEcAvwS+Emavgvx9kSWvrs9gZ1rtDeDmMS7iElgM7BPoc7q1OfHiQe+2cSd55+arHMh8EpgP2IC/hnxIHFIWqariYmlJ833KeD+QkzHp3W1e267fxh4B3F7PSZtGxfl5vk2MUkcTjwQfC3F00zy+SVwTa7vjcCPiScGrySezJyYlmM28aB9aJrvq2m+F6Xv/4RC23cDlxYOkofkvt+HiQft/dPrR2m5dq6236SyYvL5J+JB9DDi3ZTXU9+JzyXAt9J7I544hdz0SrxrgHenbeFi4jHqgHrrVFvvbJ98lhC33dnAn6d1/6Hc9DOAt6Tt4a+I+++P07QxxP0jS8u+JzBukGPo24CtwLnpu31X+l7z29aNxKQyH3gVcb96EvhYYZv5BnG734d4/Dq25voe6gsZ6Re1k8+MtAIPHGTF3QVcWKPtlcXpbDuAzh6kvJh8TsrV6SLuHBdXmydXL598BuwYuTonMjD5fJV42ytfZ2baaF+eW1ePAWNzdc4B1tZYB69I/R9TKL8DWFTYwK4Y4rt6bnmJiexZYP9q3yPxfv6/FeafD6yq0f5FxIPGzrmy16Q+Dy3s3IfUijXV/TYwP/d5OfDJQp3VpOSWK/sk0NtEnRsKdY5Ise6XKxtLPBP/aPr8qlTnoFydZcB/pffPIx78ZxTangM8WfiO81flOxPPlutOPsTt+x9S2cm5fe5Z4GVV1tvJhbJD07yVpLkUuC43/XVp+tRq3yVwUlrWntw8exCT2Jxq+021fYx4cvVDcomjjm2lm3jFODP3PW1g4B2CSrwXFeb9X+Br9dYprvfc+jy/8H0e30D8lZPcyonxIenz5EK9Cxl4DP0J4IU6Z6R1Xkn4NwK/LNT5InBz7vNTpGNeva9OeeYzmJD+ZoNM/xxwXgjhZyGES0MIhzbQ9q111ru58ibLsi1pvv0a6KdeU4m3m/J+TFwH+f7uy7JsU+7zo8QddDCVeYtt35T6bEqWZSuIl9mfLU4LIexKPCBUW57JxcEKOVOBW7Is25zr5y7iht1QrCGE8cQr1iW54sXAe0MIXYXqNxc+/w8wMS1HI3WK29RU4PEsy+6tFKTv7mdpGlmW3Q/cRkwmhBB6iCddS3Jt7AJ8Mw0I+H0I4ffE26gvCiG8hG3f8f/m+tmc2q3HFanNPxJPEC5J7Vesy7LsN5UPqc+XA58txHRdqvKK9PdK4Mjcs5PZwM+zLLtnkDimAvdmuWcSWXwu+msa+/6/QrzKXBlC+GII4e/qeAb3DuKtwOWp303E5DmvSt1q20LxmFBPncG8Lv39/mAV0uCfFSGER0IITxMfIUD8Xhox2HHnz4hXXBV3FuoUjzufJm5HN6YRda9jCJ2efKYRE8+qahOzLPsKcWV/kXhb5boQwtfqbLvZh3sh9/7ZYll6GNvseh0syebLN1eZFmhcqNFfvc4C3hBC+LtBphfbryfOetZBPU4insnfnkZRbiHeFtiTeEuilnrirFan2jZVLe7iul8CvCsdIE8g3vb4XppW2ZbeSby9XHn9BfF25oY6463lX1KbewG7Zll2bpZOZ5PiclViOqMQ02tSTL9K01cQr9TfnRL+CcSEVMtQ66vagKABoxizLLuTeDvqbOL+sgC4s3CiUDSP+KznD7nt5QPA20MItU7uKvENpdXvaFtDIbyMmCRXE5+7HcC2bbqZgS6D7adDHXeeO85lWXYR8badE4/bt4QQLq7Vaccmn7ShnEK8lfH4YPWyLFubZdlXsiybQzzgvDu3kW0m3v9sxXPDEtMO9HriwzSI92QBJuTqT2fghlb50oaK4x7grwtlf038ku/dvnrdKmeZxavCN+WmNSWd0V9OfPi+c678d8TbZ8XlORR4KMuyjTVi/av8WWoI4TXE5wd1xxpC2Il4++iTDDw4Tic+CymezRaHnv4VsCYtRyN1iu4BekIIz53xhhDGAgcycHmuIj5HeRvx6uAb6Sq70sYfic+qVlZ5bc219YZcPzsTt9V6rEttrS0knarS1cgjwL6DxPTHVG8rMeHPAY4iPoe9qkbT9wBT09VfZTn2IB7UKsu4HhhTSAjbnWVncVTXt7Ms+yDx4Pxqtt8eK328gvis7B1sn0xXAe8tzFJtW7iviTqDuSP9PWqQ6a8nXg2fmWXZ/2RZ9mu2v/vRynHnULYN4KpblmWrsiz7QpZlxxMHS5wy1AxtfRFvhdxEPCMdT7w0fR9xQMCjDBzpciED71f+J/Hh658TLx+d+CA2pOnfJd77fRnxrGYnBn9OM6A89/n/Uh+vJh5o/5ir00U8+7iOeO/+kLQsz7Ltmc9OwNPEA/SebLsffiLVBxx8lm0P9aoNOPhBIe73xK+x5jp2tg04eBWFAQfZtvu6dT/zyZX1EB8+bmTgM59/JG7A7yeeDX+AoQcc7MG2AQfTKAw4yAbeUx/0mU/6vrZ7TpGmHU58wDo5fV7NwIECf08cQXR2bp5665xf6Cs/4OCNaZkGDDjI1f0W8Iu0bK8tTPvX1P9pxAfYU4lnvJfm6lxL3FbfTNyHrqTJAQeF6RdSGB2Vymenbej8tFz7AscBXyrU+8vUxy+AawvTBnyXDBxw8DqqDzgYl5brK2m7mkF89pt/5vPPxIf9U4lXQOcR9619B1nGf6u2jGnax1P/IRfvo2kbeGWa/izw+sIyDVqn2novbj/Ek6T1xP37z4kJ54zcOn02rfu903q/v7AO9iBu56cT//3eiwY5hh6T6p2TYjWqDzi4orBezmfbyN0XAJ8n7lt7E58/3UjhOel267bWxDJexANqll5b0oLfQsycu9faEdIC/x/xIPc4MdlMzU0/gDh0+Q9sP9S63uTzdrYNf74XeGthvoNyfdxFvKJ4bsBBqjOHOPKun/qHWj8GXEaVodaFeepJPruybaj1JgpDrQfbwKq0M9i6OzuVF4da/3NuuVfR+FDrJ8kNta52wBqkjWvJPQwtTBtDHC5aGTSymjiM+ivEg9oG4N+BMYUDQz11zq/SX3Go9Y/JjXrK1ZuZlutXg8R9EtuGNT9BTGqn5Ka/mHiS8Uz6nj9Fk0Ota+1zhWnHEZ9tbEzr5U7SQIpCvUpS/btC+XbfJTGJLWfbUOvvkDsBTXXeRryK+APxWcpbGXjg/QBxP/pdauM20kCCKrHtTDzIf2qQ6VNT22/JxTubuL9UhpjPrrJMg9aptt6L2w/xVuJFqXwz8U7C53LTTyVeff6B+LynMjjrsFydDxOT4FaGHmp9X+rnUeK2vt1Q68I8+eTzZ8T99KG0vOuJJ1l71dr2KlcIIn+SQgiriTvWoPen66kjO770awEPAW/KsuynzdaRqGOf+YiIyI5LyUdEREqn224iIlI6XfmIiEjpiv/Se0egSzkRkeYM2z+GHcqOmHxYs6a5/5Knp6eHvr7O+LXxPMXVGMXVuE6NTXE1ppW4JkyYMHSlYaTbbiIiUjolHxERKZ2Sj4iIlE7JR0RESqfkIyIipVPyERGR0in5iIhI6ZR8RESkdEo+IiJSuh3yFw6a9amzzuSph1Y2Pf/Y8ZM4/WP6L19ERIai5JOzsfdhPpRtaHr++WuHMRgRkR2YbruJiEjplHxERKR0Sj4iIlI6JR8RESmdko+IiJROyUdEREo35FBrM1sEHAusd/dpqexqYN9UZTfgSXefbmaTgfuAX6dpt7j7yWme/YHFwC7AcuAMd8/MbBxwNTAZWA2Yuz9hZgFYABwDbAROdPc7Wl1gERFpv3r+nc9i4D+BKysF7v6uynsz+wzwVK7+g+4+vUo7lwHzgFuIyWcGcB1wDnCDu19iZuekzx8BjgampNdBaf6D6l0wERHpXEPednP3m4Cq//IyXZ0YcFWtNsxsPLCru9/s7hkxkR2XJs8ElqT3SwrlV7p75u63ALuldkREZJRr9RcO3gSsc/cHcmV7m9kvgN8B57v7T4CJQG+uTm8qA9jD3dcCuPtaM3tpKp8IPFJlnu1+R8DM5hGvqnB3enp6mlqYEEJT81V0d3c33XctXV1dI9JuqxRXYzo1Lujc2BRXYzo1rmpaTT4nMPCqZy3wMnd/PD3j+W8zmwpUO6pnQ7Rd9zzuvhBYWKnT19c3RNPVZdlQIdXW399Ps33X0tPTMyLttkpxNaZT44LOjU1xNaaVuCZMmDDM0dTW9Gg3M+sC/pY4WAAAd9/k7o+n9z8HHgReSbxqmZSbfRKwJr1fV7mdlv6uT+W9wF6DzCMiIqNYK0Ot3wLc7+7P3U4zs5eY2Zj0fh/iYIFV6bba02Z2cHpONAe4Ns22DJib3s8tlM8xs2BmBwNPVW7PiYjI6DZk8jGzq4CbgX3NrNfMTkqTZrH9QINDgV+a2V3ANcDJ7l4ZrHAKcAWwknhFdF0qvwQ40sweAI5MnyGOiFuV6l8O/GPjiyciIp0otPqcowNla9Y0d3duwanv57TN65rueH4Yx9kLFzc9/2B2xPvLI0lxNa5TY1NcjRmGZz6tjbpqgH7hQERESqfkIyIipVPyERGR0in5iIhI6ZR8RESkdEo+IiJSOiUfEREpnZKPiIiUTslHRERKp+QjIiKlU/IREZHSKfmIiEjplHxERKR0Sj4iIlI6JR8RESmdko+IiJROyUdEREqn5CMiIqVT8hERkdJ1DVXBzBYBxwLr3X1aKrsQeD/wWKp2nrsvT9POBU4CtgIfdPcVqXwGsAAYA1zh7pek8r2BpcA44A5gtrtvNrOxwJXA/sDjwLvcffUwLLOIiLRZPVc+i4EZVcrnu/v09Koknv2AWcDUNM8XzGyMmY0BPg8cDewHnJDqAlya2poCPEFMXKS/T7j7K4D5qZ6IiOwAhkw+7n4TsKHO9mYCS919k7s/BKwEDkyvle6+yt03E690ZppZAA4HrknzLwGOy7W1JL2/Bjgi1RcRkVFuyNtuNZxmZnOA24Gz3P0JYCJwS65ObyoDeKRQfhDwYuBJd99Spf7EyjzuvsXMnkr1+4qBmNk8YF6qS09PT1MLFEJrua27u7vpvmvp6uoakXZbpbga06lxQefGprga06lxVdNs8rkMuAjI0t/PAO8Dqh29M6pfYWU16jPEtAHcfSGwsFKnr2+7/FSXLKvafN36+/tptu9aenp6RqTdVimuxnRqXNC5sSmuxrQS14QJE4Y5mtqaGu3m7uvcfau7PwtcTrytBvHKZa9c1UnAmhrlfcBuZtZVKB/QVpr+Iuq//SciIh2sqeRjZuNzH98B3J3eLwNmmdnYNIptCnArcBswxcz2NrOdiYMSlrl7BvwIOD7NPxe4NtfW3PT+eOCHqb6IiIxy9Qy1vgo4DOgxs17gAuAwM5tOvA22GvgAgLvfY2YO3AtsAU51962pndOAFcSh1ovc/Z7UxUeApWZ2MfAL4Mup/MvAV81sJfGKZ1bLSysiIh0htPqcowNla9asGbpWFQtOfT+nbV7XdMfzwzjOXri46fkHsyPeXx5JiqtxnRqb4mrMMDzzKW1EsX7hQERESqfkIyIipVPyERGR0in5iIhI6ZR8RESkdEo+IiJSOiUfEREpnZKPiIiUTslHRERKp+QjIiKlU/IREZHSKfmIiEjplHxERKR0Sj4iIlI6JR8RESmdko+IiJROyUdEREqn5CMiIqVT8hERkdJ1DVXBzBYBxwLr3X1aKvt34G+AzcCDwHvd/UkzmwzcB/w6zX6Lu5+c5tkfWAzsAiwHznD3zMzGAVcDk4HVgLn7E2YWgAXAMcBG4ER3v2MYlllERNqsniufxcCMQtn1wDR3/0vg/4Bzc9MedPfp6XVyrvwyYB4wJb0qbZ4D3ODuU4Ab0meAo3N156X5RURkBzBk8nH3m4ANhbLvu/uW9PEWYFKtNsxsPLCru9/s7hlwJXBcmjwTWJLeLymUX+numbvfAuyW2hERkVFuyNtudXgf8bZZxd5m9gvgd8D57v4TYCLQm6vTm8oA9nD3tQDuvtbMXprKJwKPVJlnbTEAM5tHvDrC3enp6WlqQUIITc1X0d3d3XTftXR1dY1Iu61SXI3p1Ligc2NTXI3p1LiqaSn5mNm/AFuAr6eitcDL3P3x9Iznv81sKlDtqJ4N0Xzd87j7QmBhpU5fX9+QsVeTZUOFVFt/fz/N9l1LT0/PiLTbKsXVmE6NCzo3NsXVmFbimjBhwjBHU1vTo93MbC5xIMK706003H2Tuz+e3v+cOBjhlcSrlvytuUnAmvR+XeV2Wvq7PpX3AnsNMo+IiIxiTSUfM5sBfAR4u7tvzJW/xMzGpPf7EAcLrEq31Z42s4PTKLY5wLVptmXA3PR+bqF8jpkFMzsYeKpye05EREa3eoZaXwUcBvSYWS9wAXF021jgejODbUOqDwU+bmZbgK3Aye5eGaxwCtuGWl+XXgCXAG5mJwG/Ad6ZypcTh1mvJA61fm8rCyoiIp1jyOTj7idUKf7yIHW/CXxzkGm3A9OqlD8OHFGlPANOHSo+EREZffQLByIiUjolHxERKZ2Sj4iIlE7JR0RESqfkIyIipVPyERGR0in5iIhI6ZR8RESkdEo+IiJSOiUfEREpnZKPiIiUTslHRERKp+QjIiKlU/IREZHSKfmIiEjplHxERKR0Sj4iIlI6JR8RESmdko+IiJSuq55KZrYIOBZY7+7TUtk44GpgMrAaMHd/wswCsAA4BtgInOjud6R55gLnp2YvdvclqXx/YDGwC7AcOMPds8H6aGmJRUSk7eq98lkMzCiUnQPc4O5TgBvSZ4CjgSnpNQ+4DJ5LVhcABwEHAheY2e5pnstS3cp8M4boQ0RERrG6ko+73wRsKBTPBJak90uA43LlV7p75u63ALuZ2XjgrcD17r4hXb1cD8xI03Z195vdPQOuLLRVrQ8RERnF6rrtNog93H0tgLuvNbOXpvKJwCO5er2prFZ5b5XyWn0MYGbziFdOuDs9PT1NLVAIoan5Krq7u5vuu5aurq4RabdViqsxnRoXdG5siqsxnRpXNa0kn8FUO4JnTZTXzd0XAgsr8/b19TUy+7ZOs4a63U5/fz/N9l1LT0/PiLTbKsXVmE6NCzo3NsXVmFbimjBhwjBHU1sro93WpVtmpL/rU3kvsFeu3iRgzRDlk6qU1+pDRERGsVaSzzJgbno/F7g2Vz7HzIKZHQw8lW6drQCOMrPd00CDo4AVadrTZnZwGik3p9BWtT5ERGQUq3eo9VXAYUCPmfUSR61dAriZnQT8Bnhnqr6cOMx6JXGo9XsB3H2DmV0E3JbqfdzdK4MYTmHbUOvr0osafYiIyChWV/Jx9xMGmXRElboZcOog7SwCFlUpvx2YVqX88Wp9iIjI6KZfOBARkdIp+YiISOmUfEREpHRKPiIiUjolHxERKZ2Sj4iIlE7JR0RESqfkIyIipVPyERGR0in5iIhI6Ubiv1SQJvzHBeezaW1v1Wnd3d309/cPOu/Y8ZM4/WMXj1RoIiLDTsmnQ2xa28uHsuJ/Fptsrj3v/LXDH4+IyEjSbTcRESmdko+IiJROyUdEREqn5CMiIqVT8hERkdIp+YiISOmUfEREpHRN/zsfM9sXuDpXtA/wUWA34P3AY6n8PHdfnuY5FzgJ2Ap80N1XpPIZwAJgDHCFu1+SyvcGlgLjgDuA2e4+xL96ERGRTtd08nH3XwPTAcxsDPAo8G3gvcB8d/90vr6Z7QfMAqYCE4AfmNkr0+TPA0cCvcBtZrbM3e8FLk1tLTWzLxIT12XNxiwiIp1huG67HQE86O4P16gzE1jq7pvc/SFgJXBgeq1091XpqmYpMNPMAnA4cE2afwlw3DDFKyIibTRcP68zC7gq9/k0M5sD3A6c5e5PABOBW3J1elMZwCOF8oOAFwNPuvuWKvUHMLN5wDwAd6enp6ephQghNDVfRXd3d9N9d3d3D/kzOiPRbyu6urra0u9QFFfjOjU2xdWYTo2rmpaTj5ntDLwdODcVXQZcBGTp72eA9wHVjuwZ1a++shr1t+PuC4GFlTp9fX31hj+w8axq83Xr7++n2b5r/XDoSPbbip6enrb0OxTF1bhOjU1xNaaVuCZMmDDM0dQ2HFc+RwN3uPs6gMpfADO7HPhO+tgL7JWbbxKwJr2vVt4H7GZmXenqJ19fRERGseF45nMCuVtuZjY+N+0dwN3p/TJglpmNTaPYpgC3ArcBU8xs73QVNQtY5u4Z8CPg+DT/XODaYYhXRETarKUrHzN7HnGU2gdyxf9mZtOJt8hWV6a5+z1m5sC9wBbgVHffmto5DVhBHGq9yN3vSW19BFhqZhcDvwC+3Eq8IiLSGVpKPu6+kTgwIF82u0b9TwCfqFK+HFhepXwVcTSciIjsQPQLByIiUjolHxERKZ2Sj4iIlE7JR0RESqfkIyIipVPyERGR0in5iIhI6ZR8RESkdEo+IiJSOiUfEREpnZKPiIiUTslHRERKp+QjIiKlU/IREZHSKfmIiEjplHxERKR0Sj4iIlI6JR8RESmdko+IiJSuq9UGzGw18DSwFdji7geY2TjgamAysBowd3/CzAKwADgG2Aic6O53pHbmAuenZi929yWpfH9gMbALsBw4w92zVuMWEZH2Ga4rnze7+3R3PyB9Pge4wd2nADekzwBHA1PSax5wGUBKVhcABwEHAheY2e5pnstS3cp8M4YpZhERaZORuu02E1iS3i8BjsuVX+numbvfAuxmZuOBtwLXu/sGd38CuB6Ykabt6u43p6udK3NtiYjIKNXybTcgA75vZhnwJXdfCOzh7msB3H2tmb001Z0IPJKbtzeV1SrvrVI+gJnNI14d4e709PQ0tSAhhKbmq+ju7m667+7ubthcfr+t6Orqaku/Q1FcjevU2BRXYzo1rmqGI/m80d3XpARzvZndX6NutaN71kT5ACnhLaxM7+vrGyLk6rKstUdJ/f39NNt3f39/W/ptRU9PT1v6HYrialynxqa4GtNKXBMmTBjmaGpr+babu69Jf9cD3yY+s1mXbpmR/q5P1XuBvXKzTwLWDFE+qUq5iIiMYi0lHzN7vpm9sPIeOAq4G1gGzE3V5gLXpvfLgDlmFszsYOCpdHtuBXCUme2eBhocBaxI0542s4PTSLk5ubZERGSUavXKZw/gp2Z2F3Ar8F13/x5wCXCkmT0AHJk+QxwqvQpYCVwO/COAu28ALgJuS6+PpzKAU4Ar0jwPAte1GLOIiLRZS8983H0V8Joq5Y8DR1Qpz4BTB2lrEbCoSvntwLRW4hQRkc6iXzgQEZHSKfmIiEjplHxERKR0Sj4iIlI6JR8RESmdko+IiJROyUdEREqn5CMiIqVT8hERkdIp+YiISOmUfEREpHRKPiIiUjolHxERKZ1PNswyAAAH/klEQVSSj4iIlE7JR0RESqfkIyIipVPyERGR0rX0P5nKn7ZPnXUmTz20sun5x46fxOkfu3gYIxKR0ULJR5q2sfdhPpRtaHr++WuHMRgRGVWaTj5mthdwJbAn8Cyw0N0XmNmFwPuBx1LV89x9eZrnXOAkYCvwQXdfkcpnAAuAMcAV7n5JKt8bWAqMA+4AZrv75mZjFhGRztDKM58twFnu/mrgYOBUM9svTZvv7tPTq5J49gNmAVOBGcAXzGyMmY0BPg8cDewHnJBr59LU1hTgCWLiEhGRUa7p5OPua939jvT+aeA+YGKNWWYCS919k7s/BKwEDkyvle6+Kl3VLAVmmlkADgeuSfMvAY5rNl4REekcw/LMx8wmA68Ffga8ETjNzOYAtxOvjp4gJqZbcrP1si1ZPVIoPwh4MfCku2+pUr/Y/zxgHoC709PT09RyhBCamq+iu7u76b67u7uhyRuKrfTbinaur1q6urrasj6G0qlxQefGprga06lxVdNy8jGzFwDfBM5099+Z2WXARUCW/n4GeB9Q7UiVUf3qK6tRfzvuvhBYWKnT19fX0DI813hWtfm69ff302zf/f39bem3Fe1cX7X09PS0ZX0MpVPjgs6NTXE1ppW4JkyYMMzR1NZS8jGzbmLi+bq7fwvA3dflpl8OfCd97AX2ys0+CViT3lcr7wN2M7OudPWTry8iIqNY08980jOZLwP3uftnc+Xjc9XeAdyd3i8DZpnZ2DSKbQpwK3AbMMXM9jaznYmDEpa5ewb8CDg+zT8XuLbZeEVEpHO0cuXzRmA28CszuzOVnUccrTadeItsNfABAHe/x8wcuJc4Uu5Ud98KYGanASuIQ60Xufs9qb2PAEvN7GLgF8RkJyIio1zTycfdf0r15zLLa8zzCeATVcqXV5vP3VcRR8OJiMgORL/tJiIipVPyERGR0in5iIhI6ZR8RESkdEo+IiJSOiUfEREpnZKPiIiUTslHRERKp+QjIiKlU/IREZHSKfmIiEjplHxERKR0Sj4iIlI6JR8RESmdko+IiJSupf9GW6Rd/uOC89m0trfqtO7ubvr7+wedd+z4SZz+sYtHKjQRqYOSj4xKm9b28qFsQ/WJm2vPO3/t8McjIo3RbTcRESmdko+IiJSu42+7mdkMYAEwBrjC3S9pc0giItKijk4+ZjYG+DxwJNAL3GZmy9z93vZGJtK4T511Jk89tLLp+TVQQnYkHZ18gAOBle6+CsDMlgIzASUfGXU29j48+CCJOmighOxIQpZl7Y5hUGZ2PDDD3f8hfZ4NHOTupxXqzQPmAbj7/qUHKiKyYwhlddTpAw6qrYjtsqW7L3T3A9z9gDRPUy8z+3kr84/US3Eprj/V2BRX6XGVptOTTy+wV+7zJGBNm2IREZFh0unPfG4DppjZ3sCjwCzg79sbkoiItKqjr3zcfQtwGrACuC8W+T0j2OXCEWy7FYqrMYqrcZ0am+JqTKfGtZ2OHnAgIiI7po6+8hERkR2Tko+IiJSu0wcclKYTf8bHzBYBxwLr3X1au+OpMLO9gCuBPYFngYXuvqC9UYGZ/RlwEzCWuG1f4+4XtDeqbdIvdtwOPOrux7Y7HgAzWw08DWwFtqR/rtB2ZrYbcAUwjfjPK97n7je3OaZ9gatzRfsAH3X3z7UppOeY2YeAfyCuq18B73X3P7Y3qtp05cOAn/E5GtgPOMHM9mtvVAAsBma0O4gqtgBnufurgYOBUztkfW0CDnf31wDTgRlmdnCbY8o7gzhwptO82d2nd0riSRYA33P3VwGvoQPWm7v/Oq2n6cD+wEbg220OCzObCHwQOCCdpI4hjgzuaLryiTryZ3zc/SYzm9zOGKpx97XA2vT+aTO7D5hI+9dXBvw+fexOr44YUWNmk4C3AZ8A/qnN4XQ0M9sVOBQ4EcDdNzPk/9JUuiOAB9394XYHknQBu5hZP/A8RsG/h1TyiSYCj+Q+9wIHtSmWUSUlx9cCP2tzKMBzV7E/B14BfN7dOyIu4HPAh4EXtjuQggz4vpllwJfcvROG6u4DPAZ8xcxeQ/w+z3D3Z9ob1gCzgKvaHQSAuz9qZp8GfgP8Afi+u3+/zWENSbfdomo/K9ERZ8ydzMxeAHwTONPdf9fueADcfWu6LTIJONDM2v6szMwqz+1+3u5Yqniju7+OeMv5VDM7tN0BEU+KXwdc5u6vBZ4BzmlvSNuY2c7A24H/ancsAGa2O/FOzd7ABOD5Zvae9kY1NCWfSD/j0yAz6yYmnq+7+7faHU+Ruz8J3EhnPDN7I/D29HB/KXC4mX2tvSFF7r4m/V1PfH5xYHsjAuL+2Ju7ar2GmIw6xdHAHe6+rt2BJG8BHnL3x9y9H/gW8IY2xzQkJZ/ouZ/xSWc1s4BlbY6pY5lZAL4M3Ofun213PBVm9pI0Sgoz24W4U97f3qjA3c9190nuPpm4bf3Q3dt+ZmpmzzezF1beA0cBd7c3KnD33wKPpNFlEJ+vdNJ/o3ICHXLLLfkNcLCZPS/tm0fQAQM0hqLkQ1t+xqcuZnYVcDOwr5n1mtlJ7Y4peSMwm3gGf2d6HdPuoIDxwI/M7JfEE4rr3f07bY6pk+0B/NTM7gJuBb7r7t9rc0wVpwNfT9/ldOCTbY4HADN7HvE/t+yYq/10hXgNcAdxmPVOjIKf2dHP64iISOl05SMiIqVT8hERkdIp+YiISOmUfEREpHRKPiIiUjolHxERKZ2Sj4iIlO7/AyaZAad0u1DZAAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">no_prev_appl</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of No ofPrevious Applications&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One example of a customer having multiple previous applications</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">SK_ID_CURR</span> <span class="o">==</span> <span class="mi">133023</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="s1">&#39;DAYS_DECISION&#39;</span><span class="p">,</span> <span class="s1">&#39;NAME_CONTRACT_STATUS&#39;</span><span class="p">,</span>  
                                                                     <span class="s1">&#39;AMT_APPLICATION&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span><span class="s1">&#39;CODE_REJECT_REASON&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[59]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>DAYS_DECISION</th>
      <th>NAME_CONTRACT_STATUS</th>
      <th>AMT_APPLICATION</th>
      <th>AMT_CREDIT</th>
      <th>CODE_REJECT_REASON</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>22889</th>
      <td>133023</td>
      <td>-369</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>26916</th>
      <td>133023</td>
      <td>-412</td>
      <td>Approved</td>
      <td>42030.0</td>
      <td>39325.5</td>
      <td>XAP</td>
    </tr>
    <tr>
      <th>46145</th>
      <td>133023</td>
      <td>-287</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>127831</th>
      <td>133023</td>
      <td>-300</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>127832</th>
      <td>133023</td>
      <td>-356</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>139251</th>
      <td>133023</td>
      <td>-296</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>139252</th>
      <td>133023</td>
      <td>-271</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>274869</th>
      <td>133023</td>
      <td>-665</td>
      <td>Approved</td>
      <td>15237.0</td>
      <td>15160.5</td>
      <td>XAP</td>
    </tr>
    <tr>
      <th>326508</th>
      <td>133023</td>
      <td>-338</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>332839</th>
      <td>133023</td>
      <td>-295</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>332840</th>
      <td>133023</td>
      <td>-284</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>362763</th>
      <td>133023</td>
      <td>-369</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>362764</th>
      <td>133023</td>
      <td>-352</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>380991</th>
      <td>133023</td>
      <td>-315</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>417386</th>
      <td>133023</td>
      <td>-343</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>417387</th>
      <td>133023</td>
      <td>-342</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>500034</th>
      <td>133023</td>
      <td>-307</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>500035</th>
      <td>133023</td>
      <td>-330</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>518112</th>
      <td>133023</td>
      <td>-355</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
    <tr>
      <th>529842</th>
      <td>133023</td>
      <td>-302</td>
      <td>Refused</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>HC</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary-of-bureau.csv">Summary of bureau.csv<a class="anchor-link" href="#Summary-of-bureau.csv">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[60]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>SK_ID_BUREAU</th>
      <th>CREDIT_ACTIVE</th>
      <th>CREDIT_CURRENCY</th>
      <th>DAYS_CREDIT</th>
      <th>CREDIT_DAY_OVERDUE</th>
      <th>DAYS_CREDIT_ENDDATE</th>
      <th>DAYS_ENDDATE_FACT</th>
      <th>AMT_CREDIT_MAX_OVERDUE</th>
      <th>CNT_CREDIT_PROLONG</th>
      <th>AMT_CREDIT_SUM</th>
      <th>AMT_CREDIT_SUM_DEBT</th>
      <th>AMT_CREDIT_SUM_LIMIT</th>
      <th>AMT_CREDIT_SUM_OVERDUE</th>
      <th>CREDIT_TYPE</th>
      <th>DAYS_CREDIT_UPDATE</th>
      <th>AMT_ANNUITY</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>215354</td>
      <td>5714462</td>
      <td>Closed</td>
      <td>currency 1</td>
      <td>-497</td>
      <td>0</td>
      <td>-153.0</td>
      <td>-153.0</td>
      <td>NaN</td>
      <td>0</td>
      <td>91323.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-131</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>215354</td>
      <td>5714463</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-208</td>
      <td>0</td>
      <td>1075.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>225000.0</td>
      <td>171342.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Credit card</td>
      <td>-20</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>215354</td>
      <td>5714464</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>528.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>464323.5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-16</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>215354</td>
      <td>5714465</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>90000.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Credit card</td>
      <td>-16</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>215354</td>
      <td>5714466</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-629</td>
      <td>0</td>
      <td>1197.0</td>
      <td>NaN</td>
      <td>77674.5</td>
      <td>0</td>
      <td>2700000.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-21</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[61]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(1716428, 17)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Vast majority (99.75%) of customers didn't have any loans that are overdued, so number of times of 30 days over due is not very useful here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">CREDIT_DAY_OVERDUE</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[62]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.997543153572419</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">AMT_CREDIT_MAX_OVERDUE</span><span class="o">.</span><span class="n">notnull</span><span class="p">())</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">DAYS_CREDIT_UPDATE</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">365</span><span class="p">),</span> <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[63]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.16036210082799862</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>to create no_active_loans, total_creditLimit and ave_creditLimit</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">CREDIT_ACTIVE</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[64]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Closed      1079273
Active       630607
Sold           6527
Bad debt         21
Name: CREDIT_ACTIVE, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Most loans use currency 1 so we will use this currency for credit limit calculation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">CREDIT_CURRENCY</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[65]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>currency 1    1715020
currency 2       1224
currency 3        174
currency 4         10
Name: CREDIT_CURRENCY, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>calculate the total credit limit per customer</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bureau_info</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">][(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">CREDIT_ACTIVE</span> <span class="o">==</span> <span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">CREDIT_CURRENCY</span> <span class="o">==</span> <span class="s1">&#39;currency 1&#39;</span><span class="p">)</span>
                                <span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">AMT_CREDIT_SUM</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">bureau_info</span> <span class="o">=</span> <span class="n">bureau_info</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">bureau_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">bureau_info</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[66]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>AMT_CREDIT_SUM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100001</td>
      <td>884025.000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100002</td>
      <td>481988.565</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100003</td>
      <td>810000.000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100005</td>
      <td>598626.000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100008</td>
      <td>267606.000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bureau_info</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[67]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(251792, 2)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>calculate the total no of loans per customer</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bureau_info_no_loans</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">][(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">CREDIT_ACTIVE</span> <span class="o">==</span> <span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">CREDIT_CURRENCY</span> <span class="o">==</span> <span class="s1">&#39;currency 1&#39;</span><span class="p">)</span>
                                <span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_BUREAU</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">bureau_info_no_loans</span> <span class="o">=</span> <span class="n">bureau_info_no_loans</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">bureau_info_no_loans</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">bureau_info_no_loans</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[68]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>SK_ID_BUREAU</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100001</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100002</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100003</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100005</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100008</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bureau_info_no_loans</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[69]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(251792, 2)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>merge the two data sets</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bureau_info</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">bureau_info</span><span class="p">,</span> <span class="n">bureau_info_no_loans</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span>
<span class="n">bureau_info</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;AMT_CREDIT_SUM&#39;</span><span class="p">:</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;SK_ID_BUREAU&#39;</span><span class="p">:</span><span class="s1">&#39;no_of_loans&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">bureau_info</span><span class="p">[</span><span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bureau_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;total_creditLimit/no_of_loans&#39;</span><span class="p">)</span>
<span class="n">bureau_info</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[70]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>total_creditLimit</th>
      <th>no_of_loans</th>
      <th>ave_creditLimit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100001</td>
      <td>884025.000</td>
      <td>3</td>
      <td>294675.0000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100002</td>
      <td>481988.565</td>
      <td>2</td>
      <td>240994.2825</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100003</td>
      <td>810000.000</td>
      <td>1</td>
      <td>810000.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100005</td>
      <td>598626.000</td>
      <td>2</td>
      <td>299313.0000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100008</td>
      <td>267606.000</td>
      <td>1</td>
      <td>267606.0000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Merge this dataset with the train and test data set later.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">bureau_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">bureau_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There is about 29% missing data for the 3 newly created features.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">total_creditLimit</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">test</span><span class="o">.</span><span class="n">total_creditLimit</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[72]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(0.2939211930630124, 0.288835548990645)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We fill NA with 0.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[73]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_creditLimit</th>
      <th>no_of_loans</th>
      <th>ave_creditLimit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>481988.565</td>
      <td>2.0</td>
      <td>240994.2825</td>
    </tr>
    <tr>
      <th>1</th>
      <td>810000.000</td>
      <td>1.0</td>
      <td>810000.0000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.0000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[74]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_creditLimit</th>
      <th>no_of_loans</th>
      <th>ave_creditLimit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>884025.00</td>
      <td>3.0</td>
      <td>294675.000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>598626.00</td>
      <td>2.0</td>
      <td>299313.000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>864721.08</td>
      <td>5.0</td>
      <td>172944.216</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.00</td>
      <td>0.0</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="credit_card_balance.csv">credit_card_balance.csv<a class="anchor-link" href="#credit_card_balance.csv">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[75]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>MONTHS_BALANCE</th>
      <th>AMT_BALANCE</th>
      <th>AMT_CREDIT_LIMIT_ACTUAL</th>
      <th>AMT_DRAWINGS_ATM_CURRENT</th>
      <th>AMT_DRAWINGS_CURRENT</th>
      <th>AMT_DRAWINGS_OTHER_CURRENT</th>
      <th>AMT_DRAWINGS_POS_CURRENT</th>
      <th>AMT_INST_MIN_REGULARITY</th>
      <th>...</th>
      <th>AMT_RECIVABLE</th>
      <th>AMT_TOTAL_RECEIVABLE</th>
      <th>CNT_DRAWINGS_ATM_CURRENT</th>
      <th>CNT_DRAWINGS_CURRENT</th>
      <th>CNT_DRAWINGS_OTHER_CURRENT</th>
      <th>CNT_DRAWINGS_POS_CURRENT</th>
      <th>CNT_INSTALMENT_MATURE_CUM</th>
      <th>NAME_CONTRACT_STATUS</th>
      <th>SK_DPD</th>
      <th>SK_DPD_DEF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2562384</td>
      <td>378907</td>
      <td>-6</td>
      <td>56.970</td>
      <td>135000</td>
      <td>0.0</td>
      <td>877.5</td>
      <td>0.0</td>
      <td>877.5</td>
      <td>1700.325</td>
      <td>...</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>35.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2582071</td>
      <td>363914</td>
      <td>-1</td>
      <td>63975.555</td>
      <td>45000</td>
      <td>2250.0</td>
      <td>2250.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2250.000</td>
      <td>...</td>
      <td>64875.555</td>
      <td>64875.555</td>
      <td>1.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>69.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1740877</td>
      <td>371185</td>
      <td>-7</td>
      <td>31815.225</td>
      <td>450000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2250.000</td>
      <td>...</td>
      <td>31460.085</td>
      <td>31460.085</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1389973</td>
      <td>337855</td>
      <td>-4</td>
      <td>236572.110</td>
      <td>225000</td>
      <td>2250.0</td>
      <td>2250.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>11795.760</td>
      <td>...</td>
      <td>233048.970</td>
      <td>233048.970</td>
      <td>1.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1891521</td>
      <td>126868</td>
      <td>-1</td>
      <td>453919.455</td>
      <td>450000</td>
      <td>0.0</td>
      <td>11547.0</td>
      <td>0.0</td>
      <td>11547.0</td>
      <td>22924.890</td>
      <td>...</td>
      <td>453919.455</td>
      <td>453919.455</td>
      <td>0.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>101.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 23 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>we can use <em>AMT_BALANCE</em>, <em>AMT_CREDIT_LIMIT_ACTUAL</em> and <em>AMT_PAYMENT_TOTAL_CURRENT</em> to calculate the total credit limit, utilization and payment ratio.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[76]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SK_ID_PREV                    0.000000
SK_ID_CURR                    0.000000
MONTHS_BALANCE                0.000000
AMT_BALANCE                   0.000000
AMT_CREDIT_LIMIT_ACTUAL       0.000000
AMT_DRAWINGS_ATM_CURRENT      0.195249
AMT_DRAWINGS_CURRENT          0.000000
AMT_DRAWINGS_OTHER_CURRENT    0.195249
AMT_DRAWINGS_POS_CURRENT      0.195249
AMT_INST_MIN_REGULARITY       0.079482
AMT_PAYMENT_CURRENT           0.199981
AMT_PAYMENT_TOTAL_CURRENT     0.000000
AMT_RECEIVABLE_PRINCIPAL      0.000000
AMT_RECIVABLE                 0.000000
AMT_TOTAL_RECEIVABLE          0.000000
CNT_DRAWINGS_ATM_CURRENT      0.195249
CNT_DRAWINGS_CURRENT          0.000000
CNT_DRAWINGS_OTHER_CURRENT    0.195249
CNT_DRAWINGS_POS_CURRENT      0.195249
CNT_INSTALMENT_MATURE_CUM     0.079482
NAME_CONTRACT_STATUS          0.000000
SK_DPD                        0.000000
SK_DPD_DEF                    0.000000
dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[77]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Active           3698436
Completed         128918
Signed             11058
Demand              1365
Sent proposal        513
Refused               17
Approved               5
Name: NAME_CONTRACT_STATUS, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>some accounts have 0 credit limit, so we have to exclude them.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">creditCard_info</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">][(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">MONTHS_BALANCE</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">24</span><span class="p">)</span> <span class="o">&amp;</span> 
                                                  <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">==</span><span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span>
                                                 <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">AMT_CREDIT_LIMIT_ACTUAL</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)[</span><span class="s1">&#39;AMT_BALANCE&#39;</span><span class="p">,</span> 
                                                                                 <span class="s1">&#39;AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>some accounts have 0 credit limit, which is strange...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[80]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[80]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>AMT_BALANCE</th>
      <th>AMT_CREDIT_LIMIT_ACTUAL</th>
      <th>AMT_PAYMENT_TOTAL_CURRENT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100006</td>
      <td>0.0</td>
      <td>1620000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100011</td>
      <td>0.0</td>
      <td>2970000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100013</td>
      <td>0.0</td>
      <td>1305000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100021</td>
      <td>0.0</td>
      <td>4725000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100023</td>
      <td>0.0</td>
      <td>1080000</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>calculate <strong>utilization_CC</strong> and <strong>payment_ratio_CC</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">creditCard_info</span><span class="p">[</span><span class="s1">&#39;utilization_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">creditCard_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_BALANCE/AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">)</span>
<span class="n">creditCard_info</span><span class="p">[</span><span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">creditCard_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT/AMT_BALANCE&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>set <strong>payment_ratio_CC</strong> to 1 if it is NaN (when there is no unpaid balance).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[82]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">payment_ratio_CC</span><span class="o">.</span><span class="n">isnull</span><span class="p">(),</span> <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1">#creditCard_info[&#39;payment_ratio_CC&#39;] = creditCard_info[&#39;payment_ratio_CC&#39;].fillna(1)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[83]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SK_ID_CURR                   0
AMT_BALANCE                  0
AMT_CREDIT_LIMIT_ACTUAL      0
AMT_PAYMENT_TOTAL_CURRENT    0
utilization_CC               0
payment_ratio_CC             0
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>drop un-necessory columns</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AMT_BALANCE&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">creditCard_info</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">:</span><span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#ceiling the payment_ratio_CC to 1</span>
<span class="n">creditCard_info</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">payment_ratio_CC</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">payment_ratio_CC</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[86]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.0</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">creditCard_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">creditCard_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are about 75% missing data - 75% customers don't have credit card with Home Credit Group.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">total_creditLimit_CC</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[88]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.7482561599422459</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We need to decide the strategy for imputing the missing data - 0 doesn't seem to be a good choice here. We will leave this problem for hyperparameter tuning in grid serach step.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary-of-install_payment.csv">Summary of install_payment.csv<a class="anchor-link" href="#Summary-of-install_payment.csv">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[89]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>NUM_INSTALMENT_VERSION</th>
      <th>NUM_INSTALMENT_NUMBER</th>
      <th>DAYS_INSTALMENT</th>
      <th>DAYS_ENTRY_PAYMENT</th>
      <th>AMT_INSTALMENT</th>
      <th>AMT_PAYMENT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1054186</td>
      <td>161674</td>
      <td>1.0</td>
      <td>6</td>
      <td>-1180.0</td>
      <td>-1187.0</td>
      <td>6948.360</td>
      <td>6948.360</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1330831</td>
      <td>151639</td>
      <td>0.0</td>
      <td>34</td>
      <td>-2156.0</td>
      <td>-2156.0</td>
      <td>1716.525</td>
      <td>1716.525</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2085231</td>
      <td>193053</td>
      <td>2.0</td>
      <td>1</td>
      <td>-63.0</td>
      <td>-63.0</td>
      <td>25425.000</td>
      <td>25425.000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2452527</td>
      <td>199697</td>
      <td>1.0</td>
      <td>3</td>
      <td>-2418.0</td>
      <td>-2426.0</td>
      <td>24350.130</td>
      <td>24350.130</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2714724</td>
      <td>167756</td>
      <td>1.0</td>
      <td>2</td>
      <td>-1383.0</td>
      <td>-1366.0</td>
      <td>2165.040</td>
      <td>2160.585</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">][</span><span class="s1">&#39;days_past_due&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT&#39;</span><span class="p">)</span>
<span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">][</span><span class="s1">&#39;past_due_times&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">][</span><span class="s1">&#39;days_past_due&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">past_due_info</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">][</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">][</span><span class="s1">&#39;DAYS_INSTALMENT&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">730</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)[</span><span class="s1">&#39;past_due_times&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> 
<span class="n">past_due_info</span> <span class="o">=</span> <span class="n">past_due_info</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">past_due_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>About 36% customers had past due events in the past 2 years.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">past_due_info</span><span class="p">[</span><span class="n">past_due_info</span><span class="p">[</span><span class="s1">&#39;past_due_times&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">past_due_info</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[92]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.3634009215962537</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[93]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">past_due_info</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[93]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>past_due_times</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100002</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100003</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100004</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100005</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100006</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>merge with the main data sets</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">past_due_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">past_due_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>About 18% missing data here. We will leave the imputation to gridsearch step.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">past_due_times</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[95]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.18039354689750936</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Feature-Engineering">Feature Engineering<a class="anchor-link" href="#Feature-Engineering">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Features-created-in-the-EDA-step">Features created in the EDA step<a class="anchor-link" href="#Features-created-in-the-EDA-step">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">9</span><span class="p">:]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[96]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;no_prev_appl&#39;, &#39;no_approved_prev_appl&#39;, &#39;total_creditLimit&#39;,
       &#39;no_of_loans&#39;, &#39;ave_creditLimit&#39;, &#39;total_creditLimit_CC&#39;,
       &#39;utilization_CC&#39;, &#39;payment_ratio_CC&#39;, &#39;past_due_times&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Based on domain knowledge, we have created the following new features from the files other than the two application data sets:</p>
<ol>
<li>total_creditLimit: from bureau.csv, all the credit limits of all the active accounts for a customer;</li>
<li>ave_creditLimit: from bureau.csv, average credit limits of all the active accounts for a customer;</li>
<li>no_of_loans: from bureau.csv, total number of active loans for a customer;</li>
<li>total_creditLimit_CC: from credit_card_balance.csv, total credit limit of all the active credit cards for a customer;</li>
<li>utilization_CC: from credit_card_balance.csv, average ratio of total balance to total credit limit for all active accounts for a customer in the past 12 months;</li>
<li>payment_ratio_CC: from credit_card_balance.csv, to calculate the average ratio of total payment to total balance in the past 12 months;</li>
<li>past_due_flag: from install_payment.csv,  the number of times the customer paid the installment loans after the due date in the past 24 months;</li>
<li>no_prev_appl: from previous_application.csv,  no of previous applications in the past 12 months .</li>
<li>no_of_approved_prev_appl: from previous_application.csv, no of approved previous applications in the past 12 months.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check the corelation between the newly created features and the target variable:</p>
<ul>
<li>utilization_CC is a very strong feature;</li>
<li>past_due_times, no_of_loans and no_prev_appl may also help.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">[[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">,</span> <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span> <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span> <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
       <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
       <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span> <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span> <span class="s1">&#39;past_due_times&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">corr</span><span class="p">()[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[97]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>payment_ratio_CC        -0.126491
ave_creditLimit         -0.022718
total_creditLimit_CC    -0.019050
total_creditLimit       -0.005492
no_approved_prev_appl    0.006952
no_of_loans              0.043632
no_prev_appl             0.047260
past_due_times           0.066971
utilization_CC           0.149147
TARGET                   1.000000
Name: TARGET, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Develop-More-New-Features-manually">Develop More New Features manually<a class="anchor-link" href="#Develop-More-New-Features-manually">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>develop some more new features:</p>
<ul>
<li>credit_income_ratio</li>
<li>annuity_income_ratio</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[98]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_CREDIT/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#credit to income ratio</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_ANNUITY/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#annuity to income ratio</span>

<span class="n">test</span><span class="p">[</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_CREDIT/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#credit to income ratio</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_ANNUITY/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#annuity to income ratio</span>

<span class="c1"># some more new features</span>

<span class="n">train</span><span class="p">[</span><span class="s1">&#39;income_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;credit_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">AMT_CREDIT</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;annuity_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">AMT_ANNUITY</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;fam_member_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">CNT_FAM_MEMBERS</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;child_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">CNT_CHILDREN</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;goods_prices_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">AMT_GOODS_PRICE</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>                    
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;car_age_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">OWN_CAR_AGE</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 

<span class="n">test</span><span class="p">[</span><span class="s1">&#39;income_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;credit_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">AMT_CREDIT</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;annuity_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">AMT_ANNUITY</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;fam_member_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">CNT_FAM_MEMBERS</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;child_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">CNT_CHILDREN</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;goods_prices_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">AMT_GOODS_PRICE</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>                    
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;car_age_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">OWN_CAR_AGE</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>



<span class="c1"># from Nishad and Naimesh</span>
<span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;DAYS&#39;</span><span class="p">)]]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span>
    <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;DAYS&#39;</span><span class="p">)]])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">365243</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span><span class="o">/</span><span class="mi">365</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;income_credit_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">AMT_CREDIT</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;fam_member_income&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">CNT_FAM_MEMBERS</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;ann_incom_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">AMT_ANNUITY</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;new_employ_to_birth_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="o">.</span><span class="n">DAYS_EMPLOYED</span> <span class="o">/</span> <span class="n">train</span><span class="o">.</span><span class="n">DAYS_BIRTH</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;new_credit_to_annuity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;new_credit_to_goods_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;new_car_to_birth_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="p">[</span><span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;new_car_to_emp_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="p">[</span><span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;new_inc_per_child&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">test</span><span class="p">[</span><span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;DAYS&#39;</span><span class="p">)]]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span>
    <span class="n">test</span><span class="p">[</span><span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;DAYS&#39;</span><span class="p">)]])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">365243</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span><span class="o">/</span><span class="mi">365</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;income_credit_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">AMT_CREDIT</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;fam_member_income&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">CNT_FAM_MEMBERS</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;ann_incom_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">AMT_ANNUITY</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;new_employ_to_birth_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="o">.</span><span class="n">DAYS_EMPLOYED</span> <span class="o">/</span> <span class="n">test</span><span class="o">.</span><span class="n">DAYS_BIRTH</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;new_credit_to_annuity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;new_credit_to_goods_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;new_car_to_birth_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="p">[</span><span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;new_car_to_emp_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="p">[</span><span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;new_inc_per_child&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Processing-pipeline">Processing pipeline<a class="anchor-link" href="#Processing-pipeline">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Create a class to select numerical or categorical columns </span>
<span class="c1"># since Scikit-Learn doesn&#39;t handle DataFrames yet</span>
<span class="k">class</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span> <span class="o">=</span> <span class="n">attribute_names</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Identify the numeric features we wish to consider. </span>
<span class="n">num_attribs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>  <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span><span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">]</span>

<span class="n">num_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;selector&#39;</span><span class="p">,</span> <span class="n">DataFrameSelector</span><span class="p">(</span><span class="n">num_attribs</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;std_scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">])</span>
<span class="c1"># Identify the categorical features we wish to consider.</span>
<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span><span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">]</span>
<span class="n">cat_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;selector&#39;</span><span class="p">,</span> <span class="n">DataFrameSelector</span><span class="p">(</span><span class="n">cat_attribs</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">))</span>
    <span class="p">])</span>

<span class="n">data_prep_pipeline</span> <span class="o">=</span> <span class="n">FeatureUnion</span><span class="p">(</span><span class="n">transformer_list</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;num_pipeline&quot;</span><span class="p">,</span> <span class="n">num_pipeline</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;cat_pipeline&quot;</span><span class="p">,</span> <span class="n">cat_pipeline</span><span class="p">),</span>
    <span class="p">])</span>
              

    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[101]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[&#39;SK_ID_CURR&#39;,
 &#39;TARGET&#39;,
 &#39;NAME_CONTRACT_TYPE&#39;,
 &#39;CODE_GENDER&#39;,
 &#39;FLAG_OWN_CAR&#39;,
 &#39;FLAG_OWN_REALTY&#39;,
 &#39;CNT_CHILDREN&#39;,
 &#39;AMT_INCOME_TOTAL&#39;,
 &#39;AMT_CREDIT&#39;,
 &#39;AMT_ANNUITY&#39;,
 &#39;AMT_GOODS_PRICE&#39;,
 &#39;NAME_TYPE_SUITE&#39;,
 &#39;NAME_INCOME_TYPE&#39;,
 &#39;NAME_EDUCATION_TYPE&#39;,
 &#39;NAME_FAMILY_STATUS&#39;,
 &#39;NAME_HOUSING_TYPE&#39;,
 &#39;REGION_POPULATION_RELATIVE&#39;,
 &#39;DAYS_BIRTH&#39;,
 &#39;DAYS_EMPLOYED&#39;,
 &#39;DAYS_REGISTRATION&#39;,
 &#39;DAYS_ID_PUBLISH&#39;,
 &#39;OWN_CAR_AGE&#39;,
 &#39;FLAG_MOBIL&#39;,
 &#39;FLAG_EMP_PHONE&#39;,
 &#39;FLAG_WORK_PHONE&#39;,
 &#39;FLAG_CONT_MOBILE&#39;,
 &#39;FLAG_PHONE&#39;,
 &#39;FLAG_EMAIL&#39;,
 &#39;OCCUPATION_TYPE&#39;,
 &#39;CNT_FAM_MEMBERS&#39;,
 &#39;REGION_RATING_CLIENT&#39;,
 &#39;REGION_RATING_CLIENT_W_CITY&#39;,
 &#39;WEEKDAY_APPR_PROCESS_START&#39;,
 &#39;HOUR_APPR_PROCESS_START&#39;,
 &#39;REG_REGION_NOT_LIVE_REGION&#39;,
 &#39;REG_REGION_NOT_WORK_REGION&#39;,
 &#39;LIVE_REGION_NOT_WORK_REGION&#39;,
 &#39;REG_CITY_NOT_LIVE_CITY&#39;,
 &#39;REG_CITY_NOT_WORK_CITY&#39;,
 &#39;LIVE_CITY_NOT_WORK_CITY&#39;,
 &#39;ORGANIZATION_TYPE&#39;,
 &#39;EXT_SOURCE_1&#39;,
 &#39;EXT_SOURCE_2&#39;,
 &#39;EXT_SOURCE_3&#39;,
 &#39;APARTMENTS_AVG&#39;,
 &#39;BASEMENTAREA_AVG&#39;,
 &#39;YEARS_BEGINEXPLUATATION_AVG&#39;,
 &#39;YEARS_BUILD_AVG&#39;,
 &#39;COMMONAREA_AVG&#39;,
 &#39;ELEVATORS_AVG&#39;,
 &#39;ENTRANCES_AVG&#39;,
 &#39;FLOORSMAX_AVG&#39;,
 &#39;FLOORSMIN_AVG&#39;,
 &#39;LANDAREA_AVG&#39;,
 &#39;LIVINGAPARTMENTS_AVG&#39;,
 &#39;LIVINGAREA_AVG&#39;,
 &#39;NONLIVINGAPARTMENTS_AVG&#39;,
 &#39;NONLIVINGAREA_AVG&#39;,
 &#39;APARTMENTS_MODE&#39;,
 &#39;BASEMENTAREA_MODE&#39;,
 &#39;YEARS_BEGINEXPLUATATION_MODE&#39;,
 &#39;YEARS_BUILD_MODE&#39;,
 &#39;COMMONAREA_MODE&#39;,
 &#39;ELEVATORS_MODE&#39;,
 &#39;ENTRANCES_MODE&#39;,
 &#39;FLOORSMAX_MODE&#39;,
 &#39;FLOORSMIN_MODE&#39;,
 &#39;LANDAREA_MODE&#39;,
 &#39;LIVINGAPARTMENTS_MODE&#39;,
 &#39;LIVINGAREA_MODE&#39;,
 &#39;NONLIVINGAPARTMENTS_MODE&#39;,
 &#39;NONLIVINGAREA_MODE&#39;,
 &#39;APARTMENTS_MEDI&#39;,
 &#39;BASEMENTAREA_MEDI&#39;,
 &#39;YEARS_BEGINEXPLUATATION_MEDI&#39;,
 &#39;YEARS_BUILD_MEDI&#39;,
 &#39;COMMONAREA_MEDI&#39;,
 &#39;ELEVATORS_MEDI&#39;,
 &#39;ENTRANCES_MEDI&#39;,
 &#39;FLOORSMAX_MEDI&#39;,
 &#39;FLOORSMIN_MEDI&#39;,
 &#39;LANDAREA_MEDI&#39;,
 &#39;LIVINGAPARTMENTS_MEDI&#39;,
 &#39;LIVINGAREA_MEDI&#39;,
 &#39;NONLIVINGAPARTMENTS_MEDI&#39;,
 &#39;NONLIVINGAREA_MEDI&#39;,
 &#39;FONDKAPREMONT_MODE&#39;,
 &#39;HOUSETYPE_MODE&#39;,
 &#39;TOTALAREA_MODE&#39;,
 &#39;WALLSMATERIAL_MODE&#39;,
 &#39;EMERGENCYSTATE_MODE&#39;,
 &#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;,
 &#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;,
 &#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;,
 &#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;,
 &#39;DAYS_LAST_PHONE_CHANGE&#39;,
 &#39;FLAG_DOCUMENT_2&#39;,
 &#39;FLAG_DOCUMENT_3&#39;,
 &#39;FLAG_DOCUMENT_4&#39;,
 &#39;FLAG_DOCUMENT_5&#39;,
 &#39;FLAG_DOCUMENT_6&#39;,
 &#39;FLAG_DOCUMENT_7&#39;,
 &#39;FLAG_DOCUMENT_8&#39;,
 &#39;FLAG_DOCUMENT_9&#39;,
 &#39;FLAG_DOCUMENT_10&#39;,
 &#39;FLAG_DOCUMENT_11&#39;,
 &#39;FLAG_DOCUMENT_12&#39;,
 &#39;FLAG_DOCUMENT_13&#39;,
 &#39;FLAG_DOCUMENT_14&#39;,
 &#39;FLAG_DOCUMENT_15&#39;,
 &#39;FLAG_DOCUMENT_16&#39;,
 &#39;FLAG_DOCUMENT_17&#39;,
 &#39;FLAG_DOCUMENT_18&#39;,
 &#39;FLAG_DOCUMENT_19&#39;,
 &#39;FLAG_DOCUMENT_20&#39;,
 &#39;FLAG_DOCUMENT_21&#39;,
 &#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;,
 &#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;,
 &#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;,
 &#39;AMT_REQ_CREDIT_BUREAU_MON&#39;,
 &#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;,
 &#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Split the provided training data into training and validationa and test</span>
<span class="c1"># The kaggle evaluation test set has no labels</span>
<span class="c1">#</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="c1"># just selected a few features for a baseline experiment</span>
<span class="n">selected_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>  <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
    <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span><span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span><span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span><span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">][</span><span class="n">selected_features</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_train&quot;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_kaggle_test</span><span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_test&quot;</span><span class="p">][</span><span class="n">selected_features</span><span class="p">]</span>
<span class="c1"># y_test = datasets[&quot;application_test&quot;][&#39;TARGET&#39;]   #why no  TARGET?!! (hint: kaggle competition)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X train           shape: </span><span class="si">{X_train.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X validation      shape: </span><span class="si">{X_valid.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X test            shape: </span><span class="si">{X_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X X_kaggle_test   shape: </span><span class="si">{X_kaggle_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X train           shape: (222176, 14)
X validation      shape: (46127, 14)
X test            shape: (39208, 14)
X X_kaggle_test   shape: (48744, 14)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Baseline-Model">Baseline Model<a class="anchor-link" href="#Baseline-Model">&#182;</a></h1><p>To get a baseline, we will use some of the features after being preprocessed through the pipeline.
The baseline model is a logistic regression model</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">pct</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">expLog</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">expLog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;exp_name&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Train Acc&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Valid Acc&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Test  Acc&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Train AUC&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Valid AUC&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Test  AUC&quot;</span>
                                  <span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[105]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span> 
np.random.seed(42)
full_pipeline_with_predictor = Pipeline([
        (&quot;preparation&quot;, data_prep_pipeline),
        (&quot;linear&quot;, LogisticRegression(n_jobs = -1))
    ])
model = full_pipeline_with_predictor.fit(X_train, y_train)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wall time: 10min 5s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span>

<span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[106]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.92</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-metrics">Evaluation metrics<a class="anchor-link" href="#Evaluation-metrics">&#182;</a></h2><p>Submissions are evaluated on <a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">area under the ROC curve</a> between the predicted probability and the observed target.</p>
<p>The SkLearn <code>roc_auc_score</code> function computes the area under the receiver operating characteristic (ROC) curve, which is also denoted by AUC or AUROC. By computing the area under the roc curve, the curve information is summarized in one number.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="mf">0.75</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[107]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_auc_score</span>
<span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[107]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.7359284437419668</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># baseline_scores = cross_val_score(model, X_train, y_train, scoring = &#39;roc_auc&#39;, cv=30)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[109]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">exp_name</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;Baseline_{len(selected_features)}_features&quot;</span>
<span class="n">expLog</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">expLog</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="s2">&quot;</span><span class="si">{exp_name}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
               <span class="p">[</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span> 
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)),</span>
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])],</span>
    <span class="mi">4</span><span class="p">))</span> 
<span class="n">expLog</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[109]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train AUC</th>
      <th>Valid AUC</th>
      <th>Test  AUC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline_14_features</td>
      <td>0.9198</td>
      <td>0.9192</td>
      <td>0.9159</td>
      <td>0.7359</td>
      <td>0.7361</td>
      <td>0.7362</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Submission-File-Prep">Submission File Prep<a class="anchor-link" href="#Submission-File-Prep">&#182;</a></h2><p>For each SK_ID_CURR in the test set, you must predict a probability for the TARGET variable. The file should contain a header and have the following format:</p>
<div class="highlight"><pre><span></span><span class="n">SK_ID_CURR</span><span class="p">,</span><span class="n">TARGET</span>
<span class="mi">100001</span><span class="p">,</span><span class="mf">0.1</span>
<span class="mi">100005</span><span class="p">,</span><span class="mf">0.9</span>
<span class="mi">100013</span><span class="p">,</span><span class="mf">0.2</span>
<span class="n">etc</span><span class="o">.</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_kaggle_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">logit_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">fit_pipeline</span><span class="p">,</span> <span class="n">app_train_subset</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
<span class="n">log_reg_pred</span> <span class="o">=</span> <span class="n">fit_pipeline</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">logit_score_train</span> <span class="o">=</span> <span class="n">logit_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="n">pct</span><span class="p">(</span><span class="n">logit_score_train</span><span class="p">),</span><span class="s2">&quot;Untuned LogisticRegression&quot;</span><span class="p">]</span>
<span class="n">results</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">exp_name</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;Baseline_{len(selected_features)}&quot;</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Submission dataframe</span>
<span class="n">submit_df</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_test&quot;</span><span class="p">][[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit_df</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_class_scores</span>

<span class="n">submit_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">submit_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;submission.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Benchmark-Model">Benchmark Model<a class="anchor-link" href="#Benchmark-Model">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Set-up-a-pipeline-that-incorporates-feature-engineering">Set up a pipeline that incorporates feature engineering<a class="anchor-link" href="#Set-up-a-pipeline-that-incorporates-feature-engineering">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="k">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span>

<span class="c1"># Create a class to select numerical or categorical columns </span>
<span class="c1"># since Scikit-Learn doesn&#39;t handle DataFrames yet</span>
<span class="k">class</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span> <span class="o">=</span> <span class="n">attribute_names</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    
<span class="k">class</span> <span class="nc">Feature_engineering</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span> <span class="c1"># no *args or **kargs  , features=None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
<span class="c1">#         pass</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>  <span class="c1"># nothing else to do</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="c1">#         df = pd.DataFrame(columns = None)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_CREDIT/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#credit to income ratio</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_ANNUITY/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#annuity to income ratio        </span>
        
        <span class="k">return</span> <span class="n">df</span>        
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># # Identify the numeric features we wish to consider. </span>

<span class="n">num_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span><span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span> <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span><span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
               <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span> <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span> <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
               <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>  <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span> <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>


<span class="n">num_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;selector&#39;</span><span class="p">,</span> <span class="n">DataFrameSelector</span><span class="p">(</span><span class="n">num_attribs</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;std_scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">])</span>

<span class="c1"># Identify the categorical features we wish to consider.</span>
<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span><span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
              <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
              <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span> <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span> <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">]</span>

<span class="n">cat_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;selector&#39;</span><span class="p">,</span> <span class="n">DataFrameSelector</span><span class="p">(</span><span class="n">cat_attribs</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">))</span>
    <span class="p">])</span>


<span class="c1"># feature_eng = Pipeline([</span>
<span class="c1">#     (&#39;feature_eng&#39;, Feature_engineering())</span>
<span class="c1"># ])</span>


<span class="c1"># num_cat_pipeline = ColumnTransformer([</span>
<span class="c1">#     (&#39;num_pipeline&#39;, num_pipeline, num_attribs),</span>
<span class="c1">#     (&#39;cat_pipeline&#39;, cat_pipeline, cat_attribs),</span>
<span class="c1"># ], remainder = &#39;drop&#39; )</span>


<span class="c1"># data_prep_pipeline = Pipeline([</span>
<span class="c1">#     (&#39;feature_eng&#39;, feature_eng),</span>
<span class="c1">#     (&#39;num_cat_pipe&#39;, num_cat_pipeline)        </span>
<span class="c1"># ])    </span>

<span class="n">data_prep_pipeline</span> <span class="o">=</span> <span class="n">FeatureUnion</span><span class="p">(</span><span class="n">transformer_list</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;num_pipeline&quot;</span><span class="p">,</span> <span class="n">num_pipeline</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;cat_pipeline&quot;</span><span class="p">,</span> <span class="n">cat_pipeline</span><span class="p">),</span>
    <span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Split the provided training data into training and validationa and test</span>
<span class="c1"># The kaggle evaluation test set has no labels</span>
<span class="c1">#</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="c1"># just selected a few features for a baseline experiment</span>
<span class="n">selected_features</span> <span class="o">=</span> <span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs</span>
<span class="n">X_train</span><span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">selected_features</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_kaggle_test</span><span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">selected_features</span><span class="p">]</span>
<span class="c1"># y_test = datasets[&quot;application_test&quot;][&#39;TARGET&#39;]   #why no  TARGET?!! (hint: kaggle competition)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X train           shape: </span><span class="si">{X_train.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X validation      shape: </span><span class="si">{X_valid.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X test            shape: </span><span class="si">{X_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X X_kaggle_test   shape: </span><span class="si">{X_kaggle_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Logistic-Regression-Model">Logistic Regression Model<a class="anchor-link" href="#Logistic-Regression-Model">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">expLog</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">expLog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;exp_name&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Train Acc&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Valid Acc&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Test  Acc&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Train AUC&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Valid AUC&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Test  AUC&quot;</span>
                                  <span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span> 
np.random.seed(42)

full_pipeline_with_predictor = Pipeline([
(&quot;preparation&quot;, data_prep_pipeline),
(&quot;feature_selector&quot;, SelectKBest(score_func=f_classif, k=25)),
(&quot;polynomial&quot;, PolynomialFeatures(degree=2)),
(&quot;classifier&quot;, LogisticRegression(random_state=42))
])

model_benchmark = full_pipeline_with_predictor.fit(X_train, y_train)
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span>

<span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-metrics">Evaluation metrics<a class="anchor-link" href="#Evaluation-metrics">&#182;</a></h2><p>Submissions are evaluated on <a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">area under the ROC curve</a> between the predicted probability and the observed target.</p>
<p>The SkLearn <code>roc_auc_score</code> function computes the area under the receiver operating characteristic (ROC) curve, which is also denoted by AUC or AUROC. By computing the area under the roc curve, the curve information is summarized in one number.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="mf">0.75</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_auc_score</span>
<span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">exp_name</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;Baseline_{len(selected_features)}_features&quot;</span>
<span class="n">expLog</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">expLog</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="s2">&quot;</span><span class="si">{exp_name}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
               <span class="p">[</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span> 
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)),</span>
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])],</span>
    <span class="mi">4</span><span class="p">))</span> 
<span class="n">expLog</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="submission-preperation">submission preperation<a class="anchor-link" href="#submission-preperation">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span> <span class="o">=</span> <span class="n">model_benchmark</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_kaggle_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Submission dataframe</span>
<span class="n">submit_df</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_test&quot;</span><span class="p">][[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit_df</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_class_scores</span>

<span class="n">submit_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">submit_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;submission.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Logistic-Regression-Model">Logistic Regression Model<a class="anchor-link" href="#Logistic-Regression-Model">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">PolynomialFeatures</span>


<span class="c1"># Create a class to select numerical or categorical columns </span>
<span class="c1"># since Scikit-Learn doesn&#39;t handle DataFrames yet</span>
<span class="k">class</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span> <span class="o">=</span> <span class="n">attribute_names</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    
<span class="k">def</span> <span class="nf">pct</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Feature_engineering</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span> <span class="c1"># no *args or **kargs  , features=None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
<span class="c1">#         pass</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>  <span class="c1"># nothing else to do</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="c1">#         df = pd.DataFrame(columns = None)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_CREDIT/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#credit to income ratio</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_ANNUITY/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#annuity to income ratio        </span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;REGION_POPULATION_RELATIVE_flag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.07</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">),</span> <span class="s1">&#39;REGION_POPULATION_RELATIVE_flag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  
        <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;REGION_POPULATION_RELATIVE_flag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>     
        <span class="k">return</span> <span class="n">df</span>        
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Identify the numeric features we wish to consider. </span>
<span class="n">num_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span><span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span> <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span><span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
               <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span> <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span> <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
               <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>  <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span> <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>

<span class="n">num_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;selector&#39;</span><span class="p">,</span> <span class="n">DataFrameSelector</span><span class="p">(</span><span class="n">num_attribs</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;polynomial&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span> 
        <span class="p">(</span><span class="s1">&#39;std_scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">])</span>
<span class="c1"># Identify the categorical features we wish to consider.</span>
<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span><span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span> 
               <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
              <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span> <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span> <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">]</span>
<span class="n">cat_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;selector&#39;</span><span class="p">,</span> <span class="n">DataFrameSelector</span><span class="p">(</span><span class="n">cat_attribs</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">))</span>
    <span class="p">])</span>


<span class="n">feature_eng</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;feature_eng&#39;</span><span class="p">,</span> <span class="n">Feature_engineering</span><span class="p">())</span>
<span class="p">])</span>


<span class="n">num_cat_pipeline</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;num_pipeline&#39;</span><span class="p">,</span> <span class="n">num_pipeline</span><span class="p">,</span> <span class="n">num_attribs</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;cat_pipeline&#39;</span><span class="p">,</span> <span class="n">cat_pipeline</span><span class="p">,</span> <span class="n">cat_attribs</span><span class="p">),</span>
<span class="p">],</span> <span class="n">remainder</span> <span class="o">=</span> <span class="s1">&#39;drop&#39;</span> <span class="p">)</span>


<span class="n">data_prep_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;feature_eng&#39;</span><span class="p">,</span> <span class="n">feature_eng</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;num_cat_pipe&#39;</span><span class="p">,</span> <span class="n">num_cat_pipeline</span><span class="p">)</span>        
<span class="p">])</span>    


<span class="c1"># data_prep_pipeline = FeatureUnion(transformer_list=[</span>
<span class="c1">#         (&quot;num_pipeline&quot;, num_pipeline),</span>
<span class="c1">#         (&quot;cat_pipeline&quot;, cat_pipeline),</span>
<span class="c1">#     ])</span>

<span class="c1">#set up reporting format</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Classifier&quot;</span><span class="p">,</span> <span class="s2">&quot;Cross fold train AUC&quot;</span><span class="p">,</span> <span class="s2">&quot;test AUC&quot;</span><span class="p">,</span> <span class="s2">&quot;Train Time(s)&quot;</span><span class="p">,</span> 
                                <span class="s2">&quot;Test Time(s)&quot;</span><span class="p">,</span> <span class="s2">&quot;Experiment description&quot;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Split the provided training data into training and validationa and test</span>
<span class="c1"># The kaggle evaluation test set has no labels</span>
<span class="c1">#</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="c1"># just selected a few features for a baseline experiment</span>
<span class="n">selected_features</span> <span class="o">=</span> <span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs</span>
<span class="n">X_train</span><span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">selected_features</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15, random_state=42)</span>
<span class="n">X_kaggle_test</span><span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">selected_features</span><span class="p">]</span>
<span class="c1"># y_test = datasets[&quot;application_test&quot;][&#39;TARGET&#39;]   #why no  TARGET?!! (hint: kaggle competition)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X train           shape: </span><span class="si">{X_train.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X validation      shape: </span><span class="si">{X_valid.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># print(f&quot;X test            shape: {X_test.shape}&quot;)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X X_kaggle_test   shape: </span><span class="si">{X_kaggle_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">PolynomialFeatures</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># A Function to execute the grid search and record the results.</span>
<span class="k">def</span> <span class="nf">ConductGridSearch_LogisticRegression</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># generate the pipeline</span>
    <span class="n">full_pipeline_with_predictor</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;preparation&quot;</span><span class="p">,</span> <span class="n">data_prep_pipeline</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;classifier&quot;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
    <span class="p">])</span>

    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;classifier__penalty&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">),</span>
        <span class="s1">&#39;classifier__C&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">full_pipeline_with_predictor</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Best estimator score</span>
    <span class="n">best_train_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Best estimator fitting time</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="c1"># Best estimator prediction time</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
    <span class="n">best_test_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">test_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="c1"># Collect the best parameters found by the grid search</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Parameters:&quot;</span><span class="p">)</span>
    <span class="n">best_parameters</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">best_parameters</span><span class="p">[</span><span class="s1">&#39;penalty&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;classifier__penalty&#39;</span><span class="p">]</span>
    <span class="n">best_parameters</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;classifier__C&#39;</span><span class="p">]</span>  
    <span class="n">param_dump</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">param_dump</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_parameters</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="o">+</span><span class="s2">&quot;best parameters: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">best_parameters</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;****** FINISH&quot;</span><span class="p">,</span><span class="n">prefix</span><span class="p">,</span><span class="s2">&quot; *****&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="c1"># Record the results</span>
    <span class="n">results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">prefix</span><span class="p">,</span> <span class="n">best_train_score</span><span class="p">,</span> <span class="n">best_test_score</span><span class="p">,</span>  <span class="n">train_time</span><span class="p">,</span> <span class="n">test_time</span><span class="p">,</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">param_dump</span><span class="p">)]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># from sklearn.feature_selection import SelectKBest</span>
<span class="c1"># from sklearn.feature_selection import f_classif</span>
<span class="c1"># from sklearn.decomposition import PCA</span>
<span class="c1"># from sklearn.preprocessing import PolynomialFeatures</span>

<span class="c1"># from sklearn.linear_model import LogisticRegression</span>
<span class="c1"># from sklearn.ensemble import RandomForestClassifier</span>

<span class="c1"># # A Function to execute the grid search and record the results.</span>
<span class="c1"># def ConductGridSearch_LogisticRegression(X_train, y_train, X_test, y_test, i=0, prefix=&#39;&#39;):</span>
<span class="c1">#    # Create a list of classifiers for our grid search experiment</span>
<span class="c1">#     feature_selector = [</span>
<span class="c1">#         (&#39;SelectKbest&#39;, SelectKBest(score_func=f_classif)),</span>
<span class="c1">#         (&#39;pca&#39;, PCA()),</span>
<span class="c1">#     ]</span>

<span class="c1">#     # Arrange grid search parameters for each feature selector</span>
<span class="c1">#     params_grid = {</span>
<span class="c1">#         &#39;SelectKbest&#39;: {</span>
<span class="c1">#             &#39;k&#39;: [15, 25, 35], </span>
<span class="c1">#         },</span>
<span class="c1">#         &#39;pca&#39;: {&#39;n_components&#39;: [10, 20],</span>
<span class="c1">#         },</span>
<span class="c1">#     }</span>
    
<span class="c1">#     for (name, selector) in feature_selector:</span>
<span class="c1">#         i += 1</span>
<span class="c1">#         # Print classifier and parameters</span>
<span class="c1">#         print(&#39;****** START&#39;,prefix, name,&#39;*****&#39;)</span>
<span class="c1">#         parameters = params_grid[name]</span>
<span class="c1">#         print(&quot;Parameters:&quot;)</span>

<span class="c1">#         for p in sorted(parameters.keys()):</span>
<span class="c1">#             print(&quot;\t&quot;+str(p)+&quot;: &quot;+ str(parameters[p]))</span>

<span class="c1">#         # generate the pipeline</span>
<span class="c1">#         full_pipeline_with_predictor = Pipeline([</span>
<span class="c1">#         (&quot;preparation&quot;, data_prep_pipeline),</span>
<span class="c1">#         (&quot;feature_selector&quot;, selector),</span>
<span class="c1">#         (&quot;polynomial&quot;, PolynomialFeatures()),</span>
<span class="c1">#         (&quot;classifier&quot;, LogisticRegression(random_state=42))</span>
<span class="c1">#         ])</span>
        
<span class="c1">#         # Execute the grid search</span>
<span class="c1">#         params = {}</span>
<span class="c1">#         for p in parameters.keys():</span>
<span class="c1">#             pipe_key = &#39;feature_selector__&#39;+str(p)</span>
<span class="c1">#             params[pipe_key] = parameters[p] </span>
        
<span class="c1">#         params.update({&#39;polynomial__degree&#39;: (1, 2),</span>
<span class="c1">#             &#39;classifier__penalty&#39;: (&#39;l1&#39;, &#39;l2&#39;),</span>
<span class="c1">#             &#39;classifier__C&#39;: (10, 1, 0.1, 0.01),</span>
<span class="c1">#         })</span>

<span class="c1">#         grid_search = GridSearchCV(full_pipeline_with_predictor, params, scoring=&#39;roc_auc&#39;, cv=10, verbose=1, n_jobs=2)</span>
<span class="c1">#         grid_search.fit(X_train, y_train)</span>
                
<span class="c1">#         # Best estimator score</span>
<span class="c1">#         best_train_score = pct(grid_search.best_score_)</span>

<span class="c1">#         # Best estimator fitting time</span>
<span class="c1">#         start = time()</span>
<span class="c1">#         grid_search.best_estimator_.fit(X_train, y_train)</span>
<span class="c1">#         train_time = round(time() - start, 4)</span>

<span class="c1">#         # Best estimator prediction time</span>
<span class="c1">#         start = time()</span>
<span class="c1">#         best_test_score = pct(grid_search.best_estimator_.score(X_test, y_test))</span>
<span class="c1">#         test_time = round(time() - start, 4)</span>
        
<span class="c1">#         # Collect the best parameters found by the grid search</span>
<span class="c1">#         print(&quot;Best Parameters:&quot;)</span>
<span class="c1">#         best_parameters = grid_search.best_estimator_.get_params()</span>
<span class="c1">#         param_dump = []</span>
<span class="c1">#         for param_name in sorted(params.keys()):</span>
<span class="c1">#             param_dump.append((param_name, best_parameters[param_name]))</span>
<span class="c1">#             print(&quot;\t&quot;+str(param_name)+&quot;: &quot; + str(best_parameters[param_name]))</span>
<span class="c1">#         print(&quot;****** FINISH&quot;,prefix,name,&quot; *****&quot;)</span>
<span class="c1">#         print(&quot;&quot;)</span>
        
<span class="c1">#         # Record the results</span>
<span class="c1">#         results.loc[i] = [prefix+name, best_train_score, best_test_score,  train_time, test_time, json.dumps(param_dump)]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>
# This might take a while
ConductGridSearch_LogisticRegression(X_train, y_train, X_valid, y_valid, 0, &quot;Logistic Regression &quot;)
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span> 
np.random.seed(42)

full_pipeline_with_predictor = Pipeline([
(&quot;preparation&quot;, data_prep_pipeline),
(&quot;classifier&quot;, LogisticRegression(penalty=&#39;l1&#39;, C=1, random_state=42))
])

model_bestLogisticRegression = full_pipeline_with_predictor.fit(X_train, y_train)
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">stats</span>

<span class="n">best_train_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_bestLogisticRegression</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
                                   <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_train_scores</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">baseline_scores</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">t_score</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_rel</span><span class="p">(</span><span class="n">baseline_scores</span><span class="p">,</span> <span class="n">best_train_scores</span><span class="p">)</span>
<span class="n">p_value</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Dataset-loading,-feature-engineering-and-pre-processing">Dataset loading, feature engineering and pre-processing<a class="anchor-link" href="#Dataset-loading,-feature-engineering-and-pre-processing">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="k">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="k">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">FeatureUnion</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">statistics</span> <span class="k">import</span> <span class="n">mean</span>
<span class="kn">import</span> <span class="nn">timeit</span>
<span class="kn">import</span> <span class="nn">uuid</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">in_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{name}</span><span class="s1">.csv&#39;</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">in_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="k">def</span> <span class="nf">get_datasets</span><span class="p">(</span><span class="n">phase</span><span class="p">):</span>
    <span class="n">datasets</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;application_</span><span class="si">{phase}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;loaded {len(datasets[&#39;application&#39;])} records from application_</span><span class="si">{phase}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ds_names</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;bureau&quot;</span><span class="p">,</span><span class="s2">&quot;bureau_balance&quot;</span><span class="p">,</span><span class="s2">&quot;credit_card_balance&quot;</span><span class="p">,</span><span class="s2">&quot;installments_payments&quot;</span><span class="p">,</span>
            <span class="s2">&quot;previous_application&quot;</span><span class="p">,</span><span class="s2">&quot;POS_CASH_balance&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ds_name</span> <span class="ow">in</span> <span class="n">ds_names</span><span class="p">:</span>
        <span class="n">datasets</span><span class="p">[</span><span class="n">ds_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">ds_name</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;loaded {len(datasets[ds_name])} records from </span><span class="si">{ds_name}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">datasets</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">features_from_previous_application</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    creates the no_prev_appl and no_approved_prev_appl columns</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">prev_app</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span>
    <span class="n">no_app_customer</span> <span class="o">=</span> <span class="n">prev_app</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">prev_app</span><span class="o">.</span><span class="n">DAYS_DECISION</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">365</span><span class="p">)</span> <span class="o">&amp;</span> 
           <span class="p">(</span><span class="n">prev_app</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">!=</span> <span class="s1">&#39;Canceled&#39;</span><span class="p">),</span> <span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_PREV</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># only select the applications in the past 12 months</span>
    <span class="n">no_app_customer</span> <span class="o">=</span> <span class="n">no_app_customer</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">no_app_customer</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">no_app_customer</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;SK_ID_PREV&#39;</span><span class="p">:</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">no_approved_app_customer</span> <span class="o">=</span> <span class="n">prev_app</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">prev_app</span><span class="o">.</span><span class="n">DAYS_DECISION</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">365</span><span class="p">)</span> <span class="o">&amp;</span> 
           <span class="p">(</span><span class="n">prev_app</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">==</span> <span class="s1">&#39;Approved&#39;</span><span class="p">),</span> <span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_PREV</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># only select the applications in the past 12 months</span>
    <span class="n">no_approved_app_customer</span> <span class="o">=</span> <span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;SK_ID_PREV&#39;</span><span class="p">:</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">no_app_customer</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">no_approved_app_customer</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">features_from_bureau</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Engineered features:</span>
<span class="sd">    - total_creditLimit</span>
<span class="sd">    - no_of_loans </span>
<span class="sd">    - ave_creditLimit</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">bureau</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span>
    <span class="n">credit_sum</span> <span class="o">=</span> <span class="n">bureau</span><span class="p">[(</span><span class="n">bureau</span><span class="o">.</span><span class="n">CREDIT_ACTIVE</span> <span class="o">==</span> <span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">bureau</span><span class="o">.</span><span class="n">CREDIT_CURRENCY</span> <span class="o">==</span> <span class="s1">&#39;currency 1&#39;</span><span class="p">)]</span> \
        <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">AMT_CREDIT_SUM</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">credit_sum</span> <span class="o">=</span> <span class="n">credit_sum</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">credit_sum</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">no_loans</span> <span class="o">=</span> <span class="n">bureau</span><span class="p">[(</span><span class="n">bureau</span><span class="o">.</span><span class="n">CREDIT_ACTIVE</span> <span class="o">==</span> <span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">bureau</span><span class="o">.</span><span class="n">CREDIT_CURRENCY</span> <span class="o">==</span> <span class="s1">&#39;currency 1&#39;</span><span class="p">)]</span> \
        <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_BUREAU</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="n">no_loans</span> <span class="o">=</span> <span class="n">no_loans</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">no_loans</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">bureau_info</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">credit_sum</span><span class="p">,</span> <span class="n">no_loans</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span>
    <span class="n">bureau_info</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;AMT_CREDIT_SUM&#39;</span><span class="p">:</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;SK_ID_BUREAU&#39;</span><span class="p">:</span><span class="s1">&#39;no_of_loans&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">bureau_info</span><span class="p">[</span><span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bureau_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;total_creditLimit/no_of_loans&#39;</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bureau_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">features_from_credit_card_balance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Engineered features:</span>
<span class="sd">    - utilization_CC</span>
<span class="sd">    - payment_ratio_CC</span>
<span class="sd">    - total_credit_limit_CC</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">ccb</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span>
    <span class="n">creditCard_info</span> <span class="o">=</span> <span class="n">ccb</span><span class="p">[(</span><span class="n">ccb</span><span class="o">.</span><span class="n">MONTHS_BALANCE</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">24</span><span class="p">)</span> <span class="o">&amp;</span> 
                          <span class="p">(</span><span class="n">ccb</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">==</span><span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span>
                          <span class="p">(</span><span class="n">ccb</span><span class="o">.</span><span class="n">AMT_CREDIT_LIMIT_ACTUAL</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span> \
                    <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)[</span><span class="s1">&#39;AMT_BALANCE&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">creditCard_info</span><span class="p">[</span><span class="s1">&#39;utilization_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">creditCard_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_BALANCE/AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">)</span>
    <span class="n">creditCard_info</span><span class="p">[</span><span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">creditCard_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT/AMT_BALANCE&#39;</span><span class="p">)</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">payment_ratio_CC</span><span class="o">.</span><span class="n">isnull</span><span class="p">(),</span> <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">payment_ratio_CC</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AMT_BALANCE&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">:</span><span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">creditCard_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span> <span class="c1"># best fillna strategy will be left to grid search</span>

<span class="k">def</span> <span class="nf">features_from_installments_payments</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Engineered features:</span>
<span class="sd">    - past_due_times</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">ip</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">]</span>
    <span class="n">ip</span><span class="p">[</span><span class="s1">&#39;past_due_times&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ip</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT&#39;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">past_due_info</span> <span class="o">=</span> <span class="n">ip</span><span class="p">[</span><span class="n">ip</span><span class="p">[</span><span class="s1">&#39;DAYS_INSTALMENT&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">730</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)[</span><span class="s1">&#39;past_due_times&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> 
    <span class="n">past_due_info</span> <span class="o">=</span> <span class="n">past_due_info</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">past_due_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">past_due_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">features_from_application</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Engineered features:</span>
<span class="sd">    - credit_income_ratio</span>
<span class="sd">    - annuity_income_ratio</span>
<span class="sd">    - REGION_POPULATION_RELATIVE_flag</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_CREDIT/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#credit to income ratio</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_ANNUITY/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#annuity to income ratio</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;REGION_POPULATION_RELATIVE_flag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">X</span><span class="p">[</span><span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.07</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">),</span> <span class="s1">&#39;REGION_POPULATION_RELATIVE_flag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  
    <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;REGION_POPULATION_RELATIVE_flag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">X</span>
    
<span class="k">def</span> <span class="nf">build_features</span><span class="p">(</span><span class="n">datasets</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from previous application&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_previous_application</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application&#39;</span><span class="p">],</span> <span class="n">datasets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from bureau&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_bureau</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from credit card balance&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_credit_card_balance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from installments&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_installments_payments</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from application&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_application</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-up-a-pipeline-incoporating-feature-engineering">Build up a pipeline incoporating feature engineering<a class="anchor-link" href="#Build-up-a-pipeline-incoporating-feature-engineering">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="k">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span>


<span class="c1"># Create a class to select numerical or categorical columns </span>
<span class="c1"># since Scikit-Learn doesn&#39;t handle DataFrames yet</span>
<span class="k">class</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span> <span class="o">=</span> <span class="n">attribute_names</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    
    
    
<span class="k">class</span> <span class="nc">FeatureEngineering</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span> <span class="c1"># no *args or **kargs  , features=None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>

    <span class="k">def</span> <span class="nf">get_feature_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span> 
    
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>    
        <span class="k">return</span> <span class="n">build_features</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">)</span>    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>


<span class="c1"># Identify the numerical features we wish to consider.</span>
<span class="n">num_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span><span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span> <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span> <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span><span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span> <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span> <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span> <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span> <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>

<span class="c1"># Identify the categorical features we wish to consider.</span>
<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span><span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span> <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span><span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span> <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span> <span class="s1">&#39;REGION_POPULATION_RELATIVE_flag&#39;</span><span class="p">,</span> <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span> <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span> <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">]</span>


<span class="n">num_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="c1">#         (&#39;selector&#39;, DataFrameSelector(num_attribs)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;std_scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">])</span>

<span class="n">cat_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="c1">#         (&#39;selector&#39;, DataFrameSelector(cat_attribs)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">)),</span>  <span class="c1"># most_frequent</span>
        <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">))</span>
    <span class="p">])</span>


<span class="n">feature_eng_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;feature_eng&#39;</span><span class="p">,</span> <span class="n">FeatureEngineering</span><span class="p">())</span>
<span class="p">])</span>


<span class="n">num_cat_pipeline</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;num_pipeline&#39;</span><span class="p">,</span> <span class="n">num_pipeline</span><span class="p">,</span> <span class="n">num_attribs</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;cat_pipeline&#39;</span><span class="p">,</span> <span class="n">cat_pipeline</span><span class="p">,</span> <span class="n">cat_attribs</span><span class="p">),</span>
<span class="p">],</span> <span class="n">remainder</span> <span class="o">=</span> <span class="s1">&#39;drop&#39;</span> <span class="p">)</span>


<span class="n">data_prep_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="c1">#     (&#39;feature_eng_pipe&#39;, feature_eng_pipeline),</span>
    <span class="p">(</span><span class="s1">&#39;num_cat_pipe&#39;</span><span class="p">,</span> <span class="n">num_cat_pipeline</span><span class="p">)</span>        
<span class="p">])</span>    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-loading-and-pre-processing">Data loading and pre-processing<a class="anchor-link" href="#Data-loading-and-pre-processing">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;workingdir.config&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">WORKING_DIR</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
    <span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">WORKING_DIR</span><span class="p">,</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>
    <span class="n">LOG_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">WORKING_DIR</span><span class="p">,</span> <span class="s1">&#39;runs&#39;</span><span class="p">)</span>

<span class="c1"># Data loading and feature engineering    </span>
<span class="n">datasets_train</span> <span class="o">=</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">phase</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">feature_eng_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">datasets_train</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">datasets_train</span><span class="p">[</span><span class="s1">&#39;application&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>

<span class="n">datasets_test</span> <span class="o">=</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">phase</span> <span class="o">=</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">X_kaggle_test</span> <span class="o">=</span> <span class="n">feature_eng_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">datasets_test</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Train test split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X train           shape: </span><span class="si">{X_train.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X validation      shape: </span><span class="si">{X_valid.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X test            shape: </span><span class="si">{X_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X X_kaggle_test   shape: </span><span class="si">{X_kaggle_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X train           shape: (222176, 134)
X validation      shape: (46127, 134)
X test            shape: (39208, 134)
X X_kaggle_test   shape: (48744, 133)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-set-of-functions-for-reporting">A set of functions for reporting<a class="anchor-link" href="#A-set-of-functions-for-reporting">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>

<span class="k">def</span> <span class="nf">logIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">experiemnt</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">test_description</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract and record information from trained models</span>
<span class="sd">    param:</span>
<span class="sd">    - models: trained models in a list.</span>
<span class="sd">    - experiemnt:</span>
<span class="sd">    - test_description:</span>
<span class="sd">    return: record metrics to runs.csv document</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">description</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">test_description</span><span class="p">):</span>
        <span class="n">model_attribs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">experiemnt</span><span class="p">)</span>   
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">description</span><span class="p">)</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;estimator__preparation__cat_pipeline__selector__attribute_names&#39;</span><span class="p">])</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;estimator__preparation__num_pipeline__selector__attribute_names&#39;</span><span class="p">])</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">([(</span><span class="n">model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;estimator__preparation__num_pipeline__steps&#39;</span><span class="p">]),</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;estimator__preparation__cat_pipeline__steps&#39;</span><span class="p">])]</span> <span class="p">)</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">repr</span><span class="p">(</span><span class="n">model</span><span class="p">)[:</span><span class="nb">repr</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(&quot;</span><span class="p">)])</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">param_distributions</span><span class="p">)</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_fit_time&#39;</span><span class="p">]),</span> <span class="mi">5</span><span class="p">))</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">best_score_</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="mi">5</span><span class="p">))</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span> <span class="mi">5</span><span class="p">))</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">model_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()))</span>
        <span class="c1"># append to runs.csv</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;runs.csv&quot;</span><span class="p">,</span><span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">resultFile</span><span class="p">:</span>
            <span class="n">wr</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">resultFile</span><span class="p">,</span> <span class="n">dialect</span><span class="o">=</span><span class="s1">&#39;excel&#39;</span><span class="p">)</span>
            <span class="n">wr</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">model_attribs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;All models have been successfully recorded!&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="k">def</span> <span class="nf">printIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">append</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract and print information from trained models</span>
<span class="sd">    param </span>
<span class="sd">    - models: trained models in a list.</span>
<span class="sd">    - append: Boolean</span>
<span class="sd">    return: print experiment log </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">expLog</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">append</span><span class="p">:</span> 
        <span class="n">expLog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;exp_name&quot;</span><span class="p">,</span> 
                                           <span class="s2">&quot;Train Acc&quot;</span><span class="p">,</span> 
                                           <span class="s2">&quot;Valid Acc&quot;</span><span class="p">,</span>
                                           <span class="s2">&quot;Test  Acc&quot;</span><span class="p">,</span>
                                           <span class="s2">&quot;Train AUC&quot;</span><span class="p">,</span> 
                                           <span class="s2">&quot;Valid AUC&quot;</span><span class="p">,</span>
                                           <span class="s2">&quot;Test  AUC&quot;</span>
                                          <span class="p">])</span>
  
    <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">)</span> <span class="p">:</span>    
        
            
        <span class="k">try</span><span class="p">:</span>
            <span class="n">expLog</span>
        <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
            <span class="n">expLog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;exp_name&quot;</span><span class="p">,</span> 
                                           <span class="s2">&quot;Train Acc&quot;</span><span class="p">,</span> 
                                           <span class="s2">&quot;Valid Acc&quot;</span><span class="p">,</span>
                                           <span class="s2">&quot;Test  Acc&quot;</span><span class="p">,</span>
                                           <span class="s2">&quot;Train AUC&quot;</span><span class="p">,</span> 
                                           <span class="s2">&quot;Valid AUC&quot;</span><span class="p">,</span>
                                           <span class="s2">&quot;Test  AUC&quot;</span>
                                          <span class="p">])</span>
            
        <span class="k">if</span> <span class="ow">not</span> <span class="s1">&#39;DS_Store&#39;</span> <span class="ow">in</span> <span class="n">model_name</span><span class="p">:</span> 
            <span class="n">expLog</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">expLog</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="s2">&quot;{model_name.replace(&#39;.pkl&#39;, &#39;&#39;)}&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
                           <span class="p">[</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span> 
                            <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)),</span>
                            <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)),</span>
                            <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                            <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                            <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])],</span>
                <span class="mi">4</span><span class="p">))</span> 
    <span class="k">return</span> <span class="n">expLog</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[146]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plotIt</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract and plot information from trained models</span>
<span class="sd">    param:</span>
<span class="sd">    - models: trained models in a list.</span>
<span class="sd">    return: train/validation loss plots</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>

<span class="k">def</span> <span class="nf">compareIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">,</span> <span class="n">baseline_model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract and compare information from trained models</span>
<span class="sd">    param:</span>
<span class="sd">    - models: trained models in a list.</span>
<span class="sd">    return: T-test statitics with p values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># statistic table </span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;ExpID&quot;</span><span class="p">,</span> <span class="s2">&quot;Cross fold train accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;Test accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;t-statistic&quot;</span><span class="p">,</span> <span class="s2">&quot;p-value&quot;</span> <span class="p">])</span>
    
    <span class="c1"># baseline model</span>
    <span class="n">cv_scores_baseline</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">best_train_score_baseline</span> <span class="o">=</span> <span class="n">cv_scores_baseline</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">best_test_score_baseline</span> <span class="o">=</span> <span class="n">baseline_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    
    <span class="c1"># trained models</span>
    <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">):</span>
        <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">(</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_rel</span><span class="p">(</span><span class="n">cv_scores_baseline</span><span class="p">,</span> <span class="n">cv_scores</span><span class="p">)</span>
        <span class="n">best_train_score</span> <span class="o">=</span> <span class="n">cv_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">best_test_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

        <span class="c1"># Record the results</span>
        <span class="n">results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="n">best_train_score_baseline</span><span class="p">,</span> <span class="n">best_test_score_baseline</span><span class="p">,</span>  <span class="s2">&quot;---&quot;</span><span class="p">,</span> <span class="s2">&quot;---&quot;</span><span class="p">]</span>
        
        <span class="n">results</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span> <span class="n">best_train_score</span><span class="p">,</span> <span class="n">best_test_score</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">t_stat</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>  <span class="nb">round</span><span class="p">(</span><span class="n">p_value</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">results</span>   
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Random-Forest-Model">Random Forest Model<a class="anchor-link" href="#Random-Forest-Model">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparamter-tuning-and-feature-selection">Hyperparamter tuning and feature selection<a class="anchor-link" href="#Hyperparamter-tuning-and-feature-selection">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">tempfile</span> <span class="k">import</span> <span class="n">mkdtemp</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="k">import</span> <span class="n">rmtree</span>

<span class="n">cachedir</span> <span class="o">=</span> <span class="n">mkdtemp</span><span class="p">()</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;preparation&quot;</span><span class="p">,</span> <span class="n">data_prep_pipeline</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;RandomForest&quot;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">())</span>  <span class="c1"># iterations=100,learning_rate=0.03,</span>
    <span class="p">],</span> <span class="n">memory</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>


<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;RandomForest__n_estimators&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">)),</span>
    <span class="s1">&#39;RandomForest__min_samples_split&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">)),</span>
    <span class="s1">&#39;RandomForest__max_depth&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">50</span><span class="p">))</span>
<span class="p">}</span>


<span class="n">model_rf</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> 
                              <span class="n">n_iter</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> 
                              <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> 
                              <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                              <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_rf</span><span class="p">,</span> <span class="s1">&#39;model_rf3.pkl&#39;</span><span class="p">)</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-metrics">Evaluation metrics<a class="anchor-link" href="#Evaluation-metrics">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="k">import</span> <span class="n">listdir</span>

<span class="nb">dir</span> <span class="o">=</span> <span class="s1">&#39;/Users/DL/Documents/gDrive/Kaggle/trained/rf&#39;</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fnames</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">fn</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">fn</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)])</span>
<span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">fnames</span> <span class="p">:</span> 
    <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">dir</span><span class="p">,</span> <span class="n">fname</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator StandardScaler from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator Pipeline from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator FeatureUnion from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator RandomizedSearchCV from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">printIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">),</span> <span class="n">append</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[69]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train AUC</th>
      <th>Valid AUC</th>
      <th>Test  AUC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline_14_features</td>
      <td>0.9198</td>
      <td>0.9192</td>
      <td>0.9159</td>
      <td>0.7359</td>
      <td>0.7361</td>
      <td>0.7362</td>
    </tr>
    <tr>
      <th>1</th>
      <td>model_rf</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.7413</td>
      <td>0.7298</td>
      <td>0.7330</td>
    </tr>
    <tr>
      <th>2</th>
      <td>model_rf1</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.7951</td>
      <td>0.7386</td>
      <td>0.7406</td>
    </tr>
    <tr>
      <th>3</th>
      <td>model_rf2</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.8102</td>
      <td>0.7418</td>
      <td>0.7415</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The random forest model <code>Model_rf2</code> has a Train AUC much higher than Valid AUC, suggesting potential issue of overfitting.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">experiemnt</span> <span class="o">=</span> <span class="s1">&#39;Randomforest&#39;</span><span class="p">,</span> <span class="n">test_description</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>All models are successfully recorded!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="CatBoost">CatBoost<a class="anchor-link" href="#CatBoost">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Set-up-a-pipeline">Set up a pipeline<a class="anchor-link" href="#Set-up-a-pipeline">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">catboost</span> <span class="k">import</span> <span class="n">CatBoostClassifier</span>
<span class="c1"># pipeline</span>
<span class="n">pipeline_cb</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;preparation&quot;</span><span class="p">,</span> <span class="n">data_prep_pipeline</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;gboost&quot;</span><span class="p">,</span> <span class="n">CatBoostClassifier</span><span class="p">(</span><span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>  <span class="c1"># iterations=100,learning_rate=0.03, task_type=&#39;GPU&#39;, </span>
    <span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">pipeline_cb</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparameter-tunning">Hyperparameter tunning<a class="anchor-link" href="#Hyperparameter-tunning">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>
<span class="c1"># GridSearch</span>
<span class="c1"># params = {&#39;gboost__depth&#39;: [1, 7, 10],</span>
<span class="c1">#           &#39;gboost__learning_rate&#39; : [0.03, 0.1, 0.15],</span>
<span class="c1">#          &#39;gboost__l2_leaf_reg&#39;: [1, 4, 9],</span>
<span class="c1">#          &#39;gboost__iterations&#39;: [300, 500]}</span>

<span class="c1"># params = {&#39;depth&#39;:[3,1,2,6,4,5,7,8,9,10],</span>
<span class="c1">#           &#39;iterations&#39;:[250,100,500,1000],</span>
<span class="c1">#           &#39;learning_rate&#39;:[0.03,0.001,0.01,0.1,0.2,0.3], </span>
<span class="c1">#           &#39;l2_leaf_reg&#39;:[3,1,5,10,100, 200],</span>
<span class="c1">#           &#39;border_count&#39;:[32,5,10,20,50,100,200],</span>
<span class="c1">#           &#39;ctr_border_count&#39;:[50,5,10,20,100,200],</span>
<span class="c1">#           &#39;thread_count&#39;:4}</span>

<span class="c1"># params = {</span>
<span class="c1">#           &#39;gboost__learning_rate&#39; : [0.03, 0.15]</span>
<span class="c1">#         }</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;gboost__depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span> <span class="p">],</span>
          <span class="s1">&#39;gboost__learning_rate&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
         <span class="s1">&#39;gboost__l2_leaf_reg&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
         <span class="s1">&#39;gboost__border_count&#39;</span><span class="p">:[</span><span class="mi">32</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">],</span>
         <span class="s1">&#39;gboost__ctr_border_count&#39;</span><span class="p">:[</span><span class="mi">50</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">],</span>
         <span class="s1">&#39;gboost__iterations&#39;</span><span class="p">:</span> <span class="p">[</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">750</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>
<span class="n">model_cb</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> 
                            <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_cb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Save trained models</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_cb</span><span class="p">,</span> <span class="s1">&#39;model_cb8.pkl&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-metrics">Evaluation metrics<a class="anchor-link" href="#Evaluation-metrics">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="k">import</span> <span class="n">listdir</span>

<span class="nb">dir</span> <span class="o">=</span> <span class="s1">&#39;/Users/DL/Documents/gDrive/Kaggle/trained/cb&#39;</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fnames</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">fn</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">fn</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)])</span>
<span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">fnames</span> <span class="p">:</span> 
    <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">dir</span><span class="p">,</span> <span class="n">fname</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator StandardScaler from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator Pipeline from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator FeatureUnion from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator RandomizedSearchCV from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">printIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">),</span> <span class="n">append</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[71]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train AUC</th>
      <th>Valid AUC</th>
      <th>Test  AUC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline_14_features</td>
      <td>0.9198</td>
      <td>0.9192</td>
      <td>0.9159</td>
      <td>0.7359</td>
      <td>0.7361</td>
      <td>0.7362</td>
    </tr>
    <tr>
      <th>1</th>
      <td>model_rf</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.7413</td>
      <td>0.7298</td>
      <td>0.7330</td>
    </tr>
    <tr>
      <th>2</th>
      <td>model_rf1</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.7951</td>
      <td>0.7386</td>
      <td>0.7406</td>
    </tr>
    <tr>
      <th>3</th>
      <td>model_rf2</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.8102</td>
      <td>0.7418</td>
      <td>0.7415</td>
    </tr>
    <tr>
      <th>4</th>
      <td>model_cb7</td>
      <td>0.9209</td>
      <td>0.9197</td>
      <td>0.9161</td>
      <td>0.7707</td>
      <td>0.7522</td>
      <td>0.7516</td>
    </tr>
    <tr>
      <th>5</th>
      <td>model_cb8</td>
      <td>0.9213</td>
      <td>0.9198</td>
      <td>0.9160</td>
      <td>0.7752</td>
      <td>0.7539</td>
      <td>0.7530</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">experiemnt</span> <span class="o">=</span> <span class="s1">&#39;Randomforest&#39;</span><span class="p">,</span> <span class="n">test_description</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>All models are successfully recorded!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Sklearn-gradient-bootsting-with-early-stopping">Sklearn gradient bootsting with early stopping<a class="anchor-link" href="#Sklearn-gradient-bootsting-with-early-stopping">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pipeline-setup">Pipeline setup<a class="anchor-link" href="#Pipeline-setup">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">PolynomialFeatures</span>

<span class="n">pipeline_gb</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;preparation&quot;</span><span class="p">,</span> <span class="n">data_prep_pipeline</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;feature_selector&quot;</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">15</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;gradientboost&quot;</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
                                                     <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
                                                     <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span>
                                                     <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># iterations=100,learning_rate=0.03, task_type=&#39;GPU&#39;, </span>
        <span class="p">])</span>

<span class="c1"># pipeline = pipeline_gb</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparamter-tunning">Hyperparamter tunning<a class="anchor-link" href="#Hyperparamter-tunning">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
    
    <span class="s2">&quot;gradientboost__loss&quot;</span><span class="p">:[</span><span class="s2">&quot;deviance&quot;</span><span class="p">],</span>
    <span class="s2">&quot;gradientboost__learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span>  <span class="mf">0.06</span><span class="p">,</span>  <span class="mf">0.1</span><span class="p">,</span>  <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="s2">&quot;gradientboost__min_samples_split&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
    <span class="s2">&quot;gradientboost__min_samples_leaf&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
    <span class="s2">&quot;gradientboost__max_depth&quot;</span><span class="p">:[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span> <span class="p">],</span>
    <span class="s2">&quot;gradientboost__max_features&quot;</span><span class="p">:[</span><span class="s2">&quot;log2&quot;</span><span class="p">,</span><span class="s2">&quot;sqrt&quot;</span><span class="p">],</span>
<span class="c1">#     &quot;criterion&quot;: [&quot;friedman_mse&quot;,  &quot;mae&quot;],</span>
    <span class="s2">&quot;gradientboost__subsample&quot;</span><span class="p">:[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],</span>
<span class="c1">#     &quot;gradientboost__n_estimators&quot;:[10]</span>
    <span class="p">}</span>

<span class="c1"># params = {&#39;gboost__depth&#39;: [ 4, 7, 9 ],</span>
<span class="c1">#           &#39;gboost__learning_rate&#39; : [0.03, 0.06, 0.1, 0.2],</span>
<span class="c1">#          &#39;gboost__l2_leaf_reg&#39;: [2, 4, 6],</span>
<span class="c1">#          &#39;gboost__iterations&#39;: [300, 500]}</span>

<span class="n">model_gb_stop</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipeline_gb</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> 
                                   <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                                   <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> 
                                   <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model_gb_stop</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_gb_stop</span><span class="p">,</span> <span class="s1">&#39;model_gb_stop4.pkl&#39;</span><span class="p">)</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-metrics">Evaluation metrics<a class="anchor-link" href="#Evaluation-metrics">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">dir</span> <span class="o">=</span> <span class="s1">&#39;/Users/DL/Documents/gDrive/Kaggle/trained/gb&#39;</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fnames</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">fn</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">fn</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)])</span>
<span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">fnames</span> <span class="p">:</span> 
    <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">dir</span><span class="p">,</span> <span class="n">fname</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator StandardScaler from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator Pipeline from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator FeatureUnion from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
/anaconda3/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator RandomizedSearchCV from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.
  UserWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">printIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">),</span> <span class="n">append</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[75]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train AUC</th>
      <th>Valid AUC</th>
      <th>Test  AUC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline_14_features</td>
      <td>0.9198</td>
      <td>0.9192</td>
      <td>0.9159</td>
      <td>0.7359</td>
      <td>0.7361</td>
      <td>0.7362</td>
    </tr>
    <tr>
      <th>1</th>
      <td>model_rf</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.7413</td>
      <td>0.7298</td>
      <td>0.7330</td>
    </tr>
    <tr>
      <th>2</th>
      <td>model_rf1</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.7951</td>
      <td>0.7386</td>
      <td>0.7406</td>
    </tr>
    <tr>
      <th>3</th>
      <td>model_rf2</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.8102</td>
      <td>0.7418</td>
      <td>0.7415</td>
    </tr>
    <tr>
      <th>4</th>
      <td>model_cb7</td>
      <td>0.9209</td>
      <td>0.9197</td>
      <td>0.9161</td>
      <td>0.7707</td>
      <td>0.7522</td>
      <td>0.7516</td>
    </tr>
    <tr>
      <th>5</th>
      <td>model_cb8</td>
      <td>0.9213</td>
      <td>0.9198</td>
      <td>0.9160</td>
      <td>0.7752</td>
      <td>0.7539</td>
      <td>0.7530</td>
    </tr>
    <tr>
      <th>6</th>
      <td>model_gb_stop3</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.7232</td>
      <td>0.7205</td>
      <td>0.7157</td>
    </tr>
    <tr>
      <th>7</th>
      <td>model_gb_stop2</td>
      <td>0.9198</td>
      <td>0.9194</td>
      <td>0.9160</td>
      <td>0.7109</td>
      <td>0.7144</td>
      <td>0.7068</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">experiemnt</span> <span class="o">=</span> <span class="s1">&#39;Randomforest&#39;</span><span class="p">,</span> <span class="n">test_description</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>All models are successfully recorded!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Lightweight-Gradient-Boosting-Model">Lightweight Gradient Boosting Model<a class="anchor-link" href="#Lightweight-Gradient-Boosting-Model">&#182;</a></h1><h2 id="1st-order-polynomial-with-the-best-hyperparameters-found">1st-order polynomial with the best hyperparameters found<a class="anchor-link" href="#1st-order-polynomial-with-the-best-hyperparameters-found">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[148]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Create a class to select numerical or categorical columns </span>
<span class="c1"># since Scikit-Learn doesn&#39;t handle DataFrames yet</span>
<span class="k">class</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span> <span class="o">=</span> <span class="n">attribute_names</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    
<span class="k">def</span> <span class="nf">pct</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>select features</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[149]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_REGISTRATION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_ID_PUBLISH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;TOTALAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_LAST_PHONE_CHANGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span>
 <span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>

<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_TYPE_SUITE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_FAMILY_STATUS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_HOUSING_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_MOBIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_CONT_MOBILE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMAIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WEEKDAY_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_LIVE_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_LIVE_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUSETYPE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EMERGENCYSTATE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_4&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_5&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_6&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_7&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_8&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_9&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_10&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_11&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_12&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_13&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_14&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_15&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_16&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_17&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_18&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_19&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_20&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_21&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[150]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

# build pipeline

num_pipeline = Pipeline([
        (&#39;selector&#39;, DataFrameSelector(num_attribs)),
        (&#39;imputer&#39;, SimpleImputer(strategy=&#39;median&#39;)),
        (&#39;std_scaler&#39;, StandardScaler()),
    ])

cat_pipeline = Pipeline([
        (&#39;selector&#39;, DataFrameSelector(cat_attribs)),
        (&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;, fill_value = &#39;N/A&#39;)),
        (&#39;ohe&#39;, OneHotEncoder(sparse=False, dtype=np.uint8, handle_unknown=&quot;ignore&quot;))
    ])

data_prep_pipeline = FeatureUnion(transformer_list=[
        (&quot;num_pipeline&quot;, num_pipeline),
        (&quot;cat_pipeline&quot;, cat_pipeline),
    ])
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wall time: 0 ns
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[151]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># this is for only setting aside 1 test data set. Since we are going to do K-fold cross validation in GridSearch, we won&#39;t do this step.</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 

<span class="n">X_kaggle_test</span><span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X train           shape: </span><span class="si">{X_train.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X validation      shape: </span><span class="si">{X_valid.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X test            shape: </span><span class="si">{X_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X X_kaggle_test   shape: </span><span class="si">{X_kaggle_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X train           shape: (222176, 131)
X validation      shape: (46127, 131)
X test            shape: (39208, 131)
X X_kaggle_test   shape: (48744, 131)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[152]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>
train_X = data_prep_pipeline.fit_transform(X_train)
valid_X = data_prep_pipeline.transform(X_valid)
test_X = data_prep_pipeline.transform(X_test)
Kaggle_test_X = data_prep_pipeline.transform(X_kaggle_test)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wall time: 9.42 s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[153]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">expLog</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">expLog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;exp_name&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Train Acc&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Valid Acc&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Test  Acc&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Train AUC&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Valid AUC&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Test  AUC&quot;</span>
                                  <span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>early stopping to avoid overfitting for lgbm</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[155]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span> 
from lightgbm import LGBMClassifier
np.random.seed(42)

model_lgbm_es = LGBMClassifier(n_estimators=10000,
    bagging_fraction=0.75, 
    feature_fraction=0.30000000000000004, 
    learning_rate=0.025, 
    max_depth=9, 
    min_child_samples=40, 
    min_child_weight=3.5, 
    num_leaves=50, 
    reg_alpha=1, 
    reg_lambda=0.7000000000000001, 
    subsample=0.5,
    verbose=1)

model_lgbm_es.fit(train_X, y_train, eval_metric= eval_metric=[
             &#39;logloss&#39;, &#39;auc&#39;], 
            verbose= 200, eval_set=[(valid_X,y_valid)], 
                 early_stopping_rounds=1000)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 200 rounds.
[200]	valid_0&#39;s binary_logloss: 0.244819	valid_0&#39;s auc: 0.765573
[400]	valid_0&#39;s binary_logloss: 0.242657	valid_0&#39;s auc: 0.768692
[600]	valid_0&#39;s binary_logloss: 0.242114	valid_0&#39;s auc: 0.769927
[800]	valid_0&#39;s binary_logloss: 0.241944	valid_0&#39;s auc: 0.770318
[1000]	valid_0&#39;s binary_logloss: 0.241806	valid_0&#39;s auc: 0.770831
[1200]	valid_0&#39;s binary_logloss: 0.241795	valid_0&#39;s auc: 0.770984
[1400]	valid_0&#39;s binary_logloss: 0.241755	valid_0&#39;s auc: 0.771293
Early stopping, best iteration is:
[1346]	valid_0&#39;s binary_logloss: 0.241741	valid_0&#39;s auc: 0.771336
Wall time: 1min 59s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>get feature names</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[183]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cat_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[183]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Pipeline(memory=None,
     steps=[(&#39;selector&#39;, DataFrameSelector(attribute_names=[&#39;NAME_CONTRACT_TYPE&#39;, &#39;CODE_GENDER&#39;, &#39;FLAG_OWN_CAR&#39;, &#39;FLAG_OWN_REALTY&#39;, &#39;NAME_TYPE_SUITE&#39;, &#39;NAME_INCOME_TYPE&#39;, &#39;NAME_EDUCATION_TYPE&#39;, &#39;NAME_FAMILY_STATUS&#39;, &#39;NAME_HOUSING_TYPE&#39;, &#39;FLAG_MOBIL&#39;, &#39;FLAG_EMP_PHONE&#39;, &#39;FLAG_WORK_PHONE&#39;, &#39;FLAG_CONT_MOBILE...,
       dtype=&lt;class &#39;numpy.uint8&#39;&gt;, handle_unknown=&#39;ignore&#39;, n_values=None,
       sparse=False))])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[187]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">fill_value</span> <span class="o">=</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
<span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="n">X_train_cat_impute</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">cat_attribs</span><span class="p">])</span>
<span class="n">X_train_cat_impute_ohe</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_cat_impute</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[199]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cat_attribs_ohe</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">ohe</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()):</span>
    <span class="n">str_rep</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">attr</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">attr_</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">str_rep</span><span class="p">,</span> <span class="n">cat_attribs</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">cat_attribs_ohe</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attr_</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[201]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">features_full</span> <span class="o">=</span> <span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs_ohe</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>plot model importance, but we are missing column names</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[181]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model_lgbm_es</span><span class="p">,</span> <span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">max_num_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[182]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model_lgbm_es</span><span class="p">,</span> <span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;gain&#39;</span><span class="p">,</span> <span class="n">max_num_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>get model importance</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[130]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">booster</span> <span class="o">=</span> <span class="n">model_lgbm_es</span><span class="o">.</span><span class="n">booster_</span>

<span class="n">importance</span> <span class="o">=</span> <span class="n">booster</span><span class="o">.</span><span class="n">feature_importance</span><span class="p">(</span><span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;gain&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[208]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_importance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;feature_name&#39;</span><span class="p">:</span><span class="n">features_full</span><span class="p">,</span><span class="s1">&#39;importance&#39;</span><span class="p">:</span><span class="n">importance</span><span class="p">}</span> <span class="p">)</span>
<span class="n">feature_importance</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;importance&#39;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[209]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_importance</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[209]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature_name</th>
      <th>importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15</th>
      <td>EXT_SOURCE_3</td>
      <td>20263.714034</td>
    </tr>
    <tr>
      <th>14</th>
      <td>EXT_SOURCE_2</td>
      <td>15936.531626</td>
    </tr>
    <tr>
      <th>13</th>
      <td>EXT_SOURCE_1</td>
      <td>6371.954057</td>
    </tr>
    <tr>
      <th>6</th>
      <td>DAYS_BIRTH</td>
      <td>3075.980747</td>
    </tr>
    <tr>
      <th>78</th>
      <td>past_due_times</td>
      <td>2764.919170</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AMT_GOODS_PRICE</td>
      <td>2270.016201</td>
    </tr>
    <tr>
      <th>7</th>
      <td>DAYS_EMPLOYED</td>
      <td>2185.164551</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AMT_CREDIT</td>
      <td>1794.825076</td>
    </tr>
    <tr>
      <th>76</th>
      <td>utilization_CC</td>
      <td>1790.189253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AMT_ANNUITY</td>
      <td>1401.881386</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Plot the feature importance</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[216]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">feature_importance</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;feature_name&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature Name&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Relative Feature Importance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>3-fold cross validation for significant testing</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[119]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#perform corss-validation to get a series of scores for p-value</span>

<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">stats</span>

<span class="n">fit_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;early_stopping_rounds&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> 
            <span class="s1">&#39;eval_metric&#39;</span><span class="p">:</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span>
            <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s1">&#39;eval_set&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="n">test_X</span><span class="p">,</span><span class="n">y_test</span><span class="p">)]}</span>

<span class="n">best_train_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_lgbm_es</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
                                   <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[120]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_train_scores</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[120]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0.76442599, 0.76399866, 0.76257087, 0.76459844, 0.77570011,
       0.76564863, 0.78508369, 0.76405403, 0.76844225, 0.76613153,
       0.7592385 , 0.75605914, 0.75854305, 0.77913457, 0.74739931,
       0.77549347, 0.76339179, 0.77912104, 0.75766653, 0.78302365,
       0.76757681, 0.75480649, 0.75773345, 0.76610374, 0.77175365,
       0.76354919, 0.7569002 , 0.76672163, 0.77138163, 0.77553922])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[137]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">exp_name</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;LGBM_poly1_early_stopping&quot;</span>
<span class="n">expLog</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">expLog</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="s2">&quot;</span><span class="si">{exp_name}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
               <span class="p">[</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model_lgbm_es</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X</span><span class="p">)),</span> 
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model_lgbm_es</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">valid_X</span><span class="p">)),</span>
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model_lgbm_es</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model_lgbm_es</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model_lgbm_es</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">valid_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model_lgbm_es</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])],</span>
    <span class="mi">4</span><span class="p">))</span> 
<span class="n">expLog</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[137]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train AUC</th>
      <th>Valid AUC</th>
      <th>Test  AUC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline_14_features</td>
      <td>0.9198</td>
      <td>0.9192</td>
      <td>0.9159</td>
      <td>0.7359</td>
      <td>0.7361</td>
      <td>0.7362</td>
    </tr>
    <tr>
      <th>1</th>
      <td>LGBM_poly1_early_stopping</td>
      <td>0.9207</td>
      <td>0.9197</td>
      <td>0.9189</td>
      <td>0.8076</td>
      <td>0.7661</td>
      <td>0.7675</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LGBM_poly1_early_stopping</td>
      <td>0.9206</td>
      <td>0.9198</td>
      <td>0.9191</td>
      <td>0.8063</td>
      <td>0.7677</td>
      <td>0.7672</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LGBM_poly1_early_stopping</td>
      <td>0.9206</td>
      <td>0.9198</td>
      <td>0.9191</td>
      <td>0.8063</td>
      <td>0.7677</td>
      <td>0.7672</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LGBM_poly1_early_stopping</td>
      <td>0.9206</td>
      <td>0.9198</td>
      <td>0.9191</td>
      <td>0.8063</td>
      <td>0.7677</td>
      <td>0.7672</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>prepare files for Kaggle submission</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[138]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span> <span class="o">=</span> <span class="n">model_lgbm_es</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">Kaggle_test_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[139]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[139]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0.02698749, 0.09278481, 0.03969005, 0.03832893, 0.12722543,
       0.06144288, 0.0238604 , 0.05520947, 0.00798334, 0.12854635])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[140]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Submission dataframe</span>
<span class="n">submit_df</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_test&quot;</span><span class="p">][[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit_df</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_class_scores</span>

<span class="n">submit_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[140]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100001</td>
      <td>0.026987</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100005</td>
      <td>0.092785</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100013</td>
      <td>0.039690</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100028</td>
      <td>0.038329</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100038</td>
      <td>0.127225</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[141]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">submit_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;submission.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>significance test for best logit modeel and best LightGBM model</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">stats</span>


<span class="n">scores_best_logit</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.75991906</span><span class="p">,</span> <span class="mf">0.75122787</span><span class="p">,</span> <span class="mf">0.74861501</span><span class="p">,</span> <span class="mf">0.75354972</span><span class="p">,</span> <span class="mf">0.7414317</span> <span class="p">,</span>
       <span class="mf">0.76889524</span><span class="p">,</span> <span class="mf">0.74727686</span><span class="p">,</span> <span class="mf">0.75408933</span><span class="p">,</span> <span class="mf">0.75785196</span><span class="p">,</span> <span class="mf">0.76689399</span><span class="p">,</span>
       <span class="mf">0.74262034</span><span class="p">,</span> <span class="mf">0.74919817</span><span class="p">,</span> <span class="mf">0.74069637</span><span class="p">,</span> <span class="mf">0.75031871</span><span class="p">,</span> <span class="mf">0.75001898</span><span class="p">,</span>
       <span class="mf">0.73282046</span><span class="p">,</span> <span class="mf">0.75266586</span><span class="p">,</span> <span class="mf">0.73769921</span><span class="p">,</span> <span class="mf">0.75819326</span><span class="p">,</span> <span class="mf">0.75466185</span><span class="p">,</span>
       <span class="mf">0.74839916</span><span class="p">,</span> <span class="mf">0.75985089</span><span class="p">,</span> <span class="mf">0.74118288</span><span class="p">,</span> <span class="mf">0.76487458</span><span class="p">,</span> <span class="mf">0.76284237</span><span class="p">,</span>
       <span class="mf">0.75431747</span><span class="p">,</span> <span class="mf">0.74516205</span><span class="p">,</span> <span class="mf">0.74562703</span><span class="p">,</span> <span class="mf">0.7555055</span> <span class="p">,</span> <span class="mf">0.76827758</span><span class="p">]</span>

<span class="n">scores_best_lgbm</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.76442599</span><span class="p">,</span> <span class="mf">0.76399866</span><span class="p">,</span> <span class="mf">0.76257087</span><span class="p">,</span> <span class="mf">0.76459844</span><span class="p">,</span> <span class="mf">0.77570011</span><span class="p">,</span>
       <span class="mf">0.76564863</span><span class="p">,</span> <span class="mf">0.78508369</span><span class="p">,</span> <span class="mf">0.76405403</span><span class="p">,</span> <span class="mf">0.76844225</span><span class="p">,</span> <span class="mf">0.76613153</span><span class="p">,</span>
       <span class="mf">0.7592385</span> <span class="p">,</span> <span class="mf">0.75605914</span><span class="p">,</span> <span class="mf">0.75854305</span><span class="p">,</span> <span class="mf">0.77913457</span><span class="p">,</span> <span class="mf">0.74739931</span><span class="p">,</span>
       <span class="mf">0.77549347</span><span class="p">,</span> <span class="mf">0.76339179</span><span class="p">,</span> <span class="mf">0.77912104</span><span class="p">,</span> <span class="mf">0.75766653</span><span class="p">,</span> <span class="mf">0.78302365</span><span class="p">,</span>
       <span class="mf">0.76757681</span><span class="p">,</span> <span class="mf">0.75480649</span><span class="p">,</span> <span class="mf">0.75773345</span><span class="p">,</span> <span class="mf">0.76610374</span><span class="p">,</span> <span class="mf">0.77175365</span><span class="p">,</span>
       <span class="mf">0.76354919</span><span class="p">,</span> <span class="mf">0.7569002</span> <span class="p">,</span> <span class="mf">0.76672163</span><span class="p">,</span> <span class="mf">0.77138163</span><span class="p">,</span> <span class="mf">0.77553922</span><span class="p">]</span>

<span class="p">(</span><span class="n">t_score</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_rel</span><span class="p">(</span><span class="n">scores_best_logit</span><span class="p">,</span> <span class="n">scores_best_lgbm</span><span class="p">)</span>
<span class="n">p_value</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[4]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1.602776962361117e-06</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="with-new-features-from-Nishad-and-Naimesh">with new features from Nishad and Naimesh<a class="anchor-link" href="#with-new-features-from-Nishad-and-Naimesh">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Create a class to select numerical or categorical columns </span>
<span class="c1"># since Scikit-Learn doesn&#39;t handle DataFrames yet</span>
<span class="k">class</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span> <span class="o">=</span> <span class="n">attribute_names</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    
<span class="k">def</span> <span class="nf">pct</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>select features</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_REGISTRATION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_ID_PUBLISH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;TOTALAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_LAST_PHONE_CHANGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span>
 <span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;income_credit_percen&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;fam_member_income&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;ann_incom_percen&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;new_employ_to_birth_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;new_credit_to_annuity&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;new_credit_to_goods_ratio&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;new_car_to_birth_ratio&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;new_car_to_emp_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;new_inc_per_child&#39;</span><span class="p">,</span>                    
 <span class="s1">&#39;income_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;credit_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;annuity_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;fam_member_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;child_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;goods_prices_population_percen&#39;</span><span class="p">,</span>                  
<span class="s1">&#39;car_age_population_percen&#39;</span><span class="p">,]</span>

<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_TYPE_SUITE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_FAMILY_STATUS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_HOUSING_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_MOBIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_CONT_MOBILE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMAIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WEEKDAY_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_LIVE_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_LIVE_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUSETYPE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EMERGENCYSTATE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_4&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_5&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_6&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_7&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_8&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_9&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_10&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_11&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_12&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_13&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_14&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_15&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_16&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_17&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_18&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_19&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_20&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_21&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

# build pipeline

num_pipeline = Pipeline([
        (&#39;selector&#39;, DataFrameSelector(num_attribs)),
        (&#39;imputer&#39;, SimpleImputer(strategy=&#39;median&#39;)),
        (&#39;std_scaler&#39;, StandardScaler()),
    ])

cat_pipeline = Pipeline([
        (&#39;selector&#39;, DataFrameSelector(cat_attribs)),
        (&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;, fill_value = &#39;N/A&#39;)),
        (&#39;ohe&#39;, OneHotEncoder(sparse=False, dtype=np.uint8, handle_unknown=&quot;ignore&quot;))
    ])

data_prep_pipeline = FeatureUnion(transformer_list=[
        (&quot;num_pipeline&quot;, num_pipeline),
        (&quot;cat_pipeline&quot;, cat_pipeline),
    ])
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wall time: 0 ns
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># this is for only setting aside 1 test data set. Since we are going to do K-fold cross validation in GridSearch, we won&#39;t do this step.</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 

<span class="n">X_kaggle_test</span><span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X train           shape: </span><span class="si">{X_train.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X validation      shape: </span><span class="si">{X_valid.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X test            shape: </span><span class="si">{X_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X X_kaggle_test   shape: </span><span class="si">{X_kaggle_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X train           shape: (222176, 147)
X validation      shape: (46127, 147)
X test            shape: (39208, 147)
X X_kaggle_test   shape: (48744, 147)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>
train_X = data_prep_pipeline.fit_transform(X_train)
valid_X = data_prep_pipeline.transform(X_valid)
test_X = data_prep_pipeline.transform(X_test)
Kaggle_test_X = data_prep_pipeline.transform(X_kaggle_test)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wall time: 10 s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">expLog</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">expLog</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;exp_name&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Train Acc&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Valid Acc&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Test  Acc&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Train AUC&quot;</span><span class="p">,</span> 
                                   <span class="s2">&quot;Valid AUC&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Test  AUC&quot;</span>
                                  <span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>early stopping to avoid overfitting for lgbm</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[105]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span> 
from lightgbm import LGBMClassifier
np.random.seed(42)

model_lgbm_es_add_features = LGBMClassifier(num_iterations=10000, 
    bagging_fraction=0.8280934509687381, 
    feature_fraction=0.13140441247373727, 
    learning_rate=0.0355693168731072, 
    max_depth=10, 
    min_child_samples=22, 
    min_child_weight=5.298202574719083, 
    num_leaves=46, 
    reg_alpha=0.884680296141274, 
    reg_lambda=0.03948815181755697, 
    subsample=0.25869763494360765,
    verbose=1)

model_lgbm_es_add_features.fit(train_X, y_train, eval_metric= [&#39;logloss&#39;, &#39;auc&#39;], 
            verbose= 200, eval_set=[(test_X,y_test)], 
                 early_stopping_rounds=1000)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 1000 rounds.
[200]	valid_0&#39;s auc: 0.769399	valid_0&#39;s binary_logloss: 0.246118
[400]	valid_0&#39;s auc: 0.775617	valid_0&#39;s binary_logloss: 0.242964
[600]	valid_0&#39;s auc: 0.7768	valid_0&#39;s binary_logloss: 0.242311
[800]	valid_0&#39;s auc: 0.776907	valid_0&#39;s binary_logloss: 0.242157
[1000]	valid_0&#39;s auc: 0.776232	valid_0&#39;s binary_logloss: 0.242313
[1200]	valid_0&#39;s auc: 0.776002	valid_0&#39;s binary_logloss: 0.242424
[1400]	valid_0&#39;s auc: 0.775886	valid_0&#39;s binary_logloss: 0.242436
[1600]	valid_0&#39;s auc: 0.775697	valid_0&#39;s binary_logloss: 0.242481
Early stopping, best iteration is:
[675]	valid_0&#39;s auc: 0.777174	valid_0&#39;s binary_logloss: 0.242161
Wall time: 48.7 s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[135]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span> 
from lightgbm import LGBMClassifier
np.random.seed(42)

model_lgbm_es_add_features = LGBMClassifier(num_iterations=10000, 
    bagging_fraction=0.8, 
    feature_fraction=0.1, 
    learning_rate=0.03, 
    max_depth=10, 
    min_child_samples=22, 
    min_child_weight=4, 
    num_leaves=40, 
    reg_alpha=0.8, 
    reg_lambda=0.035, 
    subsample=0.2,
    verbose=1)

model_lgbm_es_add_features.fit(train_X, y_train, eval_metric= [&#39;logloss&#39;, &#39;auc&#39;], 
            verbose= 200, eval_set=[(test_X,y_test)], 
                 early_stopping_rounds=1000)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 1000 rounds.
[200]	valid_0&#39;s binary_logloss: 0.249044	valid_0&#39;s auc: 0.764544
[400]	valid_0&#39;s binary_logloss: 0.244116	valid_0&#39;s auc: 0.773936
[600]	valid_0&#39;s binary_logloss: 0.24289	valid_0&#39;s auc: 0.776066
[800]	valid_0&#39;s binary_logloss: 0.242378	valid_0&#39;s auc: 0.777046
[1000]	valid_0&#39;s binary_logloss: 0.242088	valid_0&#39;s auc: 0.777599
[1200]	valid_0&#39;s binary_logloss: 0.242102	valid_0&#39;s auc: 0.777395
[1400]	valid_0&#39;s binary_logloss: 0.24205	valid_0&#39;s auc: 0.777452
[1600]	valid_0&#39;s binary_logloss: 0.242106	valid_0&#39;s auc: 0.777262
[1800]	valid_0&#39;s binary_logloss: 0.242197	valid_0&#39;s auc: 0.776917
[2000]	valid_0&#39;s binary_logloss: 0.242218	valid_0&#39;s auc: 0.776909
Early stopping, best iteration is:
[1081]	valid_0&#39;s binary_logloss: 0.24202	valid_0&#39;s auc: 0.777735
Wall time: 1min 31s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>get feature names</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[136]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">fill_value</span> <span class="o">=</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
<span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="n">X_train_cat_impute</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">cat_attribs</span><span class="p">])</span>
<span class="n">X_train_cat_impute_ohe</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_cat_impute</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[137]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cat_attribs_ohe</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">ohe</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()):</span>
    <span class="n">str_rep</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">attr</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">attr_</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">str_rep</span><span class="p">,</span> <span class="n">cat_attribs</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">cat_attribs_ohe</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attr_</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[138]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">features_full</span> <span class="o">=</span> <span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs_ohe</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>plot model importance, but we are missing column names</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[140]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model_lgbm_es_add_features</span><span class="p">,</span> <span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">max_num_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[141]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model_lgbm_es_add_features</span><span class="p">,</span> <span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;gain&#39;</span><span class="p">,</span> <span class="n">max_num_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>get model importance</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[142]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">booster</span> <span class="o">=</span> <span class="n">model_lgbm_es_add_features</span><span class="o">.</span><span class="n">booster_</span>

<span class="n">importance</span> <span class="o">=</span> <span class="n">booster</span><span class="o">.</span><span class="n">feature_importance</span><span class="p">(</span><span class="n">importance_type</span><span class="o">=</span><span class="s1">&#39;gain&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[143]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_importance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;feature_name&#39;</span><span class="p">:</span><span class="n">features_full</span><span class="p">,</span><span class="s1">&#39;importance&#39;</span><span class="p">:</span><span class="n">importance</span><span class="p">}</span> <span class="p">)</span>
<span class="n">feature_importance</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;importance&#39;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[144]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_importance</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[144]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature_name</th>
      <th>importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15</th>
      <td>EXT_SOURCE_3</td>
      <td>57074.212437</td>
    </tr>
    <tr>
      <th>14</th>
      <td>EXT_SOURCE_2</td>
      <td>54395.051293</td>
    </tr>
    <tr>
      <th>85</th>
      <td>new_credit_to_annuity</td>
      <td>34303.024389</td>
    </tr>
    <tr>
      <th>13</th>
      <td>EXT_SOURCE_1</td>
      <td>20629.397560</td>
    </tr>
    <tr>
      <th>6</th>
      <td>DAYS_BIRTH</td>
      <td>13809.259901</td>
    </tr>
    <tr>
      <th>86</th>
      <td>new_credit_to_goods_ratio</td>
      <td>12725.869800</td>
    </tr>
    <tr>
      <th>7</th>
      <td>DAYS_EMPLOYED</td>
      <td>11961.578842</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AMT_GOODS_PRICE</td>
      <td>10602.522686</td>
    </tr>
    <tr>
      <th>78</th>
      <td>past_due_times</td>
      <td>10140.763568</td>
    </tr>
    <tr>
      <th>63</th>
      <td>DAYS_LAST_PHONE_CHANGE</td>
      <td>8497.043787</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Plot the feature importance</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[145]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">feature_importance</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;feature_name&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Feature Name&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Relative Feature Importance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>3-fold cross validation for significant testing</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#perform corss-validation to get a series of scores for p-value</span>

<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">stats</span>

<span class="n">fit_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;early_stopping_rounds&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> 
            <span class="s1">&#39;eval_metric&#39;</span><span class="p">:</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span>
            <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s1">&#39;eval_set&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="n">test_X</span><span class="p">,</span><span class="n">y_test</span><span class="p">)]}</span>

<span class="n">best_train_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_lgbm_es_add_features</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
                                   <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[107]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">best_train_scores</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[107]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0.77030327, 0.76782745, 0.76700559, 0.77593431, 0.77713727,
       0.77036133, 0.79035556, 0.77266737, 0.77913236, 0.77492249,
       0.77124891, 0.76838444, 0.76967325, 0.7883767 , 0.75981046,
       0.7842581 , 0.76804569, 0.79176172, 0.76366313, 0.7914916 ,
       0.77854834, 0.76156963, 0.77616358, 0.77599433, 0.78130813,
       0.77984074, 0.76778723, 0.77552224, 0.77899436, 0.78036259])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">stats</span>


<span class="n">scores_best_lgbm_p2</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.76442599</span><span class="p">,</span> <span class="mf">0.76399866</span><span class="p">,</span> <span class="mf">0.76257087</span><span class="p">,</span> <span class="mf">0.76459844</span><span class="p">,</span> <span class="mf">0.77570011</span><span class="p">,</span>
       <span class="mf">0.76564863</span><span class="p">,</span> <span class="mf">0.78508369</span><span class="p">,</span> <span class="mf">0.76405403</span><span class="p">,</span> <span class="mf">0.76844225</span><span class="p">,</span> <span class="mf">0.76613153</span><span class="p">,</span>
       <span class="mf">0.7592385</span> <span class="p">,</span> <span class="mf">0.75605914</span><span class="p">,</span> <span class="mf">0.75854305</span><span class="p">,</span> <span class="mf">0.77913457</span><span class="p">,</span> <span class="mf">0.74739931</span><span class="p">,</span>
       <span class="mf">0.77549347</span><span class="p">,</span> <span class="mf">0.76339179</span><span class="p">,</span> <span class="mf">0.77912104</span><span class="p">,</span> <span class="mf">0.75766653</span><span class="p">,</span> <span class="mf">0.78302365</span><span class="p">,</span>
       <span class="mf">0.76757681</span><span class="p">,</span> <span class="mf">0.75480649</span><span class="p">,</span> <span class="mf">0.75773345</span><span class="p">,</span> <span class="mf">0.76610374</span><span class="p">,</span> <span class="mf">0.77175365</span><span class="p">,</span>
       <span class="mf">0.76354919</span><span class="p">,</span> <span class="mf">0.7569002</span> <span class="p">,</span> <span class="mf">0.76672163</span><span class="p">,</span> <span class="mf">0.77138163</span><span class="p">,</span> <span class="mf">0.77553922</span><span class="p">]</span>

<span class="n">scores_best_lgbm_p3</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.77030327</span><span class="p">,</span> <span class="mf">0.76782745</span><span class="p">,</span> <span class="mf">0.76700559</span><span class="p">,</span> <span class="mf">0.77593431</span><span class="p">,</span> <span class="mf">0.77713727</span><span class="p">,</span>
       <span class="mf">0.77036133</span><span class="p">,</span> <span class="mf">0.79035556</span><span class="p">,</span> <span class="mf">0.77266737</span><span class="p">,</span> <span class="mf">0.77913236</span><span class="p">,</span> <span class="mf">0.77492249</span><span class="p">,</span>
       <span class="mf">0.77124891</span><span class="p">,</span> <span class="mf">0.76838444</span><span class="p">,</span> <span class="mf">0.76967325</span><span class="p">,</span> <span class="mf">0.7883767</span> <span class="p">,</span> <span class="mf">0.75981046</span><span class="p">,</span>
       <span class="mf">0.7842581</span> <span class="p">,</span> <span class="mf">0.76804569</span><span class="p">,</span> <span class="mf">0.79176172</span><span class="p">,</span> <span class="mf">0.76366313</span><span class="p">,</span> <span class="mf">0.7914916</span> <span class="p">,</span>
       <span class="mf">0.77854834</span><span class="p">,</span> <span class="mf">0.76156963</span><span class="p">,</span> <span class="mf">0.77616358</span><span class="p">,</span> <span class="mf">0.77599433</span><span class="p">,</span> <span class="mf">0.78130813</span><span class="p">,</span>
       <span class="mf">0.77984074</span><span class="p">,</span> <span class="mf">0.76778723</span><span class="p">,</span> <span class="mf">0.77552224</span><span class="p">,</span> <span class="mf">0.77899436</span><span class="p">,</span> <span class="mf">0.78036259</span><span class="p">]</span>

<span class="p">(</span><span class="n">t_score</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_rel</span><span class="p">(</span><span class="n">scores_best_lgbm_p2</span><span class="p">,</span> <span class="n">scores_best_lgbm_p3</span><span class="p">)</span>
<span class="n">p_value</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[108]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1.3092543392628766e-13</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[111]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span>

<span class="n">exp_name</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;LGBM_additional_features_early_stopping&quot;</span>
<span class="n">expLog</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">expLog</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="s2">&quot;</span><span class="si">{exp_name}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
               <span class="p">[</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model_lgbm_es_add_features</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X</span><span class="p">)),</span> 
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model_lgbm_es_add_features</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">valid_X</span><span class="p">)),</span>
                <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model_lgbm_es_add_features</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model_lgbm_es_add_features</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">model_lgbm_es_add_features</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">valid_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model_lgbm_es_add_features</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])],</span>
    <span class="mi">4</span><span class="p">))</span> 
<span class="n">expLog</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[111]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train AUC</th>
      <th>Valid AUC</th>
      <th>Test  AUC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>LGBM_additional_features_early_stopping</td>
      <td>0.923</td>
      <td>0.9198</td>
      <td>0.9191</td>
      <td>0.8614</td>
      <td>0.7783</td>
      <td>0.7772</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[148]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span> <span class="o">=</span> <span class="n">model_lgbm_es_add_features</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">Kaggle_test_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[149]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[149]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0.02956654, 0.07460881, 0.01716735, 0.02864101, 0.11232746,
       0.04347645, 0.01325245, 0.06442084, 0.00954362, 0.07423225])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[150]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Submission dataframe</span>
<span class="n">submit_df</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_test&quot;</span><span class="p">][[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit_df</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_class_scores</span>

<span class="n">submit_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[150]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100001</td>
      <td>0.029567</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100005</td>
      <td>0.074609</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100013</td>
      <td>0.017167</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100028</td>
      <td>0.028641</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100038</td>
      <td>0.112327</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[151]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">submit_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;submission.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>use more data for training (90% train and 10% test)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[159]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">X_kaggle_test</span><span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">num_attribs</span> <span class="o">+</span> <span class="n">cat_attribs</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X train           shape: </span><span class="si">{X_train.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X validation      shape: </span><span class="si">{X_valid.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X X_kaggle_test   shape: </span><span class="si">{X_kaggle_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>X train           shape: (276759, 147)
X validation      shape: (30752, 147)
X X_kaggle_test   shape: (48744, 147)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[160]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>
train_X = data_prep_pipeline.fit_transform(X_train)
valid_X = data_prep_pipeline.transform(X_valid)
Kaggle_test_X = data_prep_pipeline.transform(X_kaggle_test)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wall time: 11.3 s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[162]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span> 
from lightgbm import LGBMClassifier
np.random.seed(42)

model_lgbm_es_add_features_full = LGBMClassifier(num_iterations=10000, 
    bagging_fraction=0.8, 
    feature_fraction=0.1, 
    learning_rate=0.03, 
    max_depth=10, 
    min_child_samples=22, 
    min_child_weight=4, 
    num_leaves=40, 
    reg_alpha=0.8, 
    reg_lambda=0.035, 
    subsample=0.2,
    verbose=1)

model_lgbm_es_add_features_full.fit(train_X, y_train, eval_metric= [&#39;logloss&#39;, &#39;auc&#39;], 
            verbose= 200, eval_set=[(valid_X ,y_valid)], 
                 early_stopping_rounds=1000)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 1000 rounds.
[200]	valid_0&#39;s binary_logloss: 0.246189	valid_0&#39;s auc: 0.768442
[400]	valid_0&#39;s binary_logloss: 0.241521	valid_0&#39;s auc: 0.776364
[600]	valid_0&#39;s binary_logloss: 0.240134	valid_0&#39;s auc: 0.7786
[800]	valid_0&#39;s binary_logloss: 0.23964	valid_0&#39;s auc: 0.779346
[1000]	valid_0&#39;s binary_logloss: 0.23955	valid_0&#39;s auc: 0.779385
[1200]	valid_0&#39;s binary_logloss: 0.239339	valid_0&#39;s auc: 0.779801
[1400]	valid_0&#39;s binary_logloss: 0.23947	valid_0&#39;s auc: 0.779396
[1600]	valid_0&#39;s binary_logloss: 0.239383	valid_0&#39;s auc: 0.779638
[1800]	valid_0&#39;s binary_logloss: 0.239356	valid_0&#39;s auc: 0.779735
[2000]	valid_0&#39;s binary_logloss: 0.239471	valid_0&#39;s auc: 0.779452
[2200]	valid_0&#39;s binary_logloss: 0.239512	valid_0&#39;s auc: 0.779223
Early stopping, best iteration is:
[1228]	valid_0&#39;s binary_logloss: 0.239314	valid_0&#39;s auc: 0.779892
Wall time: 1min 54s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[163]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span> <span class="o">=</span> <span class="n">model_lgbm_es_add_features_full</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">Kaggle_test_X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[164]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_class_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[164]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0.03566684, 0.09055599, 0.01781322, 0.02858402, 0.11742245,
       0.02528196, 0.01015482, 0.06329073, 0.00763837, 0.08059871])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[165]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Submission dataframe</span>
<span class="n">submit_df</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application_test&quot;</span><span class="p">][[</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">]]</span>
<span class="n">submit_df</span><span class="p">[</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_class_scores</span>

<span class="n">submit_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[165]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100001</td>
      <td>0.035667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>100005</td>
      <td>0.090556</td>
    </tr>
    <tr>
      <th>2</th>
      <td>100013</td>
      <td>0.017813</td>
    </tr>
    <tr>
      <th>3</th>
      <td>100028</td>
      <td>0.028584</td>
    </tr>
    <tr>
      <th>4</th>
      <td>100038</td>
      <td>0.117422</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[166]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">submit_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;submission.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Previous Experiment Result without New Features from Nishad/Neimesh</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="A-Functionized-Approach">A Functionized Approach<a class="anchor-link" href="#A-Functionized-Approach">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="k">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="k">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">FeatureUnion</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">statistics</span> <span class="k">import</span> <span class="n">mean</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">import</span> <span class="nn">timeit</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="k">import</span> <span class="n">combinations</span>

<span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;workingdir.config&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">WORKING_DIR</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">WORKING_DIR</span><span class="p">,</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">LOG_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">WORKING_DIR</span><span class="p">,</span> <span class="s1">&#39;runs&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">in_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{name}</span><span class="s1">.csv&#39;</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">in_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="k">def</span> <span class="nf">get_datasets</span><span class="p">(</span><span class="n">phase</span><span class="p">):</span>
    <span class="n">datasets</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;application&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;application_</span><span class="si">{phase}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;loaded {len(datasets[&#39;application&#39;])} records&quot;</span><span class="p">)</span>
    <span class="n">ds_names</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;bureau&quot;</span><span class="p">,</span><span class="s2">&quot;bureau_balance&quot;</span><span class="p">,</span><span class="s2">&quot;credit_card_balance&quot;</span><span class="p">,</span><span class="s2">&quot;installments_payments&quot;</span><span class="p">,</span>
            <span class="s2">&quot;previous_application&quot;</span><span class="p">,</span><span class="s2">&quot;POS_CASH_balance&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ds_name</span> <span class="ow">in</span> <span class="n">ds_names</span><span class="p">:</span>
        <span class="n">datasets</span><span class="p">[</span><span class="n">ds_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">ds_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">datasets</span>

<span class="k">def</span> <span class="nf">features_from_previous_application</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    creates the no_prev_appl and no_approved_prev_appl columns</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">prev_app</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;previous_application&#39;</span><span class="p">]</span>
    <span class="n">no_app_customer</span> <span class="o">=</span> <span class="n">prev_app</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">prev_app</span><span class="o">.</span><span class="n">DAYS_DECISION</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">365</span><span class="p">)</span> <span class="o">&amp;</span> 
           <span class="p">(</span><span class="n">prev_app</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">!=</span> <span class="s1">&#39;Canceled&#39;</span><span class="p">),</span> <span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_PREV</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># only select the applications in the past 12 months</span>
    <span class="n">no_app_customer</span> <span class="o">=</span> <span class="n">no_app_customer</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">no_app_customer</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">no_app_customer</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;SK_ID_PREV&#39;</span><span class="p">:</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">no_approved_app_customer</span> <span class="o">=</span> <span class="n">prev_app</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">prev_app</span><span class="o">.</span><span class="n">DAYS_DECISION</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">365</span><span class="p">)</span> <span class="o">&amp;</span> 
           <span class="p">(</span><span class="n">prev_app</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">==</span> <span class="s1">&#39;Approved&#39;</span><span class="p">),</span> <span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_PREV</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># only select the applications in the past 12 months</span>
    <span class="n">no_approved_app_customer</span> <span class="o">=</span> <span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">no_approved_app_customer</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;SK_ID_PREV&#39;</span><span class="p">:</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">no_app_customer</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">no_approved_app_customer</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;no_prev_appl&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">features_from_bureau</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Engineered features:</span>
<span class="sd">    - total_creditLimit</span>
<span class="sd">    - no_of_loans </span>
<span class="sd">    - ave_creditLimit</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">bureau</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;bureau&#39;</span><span class="p">]</span>
    <span class="n">credit_sum</span> <span class="o">=</span> <span class="n">bureau</span><span class="p">[(</span><span class="n">bureau</span><span class="o">.</span><span class="n">CREDIT_ACTIVE</span> <span class="o">==</span> <span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">bureau</span><span class="o">.</span><span class="n">CREDIT_CURRENCY</span> <span class="o">==</span> <span class="s1">&#39;currency 1&#39;</span><span class="p">)]</span> \
        <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">AMT_CREDIT_SUM</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">credit_sum</span> <span class="o">=</span> <span class="n">credit_sum</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">credit_sum</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">no_loans</span> <span class="o">=</span> <span class="n">bureau</span><span class="p">[(</span><span class="n">bureau</span><span class="o">.</span><span class="n">CREDIT_ACTIVE</span> <span class="o">==</span> <span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">bureau</span><span class="o">.</span><span class="n">CREDIT_CURRENCY</span> <span class="o">==</span> <span class="s1">&#39;currency 1&#39;</span><span class="p">)]</span> \
        <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">SK_ID_BUREAU</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="n">no_loans</span> <span class="o">=</span> <span class="n">no_loans</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">no_loans</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">bureau_info</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">credit_sum</span><span class="p">,</span> <span class="n">no_loans</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)</span>
    <span class="n">bureau_info</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;AMT_CREDIT_SUM&#39;</span><span class="p">:</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;SK_ID_BUREAU&#39;</span><span class="p">:</span><span class="s1">&#39;no_of_loans&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">bureau_info</span><span class="p">[</span><span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bureau_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;total_creditLimit/no_of_loans&#39;</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bureau_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span> <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span> <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">features_from_credit_card_balance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Engineered features:</span>
<span class="sd">    - utilization_CC</span>
<span class="sd">    - payment_ratio_CC</span>
<span class="sd">    - total_credit_limit_CC</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">ccb</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;credit_card_balance&#39;</span><span class="p">]</span>
    <span class="n">creditCard_info</span> <span class="o">=</span> <span class="n">ccb</span><span class="p">[(</span><span class="n">ccb</span><span class="o">.</span><span class="n">MONTHS_BALANCE</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">24</span><span class="p">)</span> <span class="o">&amp;</span> 
                          <span class="p">(</span><span class="n">ccb</span><span class="o">.</span><span class="n">NAME_CONTRACT_STATUS</span> <span class="o">==</span><span class="s1">&#39;Active&#39;</span><span class="p">)</span> <span class="o">&amp;</span>
                          <span class="p">(</span><span class="n">ccb</span><span class="o">.</span><span class="n">AMT_CREDIT_LIMIT_ACTUAL</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span> \
                    <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)[</span><span class="s1">&#39;AMT_BALANCE&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">creditCard_info</span><span class="p">[</span><span class="s1">&#39;utilization_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">creditCard_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_BALANCE/AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">)</span>
    <span class="n">creditCard_info</span><span class="p">[</span><span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">creditCard_info</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT/AMT_BALANCE&#39;</span><span class="p">)</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">payment_ratio_CC</span><span class="o">.</span><span class="n">isnull</span><span class="p">(),</span> <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">creditCard_info</span><span class="o">.</span><span class="n">payment_ratio_CC</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AMT_BALANCE&#39;</span><span class="p">,</span> <span class="s1">&#39;AMT_PAYMENT_TOTAL_CURRENT&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">creditCard_info</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;AMT_CREDIT_LIMIT_ACTUAL&#39;</span><span class="p">:</span><span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">creditCard_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span> <span class="c1"># best fillna strategy will be left to grid search</span>

<span class="k">def</span> <span class="nf">features_from_installments_payments</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Engineered features:</span>
<span class="sd">    - past_due_times</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">ip</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;installments_payments&#39;</span><span class="p">]</span>
    <span class="n">ip</span><span class="p">[</span><span class="s1">&#39;past_due_times&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ip</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT&#39;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">past_due_info</span> <span class="o">=</span> <span class="n">ip</span><span class="p">[</span><span class="n">ip</span><span class="p">[</span><span class="s1">&#39;DAYS_INSTALMENT&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">730</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">)[</span><span class="s1">&#39;past_due_times&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> 
    <span class="n">past_due_info</span> <span class="o">=</span> <span class="n">past_due_info</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">past_due_info</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">past_due_info</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;SK_ID_CURR&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">features_from_application</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Engineered features:</span>
<span class="sd">    - credit_income_ratio</span>
<span class="sd">    - annuity_income_ratio</span>
<span class="sd">    - REGION_POPULATION_RELATIVE_flag</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_CREDIT/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#credit to income ratio</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;AMT_ANNUITY/AMT_INCOME_TOTAL&#39;</span><span class="p">)</span> <span class="c1">#annuity to income ratio</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">build_ratio_features</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    use Nishad and Neimesh methods</span>
<span class="sd">    &#39;&#39;&#39;</span> 
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;income_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;credit_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">AMT_CREDIT</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;annuity_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">AMT_ANNUITY</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;fam_member_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">CNT_FAM_MEMBERS</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;child_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">CNT_CHILDREN</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;goods_prices_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">AMT_GOODS_PRICE</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>                    
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;car_age_population_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">OWN_CAR_AGE</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">REGION_POPULATION_RELATIVE</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 
    
<span class="c1">#     X[&#39;no_prev_app_income_percen&#39;] = (</span>
<span class="c1">#         X.no_prev_appl / X.AMT_INCOME_TOTAL).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;no_prev_app_annuity_percen&#39;] = (</span>
<span class="c1">#         X.no_prev_appl / X.AMT_ANNUITY).replace(np.inf, 0)  </span>
<span class="c1">#     X[&#39;no_prev_app_credit_percen&#39;] = (</span>
<span class="c1">#         X.no_prev_appl / X.AMT_CREDIT).replace(np.inf, 0) </span>
<span class="c1">#     X[&#39;no_prev_app_days_birth_percen&#39;] = (</span>
<span class="c1">#         X.no_prev_appl / X.DAYS_BIRTH).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;no_prev_app_days_employed_percen&#39;] = (</span>
<span class="c1">#         X.no_prev_appl / X.DAYS_EMPLOYED).replace(np.inf, 0) </span>
          
<span class="c1">#     X[&#39;no_approved_prev_appl_income_percen&#39;] = (</span>
<span class="c1">#         X.no_approved_prev_appl / X.AMT_INCOME_TOTAL).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;no_approved_prev_appl_annuity_percen&#39;] = (</span>
<span class="c1">#         X.no_approved_prev_appl / X.AMT_ANNUITY).replace(np.inf, 0)  </span>
<span class="c1">#     X[&#39;no_approved_prev_appl_credit_percen&#39;] = (</span>
<span class="c1">#         X.no_approved_prev_appl / X.AMT_CREDIT).replace(np.inf, 0) </span>
<span class="c1">#     X[&#39;no_approved_prev_appl_days_birth_percen&#39;] = (</span>
<span class="c1">#         X.no_approved_prev_appl / X.DAYS_BIRTH).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;no_approved_prev_appl_days_employed_percen&#39;] = (</span>
<span class="c1">#         X.no_approved_prev_appl / X.DAYS_EMPLOYED).replace(np.inf, 0)  </span>
          
<span class="c1">#     X[&#39;total_creditLimit_income_percen&#39;] = (</span>
<span class="c1">#         X.total_creditLimit / X.AMT_INCOME_TOTAL).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;total_creditLimit_annuity_percen&#39;] = (</span>
<span class="c1">#         X.total_creditLimit / X.AMT_ANNUITY).replace(np.inf, 0)  </span>
<span class="c1">#     X[&#39;total_creditLimit_credit_percen&#39;] = (</span>
<span class="c1">#         X.total_creditLimit / X.AMT_CREDIT).replace(np.inf, 0) </span>
<span class="c1">#     X[&#39;total_creditLimit_days_birth_percen&#39;] = (</span>
<span class="c1">#         X.total_creditLimit / X.DAYS_BIRTH).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;total_creditLimit_days_employed_percen&#39;] = (</span>
<span class="c1">#         X.total_creditLimit / X.DAYS_EMPLOYED).replace(np.inf, 0)  </span>
          
<span class="c1">#     X[&#39;no_of_loans_income_percen&#39;] = (</span>
<span class="c1">#         X.no_of_loans / X.AMT_INCOME_TOTAL).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;no_of_loans_annuity_percen&#39;] = (</span>
<span class="c1">#         X.no_of_loans / X.AMT_ANNUITY).replace(np.inf, 0)  </span>
<span class="c1">#     X[&#39;no_of_loans_credit_percen&#39;] = (</span>
<span class="c1">#         X.no_of_loans / X.AMT_CREDIT).replace(np.inf, 0) </span>
<span class="c1">#     X[&#39;no_of_loans_days_birth_percen&#39;] = (</span>
<span class="c1">#         X.no_of_loans / X.DAYS_BIRTH).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;no_of_loans_days_employed_percen&#39;] = (</span>
<span class="c1">#         X.no_of_loans / X.DAYS_EMPLOYED).replace(np.inf, 0)   </span>
          
<span class="c1">#     X[&#39;utilization_CC_income_percen&#39;] = (</span>
<span class="c1">#         X.utilization_CC / X.AMT_INCOME_TOTAL).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;utilization_CC_annuity_percen&#39;] = (</span>
<span class="c1">#         X.utilization_CC / X.AMT_ANNUITY).replace(np.inf, 0)  </span>
<span class="c1">#     X[&#39;utilization_CC_credit_percen&#39;] = (</span>
<span class="c1">#         X.utilization_CC / X.AMT_CREDIT).replace(np.inf, 0) </span>
<span class="c1">#     X[&#39;utilization_CC_days_birth_percen&#39;] = (</span>
<span class="c1">#         X.utilization_CC / X.DAYS_BIRTH).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;utilization_CC_days_employed_percen&#39;] = (</span>
<span class="c1">#         X.utilization_CC / X.DAYS_EMPLOYED).replace(np.inf, 0) </span>
          
<span class="c1">#     X[&#39;payment_ratio_CC_income_percen&#39;] = (</span>
<span class="c1">#         X.payment_ratio_CC / X.AMT_INCOME_TOTAL).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;payment_ratio_CC_annuity_percen&#39;] = (</span>
<span class="c1">#         X.payment_ratio_CC / X.AMT_ANNUITY).replace(np.inf, 0)  </span>
<span class="c1">#     X[&#39;payment_ratio_CC_credit_percen&#39;] = (</span>
<span class="c1">#         X.payment_ratio_CC / X.AMT_CREDIT).replace(np.inf, 0) </span>
<span class="c1">#     X[&#39;payment_ratio_CC_days_birth_percen&#39;] = (</span>
<span class="c1">#         X.payment_ratio_CC / X.DAYS_BIRTH).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;payment_ratio_CC_days_employed_percen&#39;] = (</span>
<span class="c1">#         X.payment_ratio_CC / X.DAYS_EMPLOYED).replace(np.inf, 0) </span>
          
<span class="c1">#     X[&#39;past_due_times_income_percen&#39;] = (</span>
<span class="c1">#         X.past_due_times / X.AMT_INCOME_TOTAL).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;past_due_timesC_annuity_percen&#39;] = (</span>
<span class="c1">#         X.past_due_times / X.AMT_ANNUITY).replace(np.inf, 0)  </span>
<span class="c1">#     X[&#39;past_due_times_credit_percen&#39;] = (</span>
<span class="c1">#         X.past_due_times / X.AMT_CREDIT).replace(np.inf, 0) </span>
<span class="c1">#     X[&#39;past_due_times_days_birth_percen&#39;] = (</span>
<span class="c1">#         X.past_due_times / X.DAYS_BIRTH).replace(np.inf, 0)</span>
<span class="c1">#     X[&#39;past_due_times_days_employed_percen&#39;] = (</span>
<span class="c1">#         X.past_due_times / X.DAYS_EMPLOYED).replace(np.inf, 0) </span>

          
    <span class="c1"># the following features come from Naimesh and Nishad @thank you</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;income_credit_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">AMT_CREDIT</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;fam_member_income&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">CNT_FAM_MEMBERS</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;ann_incom_percen&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">AMT_ANNUITY</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">AMT_INCOME_TOTAL</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;new_employ_to_birth_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">DAYS_EMPLOYED</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">DAYS_BIRTH</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;new_credit_to_annuity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[</span><span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;new_credit_to_goods_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[</span><span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;new_car_to_birth_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[</span><span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;new_car_to_emp_ratio&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[</span><span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="s1">&#39;new_inc_per_child&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">X</span><span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
          
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">build_ratio_multi_features</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    take ratios of all 2-way combo of numerical features for ratio and multiplication</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">var_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
     <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
     <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
     <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
     <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
     <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
     <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
     <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
     <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
     <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
     <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
     <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
     <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
     <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
     <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
     <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
     <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
     <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
     <span class="s1">&#39;past_due_times&#39;</span><span class="p">]</span>
        
    <span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
     
    <span class="k">for</span> <span class="n">combo</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="n">var_list</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span> 
        <span class="n">ratio_feature_name</span> <span class="o">=</span> <span class="s1">&#39;_&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">combo</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_ratio&#39;</span>
        <span class="n">X</span><span class="p">[</span><span class="n">ratio_feature_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">X</span><span class="p">[</span><span class="n">combo</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[</span><span class="n">combo</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
        <span class="n">multi_feature_name</span> <span class="o">=</span> <span class="s1">&#39;_&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">combo</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_multi&#39;</span>
        <span class="n">X</span><span class="p">[</span><span class="n">multi_feature_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">combo</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">combo</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
          
        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ratio_feature_name</span><span class="p">)</span>
        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">multi_feature_name</span><span class="p">)</span>
<span class="c1">#         print(&#39;&quot;&#39; + ratio_feature_name + &#39;&quot;,&#39;)</span>
<span class="c1">#         print(&#39;&quot;&#39; + multi_feature_name + &#39;&quot;,&#39;)</span>
          
    <span class="k">return</span> <span class="n">X</span>
          
          
<span class="k">def</span> <span class="nf">build_features</span><span class="p">(</span><span class="n">datasets</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from previous application&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_previous_application</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application&#39;</span><span class="p">],</span> <span class="n">datasets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from bureau&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_bureau</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from credit card balance&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_credit_card_balance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from installments&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_installments_payments</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">datasets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features from application&quot;</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">features_from_application</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
          
    <span class="c1"># Converting days to years and removing outliers</span>
    <span class="n">X</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;DAYS&#39;</span><span class="p">)]]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span>
    <span class="n">X</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;DAYS&#39;</span><span class="p">)]])</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">365243</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span><span class="o">/</span><span class="mi">365</span>
    
    <span class="c1">#create new features are the ratio of two numerical features</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">build_ratio_features</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     X = build_ratio_multi_features(X)</span>
          
    <span class="k">return</span> <span class="n">X</span>

          
<span class="k">class</span> <span class="nc">DataFrameSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span> <span class="o">=</span> <span class="n">attribute_names</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    
<span class="k">def</span> <span class="nf">print_msg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">get_standard_pipeline</span><span class="p">(</span><span class="n">cat_attribs</span><span class="p">,</span> <span class="n">num_attribs</span><span class="p">,</span> <span class="n">poly_degree</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  
<span class="c1">#     import pdb; pdb.set_trace()</span>
    <span class="n">num_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;num_selector&#39;</span><span class="p">,</span> <span class="n">DataFrameSelector</span><span class="p">(</span><span class="n">num_attribs</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;print_num_1&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">print_msg</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;num_selector&quot;</span><span class="p">),</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;num_imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;print_num_2&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">print_msg</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;num_imputer&quot;</span><span class="p">),</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;std_scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s1">&#39;print_num_3&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">print_msg</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;num_scaler&quot;</span><span class="p">),</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span> 
        <span class="p">(</span><span class="s1">&#39;polynomial&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">poly_degree</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;print_num_done&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">print_msg</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;num_done&quot;</span><span class="p">),</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>       
    <span class="p">])</span>
<span class="c1">#     import pdb; pdb.set_trace()</span>
    <span class="n">cat_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;cat_selector&#39;</span><span class="p">,</span> <span class="n">DataFrameSelector</span><span class="p">(</span><span class="n">cat_attribs</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;print_cat_1&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">print_msg</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;cat_selector&quot;</span><span class="p">),</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;cat_imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">fill_value</span> <span class="o">=</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;print_cat_2&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">print_msg</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;cat_imputer&quot;</span><span class="p">),</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;print_cat_done&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">print_msg</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="s2">&quot;cat_done&quot;</span><span class="p">),</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="p">])</span>
    <span class="n">num_cat_pipeline</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
        <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
            <span class="p">(</span><span class="s1">&#39;num&#39;</span><span class="p">,</span> <span class="n">num_pipeline</span><span class="p">,</span> <span class="n">num_attribs</span><span class="p">),</span>
            <span class="p">(</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="n">cat_pipeline</span><span class="p">,</span> <span class="n">cat_attribs</span><span class="p">)],</span>
        <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="p">)</span>
<span class="c1">#    num_cat_pipeline = FeatureUnion(transformer_list = [</span>
<span class="c1">#        (&quot;num_pipe&quot;, num_pipeline),</span>
<span class="c1">#        (&quot;cat_pipe&quot;, cat_pipeline)</span>
<span class="c1">#    ],</span>
<span class="c1">#    n_jobs = 2</span>
<span class="c1">#    )</span>
    <span class="k">return</span> <span class="n">num_cat_pipeline</span>

<span class="c1"># default_pipeline = get_standard_pipeline(cat_attribs, num_attribs)</span>

<span class="k">def</span> <span class="nf">pre_process</span><span class="p">(</span><span class="n">preproc_pipeline</span><span class="p">,</span> <span class="n">phase</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Performs all feature engineering, data munging, etc. in a standardized way    </span>
<span class="sd">    Returns: (transformed) X, Y, (fitted) pipeline. If phase == &quot;test&quot;, Y and pipeline will = None</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">datasets</span> <span class="o">=</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">phase</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s1">&#39;application&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">build_features</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>  

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;start pipeline&quot;</span><span class="p">)</span>
<span class="c1">#     import pdb; pdb.set_trace()</span>
    <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
<span class="c1">#         import pdb; pdb.set_trace()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">preproc_pipeline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">preproc_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">preproc_pipeline</span>

<span class="k">def</span> <span class="nf">get_search_class</span><span class="p">(</span><span class="n">search_repr</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">search_repr</span><span class="p">[:</span><span class="n">search_repr</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">get_clf</span><span class="p">(</span><span class="n">search_repr</span><span class="p">):</span>
    <span class="n">e_string</span> <span class="o">=</span> <span class="s1">&#39;estimator=&#39;</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">search_repr</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">e_string</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">e_string</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">search_repr</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;),&#39;</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">search_repr</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    
<span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="n">search_repr</span><span class="p">,</span> <span class="n">is_grid</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">is_grid</span><span class="p">:</span>
        <span class="n">arg_string</span> <span class="o">=</span> <span class="s1">&#39;param_grid=&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">arg_string</span> <span class="o">=</span> <span class="s1">&#39;param_distributions=&#39;</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">search_repr</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">arg_string</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">arg_string</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">search_repr</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;},&#39;</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">search_repr</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">run_test</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> 
             <span class="n">search</span><span class="p">,</span> 
             <span class="n">test_description</span><span class="p">,</span> 
             <span class="n">experiment_name</span><span class="p">,</span> 
             <span class="n">pipeline_named_steps</span><span class="p">,</span>
             <span class="n">cat_attribs</span><span class="p">,</span>
             <span class="n">num_attribs</span><span class="p">,</span>
             <span class="n">testSize</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> 
             <span class="o">**</span><span class="n">fit_params</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Uses grid search to search for best model params</span>
<span class="sd">    NOTE: set early stopping on the estimator you pass in!</span>
<span class="sd">    Logs results, including best model (pickled), to mlflow</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    `X` - training data - will be split into train and test sets</span>
<span class="sd">    `Y` - targets</span>
<span class="sd">    `search`- an instance of GridSearchCV or RandomizedSearchCV</span>
<span class="sd">    `test_description` - description of test run to be logged</span>
<span class="sd">    `experiment_name` - name of experiment that this test run is a part of</span>
<span class="sd">    `pipeline_named_steps` - to be logged alongside metrics for future reference</span>
<span class="sd">    `cat_attribs` - to be logged alongside metrics for future reference</span>
<span class="sd">    `num_attribs` - to be logged alongside metrics for future reference</span>
<span class="sd">    `testSize` - fraction of training set to hold out for sanity check/test </span>
<span class="sd">    `fit_params` - additional parameters to be passed to the search .fit() function</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># train/test split </span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">testSize</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    
    <span class="c1"># start log</span>
    <span class="n">search_repr</span> <span class="o">=</span> <span class="nb">repr</span><span class="p">(</span><span class="n">search</span><span class="p">)</span>
    <span class="n">search_class</span> <span class="o">=</span> <span class="n">get_search_class</span><span class="p">(</span><span class="n">search_repr</span><span class="p">)</span>
    <span class="n">clf_repr</span> <span class="o">=</span> <span class="n">get_clf</span><span class="p">(</span><span class="n">search_repr</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">(</span><span class="n">search_repr</span><span class="p">)</span>

    <span class="n">run_attribs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">))</span>   
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="n">test_description</span><span class="p">))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">cat_attribs</span><span class="p">)))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">num_attribs</span><span class="p">)))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="n">pipeline_named_steps</span><span class="p">))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="n">search_class</span><span class="p">))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
    
<span class="c1">#     import pdb; pdb.set_trace()</span>
    <span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span>

    <span class="c1"># TODO in phase 3: calculate p-value w.r.t. baseline </span>

    <span class="c1"># sanity check with test set</span>
    <span class="n">verification</span> <span class="o">=</span> <span class="n">VerificationTest</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
    <span class="n">verification</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

    <span class="c1"># log: best params, auc, p-value, array of train loss, array of val loss</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">format_num</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;mean_fit_time&#39;</span><span class="p">])))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">format_num</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">format_num</span><span class="p">(</span><span class="n">verification</span><span class="o">.</span><span class="n">test_auc</span><span class="p">))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">format_num</span><span class="p">(</span><span class="n">verification</span><span class="o">.</span><span class="n">test_accuracy</span><span class="p">))</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">format_num</span><span class="p">(</span><span class="n">verification</span><span class="o">.</span><span class="n">prediction_ms_per_row</span><span class="p">))</span>
    <span class="n">run_id</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span>
    <span class="n">run_attribs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrap_in_quotes</span><span class="p">(</span><span class="n">run_id</span><span class="p">))</span>
    <span class="n">line</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">run_attribs</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="s2">&quot;runs.csv&quot;</span><span class="p">),</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">run_file</span><span class="p">:</span>
        <span class="n">run_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>    
        
    <span class="c1"># store best model</span>
    <span class="n">model_file</span> <span class="o">=</span> <span class="n">run_id</span> <span class="o">+</span> <span class="s1">&#39;.joblib&#39;</span>
    <span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="n">model_file</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">VerificationTest</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Runs a verification test against held out test set. Calculates the following metrics,</span>
<span class="sd">    which are available as properties:</span>
<span class="sd">    * test_auc</span>
<span class="sd">    * test_accuracy</span>
<span class="sd">    * prediction_ms_per_row</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        `model` = best_estimator_ from search</span>
<span class="sd">        `significance_score` = Which metric used for p_value? Choose from (&#39;auc&#39;, &#39;accuracy&#39;)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        `X_test`</span>
<span class="sd">        `y_test`</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
        
        <span class="n">y_proba</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_proba</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="n">timing_test</span> <span class="o">=</span> <span class="n">wrapper</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">predict</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
        <span class="n">test_execution_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">timeit</span><span class="p">(</span><span class="n">timing_test</span><span class="p">,</span> <span class="n">setup</span> <span class="o">=</span> <span class="n">gc</span><span class="o">.</span><span class="n">enable</span><span class="p">,</span> <span class="n">number</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prediction_ms_per_row</span> <span class="o">=</span> <span class="n">test_execution_time</span> <span class="o">*</span> <span class="mi">1000000</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
                
<span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">wrapped</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wrapped</span>
        
<span class="k">def</span> <span class="nf">wrap_in_quotes</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;&quot;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;&quot;&#39;</span> <span class="o">+</span> <span class="n">s</span> <span class="o">+</span> <span class="s1">&#39;&quot;&#39;</span>

<span class="k">def</span> <span class="nf">format_num</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="a-small-example-test-case">a small example test case<a class="anchor-link" href="#a-small-example-test-case">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

NUMERIC_COLS = [&#39;EXT_SOURCE_1&#39;, &#39;EXT_SOURCE_2&#39;,&#39;EXT_SOURCE_3&#39;, &#39;no_prev_appl&#39;, &#39;no_approved_prev_appl&#39;,&#39;utilization_CC&#39;,
               &#39;past_due_times&#39;, &#39;OWN_CAR_AGE&#39;, &#39;FLOORSMAX_AVG&#39;, &#39;AMT_GOODS_PRICE&#39;, &#39;REGION_POPULATION_RELATIVE&#39;,
               &#39;AMT_INCOME_TOTAL&#39;,  &#39;AMT_CREDIT&#39;,&#39;DAYS_EMPLOYED&#39;,&#39;credit_income_ratio&#39;, &#39;annuity_income_ratio&#39;]
CATEGORY_COLS = [&#39;CODE_GENDER&#39;, &#39;FLAG_OWN_REALTY&#39;,&#39;FLAG_OWN_CAR&#39;,&#39;NAME_CONTRACT_TYPE&#39;, 
               &#39;NAME_EDUCATION_TYPE&#39;,&#39;OCCUPATION_TYPE&#39;,&#39;NAME_INCOME_TYPE&#39;,
              &#39;FLAG_EMP_PHONE&#39;, &#39;FLAG_WORK_PHONE&#39;, &#39;REGION_RATING_CLIENT&#39;, &#39;REGION_RATING_CLIENT_W_CITY&#39;,
              &#39;ORGANIZATION_TYPE&#39;, &#39;FONDKAPREMONT_MODE&#39;, &#39;WALLSMATERIAL_MODE&#39;]

default_pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS, num_attribs=NUMERIC_COLS)

X, Y, pipe = pre_process(phase = &quot;train&quot;, preproc_pipeline = default_pipeline)
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

from sklearn.linear_model import LogisticRegression
import time

clf = LogisticRegression(penalty = &#39;l1&#39;, solver = &#39;saga&#39;, tol = 0.001, C = 1000)
grid = {&#39;penalty&#39;:[&#39;l1&#39;,&#39;l2&#39;], &#39;C&#39;:[100,10,1]}
search = GridSearchCV(
    estimator = clf,
    param_grid = grid,
    scoring = &#39;roc_auc&#39;, 
    n_jobs = -1, 
    cv = 4)

# log arguments
pipe_steps = repr(pipe.transformers_)
description = &quot;benchmark LogReg with engineered features&quot;
experiment = &quot;LogReg&quot;

start_time = time.time()
run_test(X, Y, search, description, experiment, pipe_steps, cat_attribs=CATEGORY_COLS,
        num_attribs=NUMERIC_COLS)
end_time = time.time()
elapsed_time = end_time - start_time
print(f&quot;Elapsed time: {elapsed_time} seconds&quot;)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Elapsed time: 2.0827078819274902 seconds
Wall time: 2.08 s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  &#34;the coef_ did not converge&#34;, ConvergenceWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Logistic-Regression-using-all-features">Logistic Regression using all features<a class="anchor-link" href="#Logistic-Regression-using-all-features">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># select numerica and categorical features</span>

<span class="n">NUMERIC_COLS_logit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_REGISTRATION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_ID_PUBLISH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;TOTALAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_LAST_PHONE_CHANGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span>
 <span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>

<span class="n">CATEGORY_COLS_logit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_TYPE_SUITE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_FAMILY_STATUS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_HOUSING_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_MOBIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_CONT_MOBILE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMAIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WEEKDAY_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_LIVE_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_LIVE_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUSETYPE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EMERGENCYSTATE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_4&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_5&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_6&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_7&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_8&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_9&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_10&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_11&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_12&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_13&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_14&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_15&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_16&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_17&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_18&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_19&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_20&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_21&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="full-features-with-polynomial-degree-=-1-for-numerical-features">full features with polynomial degree = 1 for numerical features<a class="anchor-link" href="#full-features-with-polynomial-degree-=-1-for-numerical-features">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

logit_full_poly1_pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_logit, num_attribs=NUMERIC_COLS_logit)

X, Y, pipe = pre_process(phase = &quot;train&quot;, preproc_pipeline = logit_full_poly1_pipeline)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>loaded 307511 records
features from previous application
features from bureau
features from credit card balance
features from installments
features from application
start pipeline
Wall time: 1min 17s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

from sklearn.linear_model import LogisticRegression
import time

clf = LogisticRegression(tol = 0.001)
grid_params = {&#39;penalty&#39;: (&#39;l1&#39;, &#39;l2&#39;),
    &#39;C&#39;: (100, 10, 1, 0.1, 0.01),
     }
search = GridSearchCV(
    estimator = clf,
    param_grid = grid_params,
    scoring = &#39;roc_auc&#39;, 
    n_jobs = 2, 
    cv = 5,
    verbose=10)

# log arguments
pipe_steps = repr(pipe.transformers_)
description = &quot;LogReg with full features poly degree = 1&quot;
experiment = &quot;LogReg_full_features_poly1&quot;

start_time = time.time()
run_test(X, Y, search, description, experiment, pipe_steps, cat_attribs=CATEGORY_COLS_logit,
        num_attribs=NUMERIC_COLS_logit)
end_time = time.time()
elapsed_time = end_time - start_time
print(f&quot;Elapsed time: {elapsed_time} seconds&quot;)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 5 folds for each of 10 candidates, totalling 50 fits
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.
[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   28.8s
[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   58.2s
[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  6.1min
[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  7.6min
[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed: 13.3min
[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed: 15.9min
[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 19.3min
[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 21.0min
[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed: 21.5min finished
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Elapsed time: 1408.5411756038666 seconds
Wall time: 23min 28s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="full-features-with-polynomial-degree-=-2-and-pca()-for-numerical-features">full features with polynomial degree = 2 and pca() for numerical features<a class="anchor-link" href="#full-features-with-polynomial-degree-=-2-and-pca()-for-numerical-features">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># for a number of features I only select the median and not mode or average because of memory error</span>

<span class="n">NUMERIC_COLS_logit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_REGISTRATION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_ID_PUBLISH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;TOTALAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_LAST_PHONE_CHANGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span>
 <span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>


<span class="n">CATEGORY_COLS_logit</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_TYPE_SUITE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_FAMILY_STATUS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_HOUSING_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_MOBIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_CONT_MOBILE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMAIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WEEKDAY_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_LIVE_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_LIVE_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUSETYPE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EMERGENCYSTATE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_4&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_5&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_6&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_7&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_8&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_9&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_10&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_11&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_12&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_13&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_14&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_15&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_16&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_17&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_18&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_19&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_20&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_21&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

# create train data
logit_full_poly2_pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_logit, num_attribs=NUMERIC_COLS_logit, poly_degree=2)
X, Y, pipe = pre_process(phase = &quot;train&quot;, preproc_pipeline = logit_full_poly2_pipeline)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>loaded 307511 records
features from previous application
features from bureau
features from credit card balance
features from installments
features from application
start pipeline
Wall time: 2min 3s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

from sklearn.linear_model import LogisticRegression
import time
from tempfile import mkdtemp
from shutil import rmtree
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline

#make a cache for memory
cachedir = mkdtemp()

estimators = [(&#39;pca&#39;, PCA()),
             (&#39;clf&#39;, LogisticRegression(tol = 0.001, n_jobs=2))]
pipeline =Pipeline(estimators, memory=cachedir)

grid_params = {&#39;pca__n_components&#39;:(100, 200, 300, 400),
    &#39;clf__penalty&#39;: (&#39;l1&#39;, &#39;l2&#39;),
    &#39;clf__C&#39;: (1, 0.1, 0.01, 0.001, 0.0001),
     }
search = GridSearchCV(
    estimator = pipeline,
    param_grid = grid_params,
    scoring = &#39;roc_auc&#39;,  
    cv = 5,
    verbose=10)

# log arguments
pipe_steps = repr(pipe.transformers_)
description = &quot;LogReg with full features pca poly degree = 2&quot;
experiment = &quot;LogReg_full_features_poly2_pca&quot;

start_time = time.time()
run_test(X, Y, search, description, experiment, pipe_steps, cat_attribs=CATEGORY_COLS_logit,
        num_attribs=NUMERIC_COLS_logit)
end_time = time.time()
elapsed_time = end_time - start_time
print(f&quot;Elapsed time: {elapsed_time} seconds&quot;)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 5 folds for each of 40 candidates, totalling 200 fits
[CV] clf__C=1, clf__penalty=l1, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 16.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=100, score=0.6525467975997179, total= 2.1min
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=1, clf__penalty=l1, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=100, score=0.6548905718213958, total= 1.1min
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.4min remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=1, clf__penalty=l1, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=100, score=0.644430342311002, total=  58.9s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.4min remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=1, clf__penalty=l1, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=100, score=0.6421079675301269, total= 1.0min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.5min remaining:    0.0s
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=100, score=0.654172122676788, total=  56.5s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.5min remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=1, clf__penalty=l1, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=200, score=0.6934760268122461, total= 1.3min
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  7.9min remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=1, clf__penalty=l1, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=200, score=0.6964838780948602, total= 1.2min
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  9.2min remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=1, clf__penalty=l1, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=200, score=0.6872198001001222, total= 1.3min
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 10.6min remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=1, clf__penalty=l1, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=200, score=0.6902385156850959, total= 1.2min
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 11.9min remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=1, clf__penalty=l1, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=200, score=0.6961195583002735, total= 1.2min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=300, score=0.7052978936419786, total= 1.6min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=300, score=0.7109867769439817, total= 1.7min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=300, score=0.7029680257198035, total= 1.6min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 7.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=300, score=0.7053925268089474, total= 2.2min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 5.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=300, score=0.7082938225477555, total= 1.7min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 5.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=400, score=0.7149181725092294, total= 2.8min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 5.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=400, score=0.7187934455657656, total= 2.4min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=400, score=0.714860028631856, total= 2.2min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=400, score=0.714954861523611, total= 2.4min
[CV] clf__C=1, clf__penalty=l1, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 4.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l1, pca__n_components=400, score=0.7191976188560062, total= 2.3min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=100, score=0.6525499903684078, total=  23.6s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=100, score=0.6548911003981235, total=  26.6s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=100, score=0.6444339057991082, total=  26.7s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=100, score=0.6421042321811852, total=  24.1s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=100 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=100, score=0.654171717426667, total=  23.0s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=200, score=0.6934747937429591, total=  34.9s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=200, score=0.6964802661538874, total=  43.9s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=200, score=0.6872173422183381, total=  44.8s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=200, score=0.6902419647160172, total=  50.7s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=200 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=200, score=0.6961200736727101, total=  38.3s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=300, score=0.7052960176151347, total= 1.1min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=300, score=0.7109827553560448, total= 1.0min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=300, score=0.7029693515664289, total= 1.1min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=300, score=0.7053879325059448, total= 1.1min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=300 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=300, score=0.7082912500904655, total=  56.7s
[CV] clf__C=1, clf__penalty=l2, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=400, score=0.7149148300106974, total= 1.1min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=400, score=0.7187789845874559, total= 1.4min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=400, score=0.7148638740275504, total= 1.3min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=400, score=0.7149573635026191, total= 1.3min
[CV] clf__C=1, clf__penalty=l2, pca__n_components=400 ................
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=1, clf__penalty=l2, pca__n_components=400, score=0.7191945662654206, total= 1.2min
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=100, score=0.65250462222628, total=  10.4s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=100, score=0.6548867088064773, total=  12.0s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=100, score=0.6444133177355628, total=  10.9s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=100, score=0.6420921759900844, total=  12.3s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=100, score=0.6541688850807124, total=  10.6s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=200, score=0.693489942879915, total=  20.3s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=200, score=0.6965338902629168, total=  18.2s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=200, score=0.6872365515775856, total=  16.2s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=200, score=0.6902082012140853, total=  20.8s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=200, score=0.6961032469829018, total=  16.5s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=300, score=0.7052986995408341, total=  22.1s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=300, score=0.7110257330488162, total=  26.5s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=300, score=0.7029566437009328, total=  25.1s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=300, score=0.7054181897133511, total=  32.9s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=300, score=0.7083308765044746, total=  23.1s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=400, score=0.7149461984125975, total=  34.8s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=400, score=0.7189506707134325, total=  39.2s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=400, score=0.7148650413011576, total=  28.6s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=400, score=0.7149117948884657, total=  39.5s
[CV] clf__C=0.1, clf__penalty=l1, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l1, pca__n_components=400, score=0.7192299067189105, total=  32.1s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=100, score=0.6525414909979645, total=  23.5s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=100, score=0.6548839822315233, total=  28.1s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=100, score=0.6444245411814151, total=  28.7s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=100 ..............</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=100, score=0.6420977966330675, total=  28.1s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=100 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=100, score=0.6541635287312866, total=  24.8s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=200, score=0.6934741639968588, total=  37.1s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=200, score=0.6964794556695714, total=  47.6s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=200, score=0.6872138007542623, total=  44.2s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=200, score=0.6902431055832059, total=  53.5s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=200 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=200, score=0.6961183469548029, total=  37.4s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=300, score=0.7052948506031307, total=  53.6s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=300, score=0.7109861206278782, total=  58.5s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=300, score=0.7029675588103607, total= 1.1min
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=300, score=0.705389390525402, total= 1.1min
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=300 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=300, score=0.708291069489868, total=  55.3s
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=400, score=0.7149157592164816, total= 1.0min
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=400, score=0.7187914369742002, total= 1.5min
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=400, score=0.714863711049726, total= 1.3min
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=400, score=0.7149586144921232, total= 1.2min
[CV] clf__C=0.1, clf__penalty=l2, pca__n_components=400 ..............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.1, clf__penalty=l2, pca__n_components=400, score=0.7191960154750925, total= 1.1min
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=100, score=0.6519723282341309, total=  10.1s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=100, score=0.6548316707547011, total=  10.7s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=100, score=0.6442576386748244, total=  11.1s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=100, score=0.6419673589528055, total=  11.7s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=100, score=0.6541389097864336, total=   9.6s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=200, score=0.693472164663086, total=  18.8s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=200, score=0.69700493581865, total=  16.5s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=200, score=0.687176029542259, total=  16.7s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=200, score=0.6898163067274735, total=  17.1s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=200, score=0.6959382176808954, total=  13.9s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=300, score=0.7049358600954655, total=  18.5s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=300, score=0.7111711577210363, total=  20.1s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=300, score=0.702621975345763, total=  18.4s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=300, score=0.7051102128360421, total=  27.9s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=300, score=0.7081706793696723, total=  20.2s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=400, score=0.7145425752005581, total=  25.7s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=400, score=0.7196111581683884, total=  22.4s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=400, score=0.7140856505112961, total=  25.6s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=400, score=0.713802911625212, total=  34.5s
[CV] clf__C=0.01, clf__penalty=l1, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l1, pca__n_components=400, score=0.7187826559467437, total=  25.1s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=100, score=0.6524530843338978, total=  21.1s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=100, score=0.6548180995472164, total=  24.9s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=100, score=0.6443290846291909, total=  25.3s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=100, score=0.6420444665981179, total=  24.4s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=100 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=100, score=0.6540799238693599, total=  21.9s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=200, score=0.693468985105853, total=  34.4s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=200, score=0.6964815655716764, total=  45.1s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=200, score=0.6871828966349136, total=  41.9s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=200, score=0.6902427708113668, total=  49.9s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=200 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=200, score=0.6960989874517384, total=  36.4s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=300, score=0.7052796398127105, total=  51.9s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=300, score=0.711027279135745, total=  57.5s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=300, score=0.7029564851279146, total= 1.1min
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=300, score=0.7053968524135, total= 1.2min
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=300 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=300, score=0.7082865016162212, total=  52.6s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=400, score=0.7149227392694105, total=  58.6s
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=400 .............</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=400, score=0.7188977293493432, total= 1.3min
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=400, score=0.7148906948916773, total= 1.2min
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=400, score=0.7149764719268044, total= 1.2min
[CV] clf__C=0.01, clf__penalty=l2, pca__n_components=400 .............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.01, clf__penalty=l2, pca__n_components=400, score=0.7192080804759785, total= 1.1min
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=100, score=0.6460978011899665, total=   9.0s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=100 ............</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=100, score=0.6528978375578088, total=   9.4s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=100, score=0.6413078017207032, total=   9.1s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=100, score=0.6364684363675159, total=   9.1s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=100, score=0.6503886150440561, total=   8.9s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=200, score=0.6854505997609378, total=  11.1s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=200, score=0.6917231901291678, total=  11.4s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=200, score=0.6769176150313232, total=  10.7s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=200, score=0.6776274182364933, total=  12.4s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=200, score=0.6878235289013154, total=  10.7s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=300, score=0.6914524324013582, total=  13.4s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=300, score=0.7001046286798923, total=  13.6s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=300, score=0.6880255888927281, total=  13.4s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=300, score=0.6857322708908529, total=  14.5s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=300, score=0.6926846935135181, total=  12.2s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=400, score=0.6921692684237792, total=  14.2s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=400, score=0.7009841142827637, total=  16.2s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=400, score=0.6900354270182638, total=  15.2s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=400, score=0.6878980684942302, total=  16.4s
[CV] clf__C=0.001, clf__penalty=l1, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l1, pca__n_components=400, score=0.6909490248646938, total=  14.7s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=100, score=0.651633934387379, total=  23.7s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=100, score=0.654244492487077, total=  24.9s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=100, score=0.6435098876069243, total=  25.1s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=100, score=0.6416512418339347, total=  30.8s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=100 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=100, score=0.6533207846752377, total=  21.1s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=200, score=0.6932309939258038, total=  32.8s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=200, score=0.6964416095758652, total=  38.6s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=200, score=0.6868955182776524, total=  39.8s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=200, score=0.6901051223218859, total=  38.0s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=200 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=200, score=0.695819814167271, total=  31.6s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=300, score=0.7050826173597255, total=  45.2s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=300, score=0.7113081295704184, total=  54.4s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=300, score=0.7027528817771945, total=  55.6s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=300, score=0.705295971562718, total= 1.0min
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=300 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=300, score=0.7081021392405058, total=  44.6s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=400, score=0.7148149602060797, total=  54.3s
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=400, score=0.7196120391296014, total= 1.1min
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=400, score=0.7150017708862061, total= 1.2min
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=400, score=0.7149083722869, total= 1.2min
[CV] clf__C=0.001, clf__penalty=l2, pca__n_components=400 ............
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.001, clf__penalty=l2, pca__n_components=400, score=0.7191727576420591, total=  57.2s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=100, score=0.5752401571983665, total=   8.1s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=100, score=0.5765877175216019, total=   8.4s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=100, score=0.5612704669368846, total=   8.1s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=100, score=0.5885645331525213, total=   8.3s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=100, score=0.5766449157473986, total=   8.3s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=200, score=0.5752385189777423, total=   9.5s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=200, score=0.5765917699431812, total=   9.6s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=200, score=0.5612723389794623, total=   9.6s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=200, score=0.5885360511168407, total=   9.5s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=200, score=0.5766449774158953, total=   9.4s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=300, score=0.5752384749395534, total=  11.1s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=300 ...........
[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=300, score=0.5765899551630826, total=  11.0s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=300, score=0.5612734622050086, total=  11.0s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=300, score=0.5885505916673792, total=  11.2s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=300, score=0.576645594100862, total=  11.4s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=400, score=0.5752388580717962, total=  12.5s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=400, score=0.5765903031427616, total=  12.6s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=400, score=0.5612699780034116, total=  12.4s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=400, score=0.5885544899973477, total=  12.2s
[CV] clf__C=0.0001, clf__penalty=l1, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l1, pca__n_components=400, score=0.5766454267149426, total=  12.8s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=100, score=0.6481680056199071, total=  24.3s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=100, score=0.65114749096234, total=  20.5s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=100, score=0.6402480890728958, total=  20.1s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=100, score=0.6394307662984661, total=  22.4s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=100 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=100, score=0.6498624902646366, total=  26.2s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=200, score=0.6909325747937333, total=  26.7s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=200, score=0.6944153767621576, total=  27.6s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=200, score=0.6850123667793385, total=  32.0s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=200, score=0.6881313868465236, total=  31.6s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=200 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=200, score=0.6937356260094637, total=  26.4s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=300, score=0.7031202888771311, total=  46.3s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=300, score=0.710008412254574, total=  41.0s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=300, score=0.7010164103208288, total=  35.2s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=300, score=0.7030280949777661, total=  40.8s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=300 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=300, score=0.7059913191019181, total=  37.8s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=400, score=0.712872136237316, total=  42.0s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=400, score=0.718865631527551, total=  44.4s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=400, score=0.7134282155869428, total=  52.6s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=400, score=0.7126488782126038, total=  48.5s
[CV] clf__C=0.0001, clf__penalty=l2, pca__n_components=400 ...........
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[CV]  clf__C=0.0001, clf__penalty=l2, pca__n_components=400, score=0.7171360938707283, total=  54.8s
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 152.2min finished
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\pipeline.py:230: UserWarning: Persisting input arguments took 5.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib&#39;s team with an
 example so that they can fix the problem.
  **fit_params_steps[name])
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
C:\Users\stefanie\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:1297: UserWarning: &#39;n_jobs&#39; &gt; 1 does not have any effect when &#39;solver&#39; is set to &#39;liblinear&#39;. Got &#39;n_jobs&#39; = 2.
  &#34; = {}.&#34;.format(effective_n_jobs(self.n_jobs)))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Elapsed time: 9344.747162342072 seconds
Wall time: 2h 35min 44s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>unfortunately, the pac() method doesn't have very good performance</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="lightgbm()-with-early-stopping">lightgbm() with early stopping<a class="anchor-link" href="#lightgbm()-with-early-stopping">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="use-full-featues-with-poly-degree-=-1">use full featues with poly degree = 1<a class="anchor-link" href="#use-full-featues-with-poly-degree-=-1">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># select numerica and categorical features</span>

<span class="n">NUMERIC_COLS_lgbm</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_REGISTRATION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_ID_PUBLISH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;TOTALAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_LAST_PHONE_CHANGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span>
 <span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>

<span class="n">CATEGORY_COLS_lgbm</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_TYPE_SUITE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_FAMILY_STATUS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_HOUSING_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_MOBIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_CONT_MOBILE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMAIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WEEKDAY_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_LIVE_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_LIVE_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUSETYPE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EMERGENCYSTATE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_4&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_5&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_6&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_7&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_8&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_9&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_10&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_11&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_12&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_13&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_14&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_15&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_16&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_17&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_18&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_19&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_20&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_21&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

lgbm_pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_lgbm, num_attribs=NUMERIC_COLS_lgbm)

X, Y, pipe = pre_process(phase = &quot;train&quot;, preproc_pipeline = lgbm_pipeline)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>loaded 307511 records
features from previous application
features from bureau
features from credit card balance
features from installments
features from application
start pipeline
Wall time: 1min 13s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">randint</span> <span class="k">as</span> <span class="n">sp_randint</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">uniform</span> <span class="k">as</span> <span class="n">sp_uniform</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">grid_params</span> <span class="o">=</span><span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
             <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> 
             <span class="s1">&#39;min_child_samples&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> 
             <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1e1</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">],</span>
             <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.14</span><span class="p">),</span>
             <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.8</span><span class="p">),</span>
             <span class="s1">&#39;bagging_fraction&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.6</span><span class="p">),</span>
             <span class="s1">&#39;feature_fraction&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.6</span><span class="p">),</span>
             <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
             <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)}</span>

<span class="n">fit_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;early_stopping_rounds&quot;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> 
            <span class="s2">&quot;eval_metric&quot;</span> <span class="p">:</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span> 
            <span class="s2">&quot;eval_set&quot;</span> <span class="p">:</span> <span class="p">[(</span><span class="n">X_valid</span><span class="p">,</span><span class="n">y_valid</span><span class="p">)],</span>
            <span class="s1">&#39;eval_names&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">],</span>
            <span class="c1">#&#39;callbacks&#39;: [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],</span>
            <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s1">&#39;categorical_feature&#39;</span><span class="p">:</span> <span class="s1">&#39;auto&#39;</span><span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

from lightgbm import LGBMClassifier
import time



clf = LGBMClassifier()
search = RandomizedSearchCV(
    estimator=clf, 
    param_distributions=grid_params, 
    n_iter=100,
    scoring=&#39;roc_auc&#39;,
    cv=5,
    refit=True,
    random_state=42,
    verbose=True)

# log arguments
pipe_steps = repr(pipe.transformers_)
description = &quot;lightweight GB with full features poly degree = 1&quot;
experiment = &quot;Lgbm_full_features_poly1&quot;

start_time = time.time()
run_test(X_train, y_train, search, description, experiment, pipe_steps, cat_attribs=CATEGORY_COLS_lgbm,
        num_attribs=NUMERIC_COLS_lgbm, **fit_params)
end_time = time.time()
elapsed_time = end_time - start_time
print(f&quot;Elapsed time: {elapsed_time} seconds&quot;)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 5 folds for each of 100 candidates, totalling 500 fits
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244642	valid&#39;s auc: 0.761839
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244642	valid&#39;s auc: 0.761839
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244861	valid&#39;s auc: 0.761195
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244861	valid&#39;s auc: 0.761195
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244598	valid&#39;s auc: 0.762061
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244598	valid&#39;s auc: 0.762061
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244784	valid&#39;s auc: 0.761545
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244784	valid&#39;s auc: 0.761545
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244857	valid&#39;s auc: 0.761303
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244857	valid&#39;s auc: 0.761303
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243487	valid&#39;s auc: 0.76542
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243487	valid&#39;s auc: 0.76542
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243761	valid&#39;s auc: 0.764977
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243761	valid&#39;s auc: 0.764977
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243579	valid&#39;s auc: 0.764945
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243579	valid&#39;s auc: 0.764945
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243583	valid&#39;s auc: 0.765517
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243583	valid&#39;s auc: 0.765517
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243374	valid&#39;s auc: 0.765958
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243374	valid&#39;s auc: 0.765958
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243499	valid&#39;s auc: 0.765752
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243499	valid&#39;s auc: 0.765752
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243839	valid&#39;s auc: 0.764445
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243839	valid&#39;s auc: 0.764445
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243495	valid&#39;s auc: 0.76502
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243495	valid&#39;s auc: 0.76502
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243295	valid&#39;s auc: 0.766412
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243295	valid&#39;s auc: 0.766412
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243623	valid&#39;s auc: 0.764956
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243623	valid&#39;s auc: 0.764956
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244551	valid&#39;s auc: 0.762518
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244551	valid&#39;s auc: 0.762518
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244668	valid&#39;s auc: 0.761962
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244668	valid&#39;s auc: 0.761962
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244437	valid&#39;s auc: 0.762841
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244437	valid&#39;s auc: 0.762841
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244327	valid&#39;s auc: 0.763625
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244327	valid&#39;s auc: 0.763625
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244191	valid&#39;s auc: 0.763723
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244191	valid&#39;s auc: 0.763723
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244147	valid&#39;s auc: 0.76344
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244147	valid&#39;s auc: 0.76344
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244134	valid&#39;s auc: 0.763399
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244134	valid&#39;s auc: 0.763399
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244278	valid&#39;s auc: 0.763017
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244278	valid&#39;s auc: 0.763017
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244178	valid&#39;s auc: 0.763933
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244178	valid&#39;s auc: 0.763933
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243957	valid&#39;s auc: 0.764486
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243957	valid&#39;s auc: 0.764486
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249198	valid&#39;s auc: 0.751448
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249198	valid&#39;s auc: 0.751448
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249564	valid&#39;s auc: 0.749761
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249564	valid&#39;s auc: 0.749761
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249486	valid&#39;s auc: 0.749985
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249486	valid&#39;s auc: 0.749985
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249344	valid&#39;s auc: 0.751216
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249344	valid&#39;s auc: 0.751216
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249366	valid&#39;s auc: 0.750328
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249366	valid&#39;s auc: 0.750328
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[35]	valid&#39;s binary_logloss: 0.266418	valid&#39;s auc: 0.730086
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[30]	valid&#39;s binary_logloss: 0.267815	valid&#39;s auc: 0.731749
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[30]	valid&#39;s binary_logloss: 0.267725	valid&#39;s auc: 0.731593
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[32]	valid&#39;s binary_logloss: 0.267359	valid&#39;s auc: 0.730646
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[11]	valid&#39;s binary_logloss: 0.274451	valid&#39;s auc: 0.727005
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24451	valid&#39;s auc: 0.762588
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24451	valid&#39;s auc: 0.762588
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244328	valid&#39;s auc: 0.763375
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244328	valid&#39;s auc: 0.763375
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244333	valid&#39;s auc: 0.763283
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244333	valid&#39;s auc: 0.763283
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244444	valid&#39;s auc: 0.7633
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244444	valid&#39;s auc: 0.7633
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244332	valid&#39;s auc: 0.763435
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244332	valid&#39;s auc: 0.763435
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243971	valid&#39;s auc: 0.764215
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243971	valid&#39;s auc: 0.764215
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243944	valid&#39;s auc: 0.764654
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243944	valid&#39;s auc: 0.764654
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243936	valid&#39;s auc: 0.764671
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243936	valid&#39;s auc: 0.764671
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243882	valid&#39;s auc: 0.764792
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243882	valid&#39;s auc: 0.764792
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243735	valid&#39;s auc: 0.765264
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243735	valid&#39;s auc: 0.765264
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245136	valid&#39;s auc: 0.761141
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245136	valid&#39;s auc: 0.761141
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245402	valid&#39;s auc: 0.760624
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245402	valid&#39;s auc: 0.760624
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245168	valid&#39;s auc: 0.760667
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245168	valid&#39;s auc: 0.760667
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244885	valid&#39;s auc: 0.762735
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244885	valid&#39;s auc: 0.762735
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245076	valid&#39;s auc: 0.761348
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245076	valid&#39;s auc: 0.761348
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243457	valid&#39;s auc: 0.765909
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243457	valid&#39;s auc: 0.765909
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243583	valid&#39;s auc: 0.765802
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243583	valid&#39;s auc: 0.765802
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243686	valid&#39;s auc: 0.765537
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243686	valid&#39;s auc: 0.765537
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243382	valid&#39;s auc: 0.766681
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243382	valid&#39;s auc: 0.766681
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243547	valid&#39;s auc: 0.76566
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243547	valid&#39;s auc: 0.76566
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243364	valid&#39;s auc: 0.76621
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243364	valid&#39;s auc: 0.76621
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243517	valid&#39;s auc: 0.765746
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243517	valid&#39;s auc: 0.765746
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243302	valid&#39;s auc: 0.766019
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243302	valid&#39;s auc: 0.766019
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243543	valid&#39;s auc: 0.765952
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243543	valid&#39;s auc: 0.765952
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243281	valid&#39;s auc: 0.766124
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243281	valid&#39;s auc: 0.766124
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242797	valid&#39;s auc: 0.767823
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242797	valid&#39;s auc: 0.767823
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243099	valid&#39;s auc: 0.766878
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243099	valid&#39;s auc: 0.766878
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242875	valid&#39;s auc: 0.767816
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242875	valid&#39;s auc: 0.767816
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242847	valid&#39;s auc: 0.768432
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242847	valid&#39;s auc: 0.768432
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242718	valid&#39;s auc: 0.768524
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242714	valid&#39;s auc: 0.768546
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24398	valid&#39;s auc: 0.763976
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24398	valid&#39;s auc: 0.763976
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243629	valid&#39;s auc: 0.765293
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243629	valid&#39;s auc: 0.765293
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243708	valid&#39;s auc: 0.76492
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243708	valid&#39;s auc: 0.76492
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243683	valid&#39;s auc: 0.765509
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243683	valid&#39;s auc: 0.765509
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243576	valid&#39;s auc: 0.765125
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243576	valid&#39;s auc: 0.765125
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[25]	valid&#39;s binary_logloss: 0.267966	valid&#39;s auc: 0.742776
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[25]	valid&#39;s binary_logloss: 0.268005	valid&#39;s auc: 0.743012
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[29]	valid&#39;s binary_logloss: 0.265897	valid&#39;s auc: 0.741728
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[30]	valid&#39;s binary_logloss: 0.265703	valid&#39;s auc: 0.74068
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[30]	valid&#39;s binary_logloss: 0.26548	valid&#39;s auc: 0.741255
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246844	valid&#39;s auc: 0.756517
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246844	valid&#39;s auc: 0.756517
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246922	valid&#39;s auc: 0.756033
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246922	valid&#39;s auc: 0.756033
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2469	valid&#39;s auc: 0.75634
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.2469	valid&#39;s auc: 0.75634
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246958	valid&#39;s auc: 0.756288
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246958	valid&#39;s auc: 0.756288
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246825	valid&#39;s auc: 0.756959
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246825	valid&#39;s auc: 0.756959
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244067	valid&#39;s auc: 0.763538
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244067	valid&#39;s auc: 0.763538
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244304	valid&#39;s auc: 0.763588
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244304	valid&#39;s auc: 0.763588
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243887	valid&#39;s auc: 0.764122
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243887	valid&#39;s auc: 0.764122
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244097	valid&#39;s auc: 0.764083
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244097	valid&#39;s auc: 0.764083
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244018	valid&#39;s auc: 0.764261
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244018	valid&#39;s auc: 0.764261
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242603	valid&#39;s auc: 0.768564
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242603	valid&#39;s auc: 0.768564
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242666	valid&#39;s auc: 0.768053
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242666	valid&#39;s auc: 0.768053
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242267	valid&#39;s auc: 0.769441
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242267	valid&#39;s auc: 0.769441
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[76]	valid&#39;s binary_logloss: 0.24276	valid&#39;s auc: 0.768757
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[87]	valid&#39;s binary_logloss: 0.242763	valid&#39;s auc: 0.768401
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[19]	valid&#39;s binary_logloss: 0.257456	valid&#39;s auc: 0.746528
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[18]	valid&#39;s binary_logloss: 0.258421	valid&#39;s auc: 0.745552
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245802	valid&#39;s auc: 0.759041
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245802	valid&#39;s auc: 0.759041
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[18]	valid&#39;s binary_logloss: 0.258282	valid&#39;s auc: 0.746974
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[19]	valid&#39;s binary_logloss: 0.257329	valid&#39;s auc: 0.746835
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245933	valid&#39;s auc: 0.758732
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245933	valid&#39;s auc: 0.758732
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24614	valid&#39;s auc: 0.757778
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24614	valid&#39;s auc: 0.757778
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24573	valid&#39;s auc: 0.759328
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24573	valid&#39;s auc: 0.759328
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245612	valid&#39;s auc: 0.760115
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245612	valid&#39;s auc: 0.760115
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246032	valid&#39;s auc: 0.758244
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246032	valid&#39;s auc: 0.758244
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243502	valid&#39;s auc: 0.765576
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243502	valid&#39;s auc: 0.765576
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243637	valid&#39;s auc: 0.765053
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243637	valid&#39;s auc: 0.765053
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243746	valid&#39;s auc: 0.764916
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243746	valid&#39;s auc: 0.764916
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243785	valid&#39;s auc: 0.765496
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243785	valid&#39;s auc: 0.765496
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243284	valid&#39;s auc: 0.766697
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243284	valid&#39;s auc: 0.766697
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[8]	valid&#39;s binary_logloss: 0.276485	valid&#39;s auc: 0.731597
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[24]	valid&#39;s binary_logloss: 0.270196	valid&#39;s auc: 0.736833
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[31]	valid&#39;s binary_logloss: 0.267924	valid&#39;s auc: 0.736138
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[24]	valid&#39;s binary_logloss: 0.27027	valid&#39;s auc: 0.736641
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[35]	valid&#39;s binary_logloss: 0.26689	valid&#39;s auc: 0.735315
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248809	valid&#39;s auc: 0.751838
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248809	valid&#39;s auc: 0.751838
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248876	valid&#39;s auc: 0.75184
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248876	valid&#39;s auc: 0.75184
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24887	valid&#39;s auc: 0.7517
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24887	valid&#39;s auc: 0.7517
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248813	valid&#39;s auc: 0.75228
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248813	valid&#39;s auc: 0.75228
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248736	valid&#39;s auc: 0.752025
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248736	valid&#39;s auc: 0.752025
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24298	valid&#39;s auc: 0.766944
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24298	valid&#39;s auc: 0.766944
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243401	valid&#39;s auc: 0.765974
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243401	valid&#39;s auc: 0.765974
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243303	valid&#39;s auc: 0.76625
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.2433	valid&#39;s auc: 0.766218
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243135	valid&#39;s auc: 0.766698
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243133	valid&#39;s auc: 0.766737
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243129	valid&#39;s auc: 0.766714
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243129	valid&#39;s auc: 0.766714
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249606	valid&#39;s auc: 0.74968
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249606	valid&#39;s auc: 0.74968
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249793	valid&#39;s auc: 0.748951
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249793	valid&#39;s auc: 0.748951
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249616	valid&#39;s auc: 0.749658
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249616	valid&#39;s auc: 0.749658
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.249638	valid&#39;s auc: 0.750292
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.249638	valid&#39;s auc: 0.750292
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[3]	valid&#39;s binary_logloss: 0.27631	valid&#39;s auc: 0.720217
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243253	valid&#39;s auc: 0.766107
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243253	valid&#39;s auc: 0.766107
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243596	valid&#39;s auc: 0.765488
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243593	valid&#39;s auc: 0.765511
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243077	valid&#39;s auc: 0.766401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243077	valid&#39;s auc: 0.766401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243556	valid&#39;s auc: 0.765298
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243556	valid&#39;s auc: 0.765298
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243298	valid&#39;s auc: 0.7664
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243296	valid&#39;s auc: 0.766422
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248105	valid&#39;s auc: 0.753436
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248105	valid&#39;s auc: 0.753436
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248372	valid&#39;s auc: 0.752754
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248372	valid&#39;s auc: 0.752754
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248135	valid&#39;s auc: 0.753311
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248135	valid&#39;s auc: 0.753311
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248217	valid&#39;s auc: 0.753514
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248217	valid&#39;s auc: 0.753514
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248188	valid&#39;s auc: 0.753219
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248188	valid&#39;s auc: 0.753219
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245288	valid&#39;s auc: 0.760567
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245288	valid&#39;s auc: 0.760567
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245239	valid&#39;s auc: 0.760984
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245239	valid&#39;s auc: 0.760984
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245199	valid&#39;s auc: 0.760976
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245199	valid&#39;s auc: 0.760976
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24508	valid&#39;s auc: 0.761727
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24508	valid&#39;s auc: 0.761727
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245086	valid&#39;s auc: 0.761232
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245086	valid&#39;s auc: 0.761232
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24312	valid&#39;s auc: 0.766726
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24312	valid&#39;s auc: 0.766726
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243268	valid&#39;s auc: 0.766087
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243268	valid&#39;s auc: 0.766087
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243315	valid&#39;s auc: 0.765579
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243315	valid&#39;s auc: 0.765579
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2433	valid&#39;s auc: 0.765989
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.2433	valid&#39;s auc: 0.765989
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243368	valid&#39;s auc: 0.765596
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243368	valid&#39;s auc: 0.765596
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246399	valid&#39;s auc: 0.757901
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246399	valid&#39;s auc: 0.757901
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246644	valid&#39;s auc: 0.757101
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246644	valid&#39;s auc: 0.757101
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246584	valid&#39;s auc: 0.756782
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246584	valid&#39;s auc: 0.756782
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246647	valid&#39;s auc: 0.757326
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246647	valid&#39;s auc: 0.757326
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24655	valid&#39;s auc: 0.757412
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24655	valid&#39;s auc: 0.757412
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243063	valid&#39;s auc: 0.766866
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.243056	valid&#39;s auc: 0.766883
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243192	valid&#39;s auc: 0.766988
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243192	valid&#39;s auc: 0.766988
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243259	valid&#39;s auc: 0.766316
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.243258	valid&#39;s auc: 0.766252
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243289	valid&#39;s auc: 0.767071
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243289	valid&#39;s auc: 0.767071
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243167	valid&#39;s auc: 0.767398
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243167	valid&#39;s auc: 0.767398
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245478	valid&#39;s auc: 0.761361
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245478	valid&#39;s auc: 0.761361
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245892	valid&#39;s auc: 0.759743
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245892	valid&#39;s auc: 0.759743
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245694	valid&#39;s auc: 0.760021
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245694	valid&#39;s auc: 0.760021
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245476	valid&#39;s auc: 0.761593
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245476	valid&#39;s auc: 0.761593
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245497	valid&#39;s auc: 0.761029
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245497	valid&#39;s auc: 0.761029
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246118	valid&#39;s auc: 0.75865
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246118	valid&#39;s auc: 0.75865
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246351	valid&#39;s auc: 0.75761
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246351	valid&#39;s auc: 0.75761
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246345	valid&#39;s auc: 0.757841
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246345	valid&#39;s auc: 0.757841
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246083	valid&#39;s auc: 0.758888
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246083	valid&#39;s auc: 0.758888
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246131	valid&#39;s auc: 0.758762
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246131	valid&#39;s auc: 0.758762
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244344	valid&#39;s auc: 0.763006
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244344	valid&#39;s auc: 0.763006
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244297	valid&#39;s auc: 0.763729
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244297	valid&#39;s auc: 0.763729
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244345	valid&#39;s auc: 0.762867
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244345	valid&#39;s auc: 0.762867
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244373	valid&#39;s auc: 0.763573
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244373	valid&#39;s auc: 0.763573
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244275	valid&#39;s auc: 0.763648
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244275	valid&#39;s auc: 0.763648
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[4]	valid&#39;s binary_logloss: 0.274694	valid&#39;s auc: 0.731674
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247538	valid&#39;s auc: 0.755016
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247538	valid&#39;s auc: 0.755016
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[24]	valid&#39;s binary_logloss: 0.259917	valid&#39;s auc: 0.739722
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247472	valid&#39;s auc: 0.755947
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247472	valid&#39;s auc: 0.755947
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247287	valid&#39;s auc: 0.755833
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247287	valid&#39;s auc: 0.755833
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[12]	valid&#39;s binary_logloss: 0.274989	valid&#39;s auc: 0.711398
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[12]	valid&#39;s binary_logloss: 0.274934	valid&#39;s auc: 0.71239
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[12]	valid&#39;s binary_logloss: 0.274917	valid&#39;s auc: 0.713145
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[12]	valid&#39;s binary_logloss: 0.274982	valid&#39;s auc: 0.712223
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[12]	valid&#39;s binary_logloss: 0.274925	valid&#39;s auc: 0.712036
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.251753	valid&#39;s auc: 0.744924
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.251753	valid&#39;s auc: 0.744924
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.251842	valid&#39;s auc: 0.744586
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.251842	valid&#39;s auc: 0.744586
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[37]	valid&#39;s binary_logloss: 0.260657	valid&#39;s auc: 0.73726
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[37]	valid&#39;s binary_logloss: 0.260827	valid&#39;s auc: 0.737349
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[37]	valid&#39;s binary_logloss: 0.260627	valid&#39;s auc: 0.737823
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242992	valid&#39;s auc: 0.766898
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24299	valid&#39;s auc: 0.766918
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243012	valid&#39;s auc: 0.767325
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243012	valid&#39;s auc: 0.767325
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242504	valid&#39;s auc: 0.76895
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242504	valid&#39;s auc: 0.76895
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243156	valid&#39;s auc: 0.767055
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243156	valid&#39;s auc: 0.767055
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242903	valid&#39;s auc: 0.767757
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242903	valid&#39;s auc: 0.767757
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248643	valid&#39;s auc: 0.752099
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248643	valid&#39;s auc: 0.752099
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248794	valid&#39;s auc: 0.75136
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248794	valid&#39;s auc: 0.75136
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248669	valid&#39;s auc: 0.751889
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248669	valid&#39;s auc: 0.751889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248611	valid&#39;s auc: 0.752443
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248611	valid&#39;s auc: 0.752443
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248638	valid&#39;s auc: 0.751906
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248638	valid&#39;s auc: 0.751906
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243054	valid&#39;s auc: 0.766357
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.243048	valid&#39;s auc: 0.76641
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242532	valid&#39;s auc: 0.769036
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242532	valid&#39;s auc: 0.769036
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242744	valid&#39;s auc: 0.767758
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242744	valid&#39;s auc: 0.767758
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242377	valid&#39;s auc: 0.768936
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242372	valid&#39;s auc: 0.768931
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24281	valid&#39;s auc: 0.767734
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24281	valid&#39;s auc: 0.767734
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248199	valid&#39;s auc: 0.753345
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248199	valid&#39;s auc: 0.753345
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248325	valid&#39;s auc: 0.753026
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248325	valid&#39;s auc: 0.753026
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248211	valid&#39;s auc: 0.753028
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248211	valid&#39;s auc: 0.753028
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248267	valid&#39;s auc: 0.753706
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248267	valid&#39;s auc: 0.753706
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24817	valid&#39;s auc: 0.753452
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24817	valid&#39;s auc: 0.753452
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24698	valid&#39;s auc: 0.756549
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24698	valid&#39;s auc: 0.756549
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24726	valid&#39;s auc: 0.755817
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24726	valid&#39;s auc: 0.755817
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247186	valid&#39;s auc: 0.755776
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247186	valid&#39;s auc: 0.755776
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247131	valid&#39;s auc: 0.756175
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247131	valid&#39;s auc: 0.756175
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24705	valid&#39;s auc: 0.755682
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24705	valid&#39;s auc: 0.755682
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243034	valid&#39;s auc: 0.767026
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243021	valid&#39;s auc: 0.767112
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[77]	valid&#39;s binary_logloss: 0.243115	valid&#39;s auc: 0.766329
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242585	valid&#39;s auc: 0.768096
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242585	valid&#39;s auc: 0.768096
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243233	valid&#39;s auc: 0.766681
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.243228	valid&#39;s auc: 0.76669
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242767	valid&#39;s auc: 0.767738
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242767	valid&#39;s auc: 0.767738
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.251198	valid&#39;s auc: 0.744997
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.251198	valid&#39;s auc: 0.744997
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.251266	valid&#39;s auc: 0.744155
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.251266	valid&#39;s auc: 0.744155
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[4]	valid&#39;s binary_logloss: 0.276655	valid&#39;s auc: 0.720981
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[16]	valid&#39;s binary_logloss: 0.268348	valid&#39;s auc: 0.723111
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[4]	valid&#39;s binary_logloss: 0.276709	valid&#39;s auc: 0.718672
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243907	valid&#39;s auc: 0.764451
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243907	valid&#39;s auc: 0.764451
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243803	valid&#39;s auc: 0.764805
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243803	valid&#39;s auc: 0.764805
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244065	valid&#39;s auc: 0.763395
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244065	valid&#39;s auc: 0.763395
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243805	valid&#39;s auc: 0.765084
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243805	valid&#39;s auc: 0.765084
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244015	valid&#39;s auc: 0.764187
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244015	valid&#39;s auc: 0.764187
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245635	valid&#39;s auc: 0.760583
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245635	valid&#39;s auc: 0.760583
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245696	valid&#39;s auc: 0.760192
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245696	valid&#39;s auc: 0.760192
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245588	valid&#39;s auc: 0.76044
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245588	valid&#39;s auc: 0.76044
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245644	valid&#39;s auc: 0.76092
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245644	valid&#39;s auc: 0.76092
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245418	valid&#39;s auc: 0.760594
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245418	valid&#39;s auc: 0.760594
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245723	valid&#39;s auc: 0.759572
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245723	valid&#39;s auc: 0.759572
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245812	valid&#39;s auc: 0.759013
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245812	valid&#39;s auc: 0.759013
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245753	valid&#39;s auc: 0.759353
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245753	valid&#39;s auc: 0.759353
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245704	valid&#39;s auc: 0.759838
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245704	valid&#39;s auc: 0.759838
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245745	valid&#39;s auc: 0.759668
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245745	valid&#39;s auc: 0.759668
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244533	valid&#39;s auc: 0.762661
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244533	valid&#39;s auc: 0.762661
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244608	valid&#39;s auc: 0.762318
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244608	valid&#39;s auc: 0.762318
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244495	valid&#39;s auc: 0.762291
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244495	valid&#39;s auc: 0.762291
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244444	valid&#39;s auc: 0.763009
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244444	valid&#39;s auc: 0.763009
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244555	valid&#39;s auc: 0.762522
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244555	valid&#39;s auc: 0.762522
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243076	valid&#39;s auc: 0.766735
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243076	valid&#39;s auc: 0.766735
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243156	valid&#39;s auc: 0.767266
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243156	valid&#39;s auc: 0.767266
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243146	valid&#39;s auc: 0.767083
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243146	valid&#39;s auc: 0.767083
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242964	valid&#39;s auc: 0.768103
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242964	valid&#39;s auc: 0.768103
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242834	valid&#39;s auc: 0.767089
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242834	valid&#39;s auc: 0.767089
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245827	valid&#39;s auc: 0.759131
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245827	valid&#39;s auc: 0.759131
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2461	valid&#39;s auc: 0.758079
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.2461	valid&#39;s auc: 0.758079
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246005	valid&#39;s auc: 0.75847
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246005	valid&#39;s auc: 0.75847
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2462	valid&#39;s auc: 0.758087
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.2462	valid&#39;s auc: 0.758087
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24596	valid&#39;s auc: 0.758446
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24596	valid&#39;s auc: 0.758446
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244788	valid&#39;s auc: 0.762361
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244788	valid&#39;s auc: 0.762361
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245168	valid&#39;s auc: 0.761633
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245168	valid&#39;s auc: 0.761633
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244858	valid&#39;s auc: 0.762474
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244858	valid&#39;s auc: 0.762474
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244956	valid&#39;s auc: 0.762819
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244956	valid&#39;s auc: 0.762819
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245008	valid&#39;s auc: 0.762033
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245008	valid&#39;s auc: 0.762033
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244191	valid&#39;s auc: 0.76326
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244191	valid&#39;s auc: 0.76326
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244192	valid&#39;s auc: 0.763063
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244192	valid&#39;s auc: 0.763063
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244165	valid&#39;s auc: 0.762858
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244165	valid&#39;s auc: 0.762858
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244087	valid&#39;s auc: 0.764169
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244087	valid&#39;s auc: 0.764169
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244344	valid&#39;s auc: 0.762779
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244344	valid&#39;s auc: 0.762779
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244099	valid&#39;s auc: 0.763662
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244099	valid&#39;s auc: 0.763662
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243817	valid&#39;s auc: 0.764905
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243817	valid&#39;s auc: 0.764905
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243836	valid&#39;s auc: 0.76445
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243836	valid&#39;s auc: 0.76445
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243752	valid&#39;s auc: 0.764994
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243752	valid&#39;s auc: 0.764994
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243769	valid&#39;s auc: 0.764861
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243769	valid&#39;s auc: 0.764861
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[25]	valid&#39;s binary_logloss: 0.266903	valid&#39;s auc: 0.725961
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[25]	valid&#39;s binary_logloss: 0.266947	valid&#39;s auc: 0.72653
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.253687	valid&#39;s auc: 0.739545
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.253687	valid&#39;s auc: 0.739545
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[9]	valid&#39;s binary_logloss: 0.273995	valid&#39;s auc: 0.71745
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.253629	valid&#39;s auc: 0.739774
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.253629	valid&#39;s auc: 0.739774
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247113	valid&#39;s auc: 0.755518
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247113	valid&#39;s auc: 0.755518
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247151	valid&#39;s auc: 0.755353
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247151	valid&#39;s auc: 0.755353
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247115	valid&#39;s auc: 0.755453
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247115	valid&#39;s auc: 0.755453
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247135	valid&#39;s auc: 0.755892
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247135	valid&#39;s auc: 0.755892
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24712	valid&#39;s auc: 0.755317
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24712	valid&#39;s auc: 0.755317
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243656	valid&#39;s auc: 0.764858
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243656	valid&#39;s auc: 0.764858
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243442	valid&#39;s auc: 0.765784
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243442	valid&#39;s auc: 0.765784
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243481	valid&#39;s auc: 0.765391
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24348	valid&#39;s auc: 0.765426
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243287	valid&#39;s auc: 0.766753
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243287	valid&#39;s auc: 0.766753
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243339	valid&#39;s auc: 0.766517
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243339	valid&#39;s auc: 0.766517
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245373	valid&#39;s auc: 0.761323
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245373	valid&#39;s auc: 0.761323
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245785	valid&#39;s auc: 0.759394
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245785	valid&#39;s auc: 0.759394
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245769	valid&#39;s auc: 0.759022
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245769	valid&#39;s auc: 0.759022
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245454	valid&#39;s auc: 0.760913
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245454	valid&#39;s auc: 0.760913
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245422	valid&#39;s auc: 0.760759
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245422	valid&#39;s auc: 0.760759
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24621	valid&#39;s auc: 0.758246
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24621	valid&#39;s auc: 0.758246
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246519	valid&#39;s auc: 0.757495
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246519	valid&#39;s auc: 0.757495
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246491	valid&#39;s auc: 0.757229
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246491	valid&#39;s auc: 0.757229
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246326	valid&#39;s auc: 0.758512
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246326	valid&#39;s auc: 0.758512
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246453	valid&#39;s auc: 0.757874
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246453	valid&#39;s auc: 0.757874
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.254015	valid&#39;s auc: 0.749217
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.254015	valid&#39;s auc: 0.749217
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.253932	valid&#39;s auc: 0.748502
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.253932	valid&#39;s auc: 0.748502
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[49]	valid&#39;s binary_logloss: 0.261839	valid&#39;s auc: 0.746946
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[49]	valid&#39;s binary_logloss: 0.262017	valid&#39;s auc: 0.746207
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[75]	valid&#39;s binary_logloss: 0.257256	valid&#39;s auc: 0.750054
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[31]	valid&#39;s binary_logloss: 0.258735	valid&#39;s auc: 0.745342
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248266	valid&#39;s auc: 0.753954
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248266	valid&#39;s auc: 0.753954
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[29]	valid&#39;s binary_logloss: 0.259217	valid&#39;s auc: 0.744951
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248316	valid&#39;s auc: 0.753789
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248316	valid&#39;s auc: 0.753789
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248041	valid&#39;s auc: 0.75437
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248041	valid&#39;s auc: 0.75437
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2432	valid&#39;s auc: 0.766995
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.2432	valid&#39;s auc: 0.766995
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243223	valid&#39;s auc: 0.766615
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243218	valid&#39;s auc: 0.766619
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243148	valid&#39;s auc: 0.766821
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243148	valid&#39;s auc: 0.766821
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243113	valid&#39;s auc: 0.767295
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243113	valid&#39;s auc: 0.767295
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24315	valid&#39;s auc: 0.767314
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24315	valid&#39;s auc: 0.767314
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.25356	valid&#39;s auc: 0.740441
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.25356	valid&#39;s auc: 0.740441
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.253732	valid&#39;s auc: 0.739214
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.253732	valid&#39;s auc: 0.739214
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.25362	valid&#39;s auc: 0.739599
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.25362	valid&#39;s auc: 0.739599
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[12]	valid&#39;s binary_logloss: 0.272172	valid&#39;s auc: 0.720547
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.253547	valid&#39;s auc: 0.740553
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.253547	valid&#39;s auc: 0.740553
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.250891	valid&#39;s auc: 0.748038
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.250891	valid&#39;s auc: 0.748038
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.250939	valid&#39;s auc: 0.748137
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.250939	valid&#39;s auc: 0.748137
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.250898	valid&#39;s auc: 0.748064
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.250898	valid&#39;s auc: 0.748064
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.251019	valid&#39;s auc: 0.74811
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.251019	valid&#39;s auc: 0.74811
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.25079	valid&#39;s auc: 0.748599
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.25079	valid&#39;s auc: 0.748599
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.255897	valid&#39;s auc: 0.734098
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.255897	valid&#39;s auc: 0.734098
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.255947	valid&#39;s auc: 0.733707
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.255947	valid&#39;s auc: 0.733707
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[9]	valid&#39;s binary_logloss: 0.275082	valid&#39;s auc: 0.715902
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[9]	valid&#39;s binary_logloss: 0.275148	valid&#39;s auc: 0.715483
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[4]	valid&#39;s binary_logloss: 0.277743	valid&#39;s auc: 0.71692
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245071	valid&#39;s auc: 0.761263
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245071	valid&#39;s auc: 0.761263
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245281	valid&#39;s auc: 0.76059
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245281	valid&#39;s auc: 0.76059
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245317	valid&#39;s auc: 0.760448
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245317	valid&#39;s auc: 0.760448
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24529	valid&#39;s auc: 0.760939
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24529	valid&#39;s auc: 0.760939
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245221	valid&#39;s auc: 0.76103
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245221	valid&#39;s auc: 0.76103
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.255718	valid&#39;s auc: 0.743262
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.255718	valid&#39;s auc: 0.743262
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[18]	valid&#39;s binary_logloss: 0.272765	valid&#39;s auc: 0.7409
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[19]	valid&#39;s binary_logloss: 0.272315	valid&#39;s auc: 0.740934
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[14]	valid&#39;s binary_logloss: 0.274111	valid&#39;s auc: 0.741894
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[9]	valid&#39;s binary_logloss: 0.275658	valid&#39;s auc: 0.734756
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244292	valid&#39;s auc: 0.762909
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244292	valid&#39;s auc: 0.762909
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244638	valid&#39;s auc: 0.761989
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244638	valid&#39;s auc: 0.761989
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244651	valid&#39;s auc: 0.76148
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244651	valid&#39;s auc: 0.76148
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24445	valid&#39;s auc: 0.762937
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24445	valid&#39;s auc: 0.762937
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244306	valid&#39;s auc: 0.763749
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244306	valid&#39;s auc: 0.763749
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.256589	valid&#39;s auc: 0.732039
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.256589	valid&#39;s auc: 0.732039
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.256497	valid&#39;s auc: 0.732013
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.256497	valid&#39;s auc: 0.732013
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.25642	valid&#39;s auc: 0.73265
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.25642	valid&#39;s auc: 0.73265
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[2]	valid&#39;s binary_logloss: 0.279204	valid&#39;s auc: 0.718439
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[2]	valid&#39;s binary_logloss: 0.279205	valid&#39;s auc: 0.717667
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243273	valid&#39;s auc: 0.766065
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243273	valid&#39;s auc: 0.766065
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243599	valid&#39;s auc: 0.765507
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243599	valid&#39;s auc: 0.765507
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243378	valid&#39;s auc: 0.765617
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243378	valid&#39;s auc: 0.765617
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243145	valid&#39;s auc: 0.767106
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243145	valid&#39;s auc: 0.767106
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243425	valid&#39;s auc: 0.765868
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243425	valid&#39;s auc: 0.765868
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24843	valid&#39;s auc: 0.755561
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24843	valid&#39;s auc: 0.755561
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248511	valid&#39;s auc: 0.756079
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248511	valid&#39;s auc: 0.756079
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248504	valid&#39;s auc: 0.754974
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248504	valid&#39;s auc: 0.754974
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248575	valid&#39;s auc: 0.756264
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248575	valid&#39;s auc: 0.756264
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2484	valid&#39;s auc: 0.756143
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.2484	valid&#39;s auc: 0.756143
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245411	valid&#39;s auc: 0.75987
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245411	valid&#39;s auc: 0.75987
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245595	valid&#39;s auc: 0.759506
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245595	valid&#39;s auc: 0.759506
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245625	valid&#39;s auc: 0.759535
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245625	valid&#39;s auc: 0.759535
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245489	valid&#39;s auc: 0.760534
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245489	valid&#39;s auc: 0.760534
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245481	valid&#39;s auc: 0.760083
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245481	valid&#39;s auc: 0.760083
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244135	valid&#39;s auc: 0.763653
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244135	valid&#39;s auc: 0.763653
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244161	valid&#39;s auc: 0.764115
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244161	valid&#39;s auc: 0.764115
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244177	valid&#39;s auc: 0.763922
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244177	valid&#39;s auc: 0.763922
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244127	valid&#39;s auc: 0.764356
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244127	valid&#39;s auc: 0.764356
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244196	valid&#39;s auc: 0.764277
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244196	valid&#39;s auc: 0.764277
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[3]	valid&#39;s binary_logloss: 0.274096	valid&#39;s auc: 0.729698
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[3]	valid&#39;s binary_logloss: 0.274015	valid&#39;s auc: 0.729957
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245447	valid&#39;s auc: 0.759742
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245447	valid&#39;s auc: 0.759742
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245389	valid&#39;s auc: 0.76065
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245389	valid&#39;s auc: 0.76065
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[3]	valid&#39;s binary_logloss: 0.273997	valid&#39;s auc: 0.730299
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243134	valid&#39;s auc: 0.766954
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243134	valid&#39;s auc: 0.766954
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243087	valid&#39;s auc: 0.76652
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243087	valid&#39;s auc: 0.76652
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243036	valid&#39;s auc: 0.766596
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243036	valid&#39;s auc: 0.766596
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242854	valid&#39;s auc: 0.767591
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242849	valid&#39;s auc: 0.767591
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242902	valid&#39;s auc: 0.767604
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242902	valid&#39;s auc: 0.767604
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244094	valid&#39;s auc: 0.763775
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244094	valid&#39;s auc: 0.763775
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244264	valid&#39;s auc: 0.763529
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244264	valid&#39;s auc: 0.763529
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244342	valid&#39;s auc: 0.762974
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244342	valid&#39;s auc: 0.762974
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244158	valid&#39;s auc: 0.764032
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244158	valid&#39;s auc: 0.764032
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244338	valid&#39;s auc: 0.763376
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244338	valid&#39;s auc: 0.763376
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244563	valid&#39;s auc: 0.762699
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244563	valid&#39;s auc: 0.762699
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244537	valid&#39;s auc: 0.762825
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244537	valid&#39;s auc: 0.762825
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244283	valid&#39;s auc: 0.763104
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244283	valid&#39;s auc: 0.763104
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24452	valid&#39;s auc: 0.763334
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24452	valid&#39;s auc: 0.763334
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244431	valid&#39;s auc: 0.763154
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244431	valid&#39;s auc: 0.763154
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247274	valid&#39;s auc: 0.756382
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247274	valid&#39;s auc: 0.756382
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[16]	valid&#39;s binary_logloss: 0.264667	valid&#39;s auc: 0.742744
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247499	valid&#39;s auc: 0.75503
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247499	valid&#39;s auc: 0.75503
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[16]	valid&#39;s binary_logloss: 0.264743	valid&#39;s auc: 0.74232
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247416	valid&#39;s auc: 0.755716
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247416	valid&#39;s auc: 0.755716
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[19]	valid&#39;s binary_logloss: 0.270816	valid&#39;s auc: 0.734793
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[19]	valid&#39;s binary_logloss: 0.270837	valid&#39;s auc: 0.736269
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[21]	valid&#39;s binary_logloss: 0.270021	valid&#39;s auc: 0.735586
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[19]	valid&#39;s binary_logloss: 0.270901	valid&#39;s auc: 0.735257
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[19]	valid&#39;s binary_logloss: 0.270753	valid&#39;s auc: 0.735473
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243545	valid&#39;s auc: 0.765788
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243545	valid&#39;s auc: 0.765788
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243315	valid&#39;s auc: 0.766415
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243315	valid&#39;s auc: 0.766409
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243533	valid&#39;s auc: 0.76509
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243532	valid&#39;s auc: 0.765114
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243293	valid&#39;s auc: 0.766872
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243293	valid&#39;s auc: 0.766872
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243302	valid&#39;s auc: 0.766503
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243302	valid&#39;s auc: 0.766503
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245311	valid&#39;s auc: 0.760748
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245311	valid&#39;s auc: 0.760748
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245502	valid&#39;s auc: 0.760255
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245502	valid&#39;s auc: 0.760255
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245298	valid&#39;s auc: 0.760497
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245298	valid&#39;s auc: 0.760497
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245403	valid&#39;s auc: 0.761134
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245403	valid&#39;s auc: 0.761134
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245259	valid&#39;s auc: 0.76132
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245259	valid&#39;s auc: 0.76132
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245762	valid&#39;s auc: 0.758714
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245762	valid&#39;s auc: 0.758714
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245999	valid&#39;s auc: 0.758
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245999	valid&#39;s auc: 0.758
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245918	valid&#39;s auc: 0.75846
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245918	valid&#39;s auc: 0.75846
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245635	valid&#39;s auc: 0.759539
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245635	valid&#39;s auc: 0.759539
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245766	valid&#39;s auc: 0.758735
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245766	valid&#39;s auc: 0.758735
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243647	valid&#39;s auc: 0.765124
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243634	valid&#39;s auc: 0.765196
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243775	valid&#39;s auc: 0.7648
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243775	valid&#39;s auc: 0.7648
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243718	valid&#39;s auc: 0.764718
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243718	valid&#39;s auc: 0.764715
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243886	valid&#39;s auc: 0.76481
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243886	valid&#39;s auc: 0.76481
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243448	valid&#39;s auc: 0.765725
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243448	valid&#39;s auc: 0.765725
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244216	valid&#39;s auc: 0.763602
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244216	valid&#39;s auc: 0.763602
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244178	valid&#39;s auc: 0.763648
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244178	valid&#39;s auc: 0.763648
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243944	valid&#39;s auc: 0.764574
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243944	valid&#39;s auc: 0.764574
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244217	valid&#39;s auc: 0.76328
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244217	valid&#39;s auc: 0.76328
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244036	valid&#39;s auc: 0.764246
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244036	valid&#39;s auc: 0.764246
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246048	valid&#39;s auc: 0.758401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246048	valid&#39;s auc: 0.758401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246205	valid&#39;s auc: 0.758012
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246205	valid&#39;s auc: 0.758012
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246195	valid&#39;s auc: 0.757785
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246195	valid&#39;s auc: 0.757785
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245935	valid&#39;s auc: 0.758842
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245935	valid&#39;s auc: 0.758842
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246237	valid&#39;s auc: 0.757808
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246237	valid&#39;s auc: 0.757808
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247162	valid&#39;s auc: 0.755877
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247162	valid&#39;s auc: 0.755877
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247443	valid&#39;s auc: 0.754939
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247443	valid&#39;s auc: 0.754939
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[3]	valid&#39;s binary_logloss: 0.27527	valid&#39;s auc: 0.721158
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[3]	valid&#39;s binary_logloss: 0.275339	valid&#39;s auc: 0.720393
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247364	valid&#39;s auc: 0.755411
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247364	valid&#39;s auc: 0.755411
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247305	valid&#39;s auc: 0.755698
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247305	valid&#39;s auc: 0.755698
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24754	valid&#39;s auc: 0.755047
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24754	valid&#39;s auc: 0.755047
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247447	valid&#39;s auc: 0.754968
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247447	valid&#39;s auc: 0.754968
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247388	valid&#39;s auc: 0.755764
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247388	valid&#39;s auc: 0.755764
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247239	valid&#39;s auc: 0.755629
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247239	valid&#39;s auc: 0.755629
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247922	valid&#39;s auc: 0.753507
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247922	valid&#39;s auc: 0.753507
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247841	valid&#39;s auc: 0.753857
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247841	valid&#39;s auc: 0.753857
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247738	valid&#39;s auc: 0.754029
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247738	valid&#39;s auc: 0.754029
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247809	valid&#39;s auc: 0.754239
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247809	valid&#39;s auc: 0.754239
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247685	valid&#39;s auc: 0.754234
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247685	valid&#39;s auc: 0.754234
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244583	valid&#39;s auc: 0.762822
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244583	valid&#39;s auc: 0.762822
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244704	valid&#39;s auc: 0.762336
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244704	valid&#39;s auc: 0.762336
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244706	valid&#39;s auc: 0.76217
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244706	valid&#39;s auc: 0.76217
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244747	valid&#39;s auc: 0.762337
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244747	valid&#39;s auc: 0.762337
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244591	valid&#39;s auc: 0.762448
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244591	valid&#39;s auc: 0.762448
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.250288	valid&#39;s auc: 0.756773
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.250288	valid&#39;s auc: 0.756773
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.250208	valid&#39;s auc: 0.755831
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.250208	valid&#39;s auc: 0.755831
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.250348	valid&#39;s auc: 0.756131
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.250348	valid&#39;s auc: 0.756131
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.25043	valid&#39;s auc: 0.756446
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.25043	valid&#39;s auc: 0.756446
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.250033	valid&#39;s auc: 0.756465
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.250033	valid&#39;s auc: 0.756465
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248004	valid&#39;s auc: 0.754042
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248004	valid&#39;s auc: 0.754042
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248163	valid&#39;s auc: 0.753662
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248163	valid&#39;s auc: 0.753662
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247818	valid&#39;s auc: 0.754507
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247818	valid&#39;s auc: 0.754507
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248131	valid&#39;s auc: 0.754349
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248131	valid&#39;s auc: 0.754349
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.248055	valid&#39;s auc: 0.753517
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.248055	valid&#39;s auc: 0.753517
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242711	valid&#39;s auc: 0.768031
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.2427	valid&#39;s auc: 0.768055
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242676	valid&#39;s auc: 0.768536
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242676	valid&#39;s auc: 0.768536
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242925	valid&#39;s auc: 0.767044
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242925	valid&#39;s auc: 0.767044
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242461	valid&#39;s auc: 0.769231
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242461	valid&#39;s auc: 0.769231
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242093	valid&#39;s auc: 0.770224
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242093	valid&#39;s auc: 0.770224
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243347	valid&#39;s auc: 0.765911
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243347	valid&#39;s auc: 0.765911
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243226	valid&#39;s auc: 0.766817
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243226	valid&#39;s auc: 0.766817
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243297	valid&#39;s auc: 0.765898
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243297	valid&#39;s auc: 0.765898
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243076	valid&#39;s auc: 0.767145
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243076	valid&#39;s auc: 0.767145
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243108	valid&#39;s auc: 0.766987
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243108	valid&#39;s auc: 0.766987
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246005	valid&#39;s auc: 0.758403
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246005	valid&#39;s auc: 0.758403
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246185	valid&#39;s auc: 0.757813
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246185	valid&#39;s auc: 0.757813
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246148	valid&#39;s auc: 0.757661
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246148	valid&#39;s auc: 0.757661
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246086	valid&#39;s auc: 0.758538
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246086	valid&#39;s auc: 0.758538
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24615	valid&#39;s auc: 0.758024
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24615	valid&#39;s auc: 0.758024
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.254731	valid&#39;s auc: 0.737716
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.254731	valid&#39;s auc: 0.737716
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.254729	valid&#39;s auc: 0.737293
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.254729	valid&#39;s auc: 0.737293
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.254525	valid&#39;s auc: 0.738315
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.254525	valid&#39;s auc: 0.738315
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[11]	valid&#39;s binary_logloss: 0.273832	valid&#39;s auc: 0.718341
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.254563	valid&#39;s auc: 0.737918
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.254563	valid&#39;s auc: 0.737918
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243244	valid&#39;s auc: 0.76634
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243244	valid&#39;s auc: 0.76634
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243405	valid&#39;s auc: 0.765978
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243389	valid&#39;s auc: 0.766019
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243141	valid&#39;s auc: 0.766569
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243141	valid&#39;s auc: 0.766569
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243496	valid&#39;s auc: 0.765684
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243496	valid&#39;s auc: 0.765684
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243039	valid&#39;s auc: 0.767527
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243039	valid&#39;s auc: 0.767527
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247245	valid&#39;s auc: 0.755936
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247245	valid&#39;s auc: 0.755936
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247457	valid&#39;s auc: 0.755226
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247457	valid&#39;s auc: 0.755226
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247402	valid&#39;s auc: 0.755108
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247402	valid&#39;s auc: 0.755108
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247222	valid&#39;s auc: 0.75644
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247222	valid&#39;s auc: 0.75644
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.247195	valid&#39;s auc: 0.755951
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.247195	valid&#39;s auc: 0.755951
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242824	valid&#39;s auc: 0.767782
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242823	valid&#39;s auc: 0.767767
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242759	valid&#39;s auc: 0.768176
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242759	valid&#39;s auc: 0.768176
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242641	valid&#39;s auc: 0.768251
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242641	valid&#39;s auc: 0.768251
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242814	valid&#39;s auc: 0.768437
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242802	valid&#39;s auc: 0.768469
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242709	valid&#39;s auc: 0.768166
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242709	valid&#39;s auc: 0.768166
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243576	valid&#39;s auc: 0.765466
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243576	valid&#39;s auc: 0.765466
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243657	valid&#39;s auc: 0.765308
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243657	valid&#39;s auc: 0.765308
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243663	valid&#39;s auc: 0.764802
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243663	valid&#39;s auc: 0.764802
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243537	valid&#39;s auc: 0.765632
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243537	valid&#39;s auc: 0.765632
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243252	valid&#39;s auc: 0.766532
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243252	valid&#39;s auc: 0.766532
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24575	valid&#39;s auc: 0.758916
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24575	valid&#39;s auc: 0.758916
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.246123	valid&#39;s auc: 0.757503
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.246123	valid&#39;s auc: 0.757503
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245687	valid&#39;s auc: 0.75889
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245687	valid&#39;s auc: 0.75889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.245721	valid&#39;s auc: 0.75939
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.245721	valid&#39;s auc: 0.75939
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24599	valid&#39;s auc: 0.758172
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24599	valid&#39;s auc: 0.758172
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244092	valid&#39;s auc: 0.763953
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244092	valid&#39;s auc: 0.763953
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244248	valid&#39;s auc: 0.763289
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244248	valid&#39;s auc: 0.763289
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244248	valid&#39;s auc: 0.763258
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244248	valid&#39;s auc: 0.763258
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.244117	valid&#39;s auc: 0.763689
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.244117	valid&#39;s auc: 0.763689
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243944	valid&#39;s auc: 0.764611
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243944	valid&#39;s auc: 0.764611
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 67.8min finished
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242128	valid&#39;s auc: 0.77025
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242128	valid&#39;s auc: 0.77025
Elapsed time: 4077.7178342342377 seconds
Wall time: 1h 7min 57s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>narrow down the search area based on previous randomized searh</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_params</span> <span class="o">=</span><span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span>
             <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">),</span> 
             <span class="s1">&#39;min_child_samples&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span> 
             <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">],</span>
             <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.05</span><span class="p">),</span>
             <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
             <span class="s1">&#39;bagging_fraction&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.25</span><span class="p">),</span>
             <span class="s1">&#39;feature_fraction&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
             <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
             <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">)}</span>

<span class="n">fit_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;early_stopping_rounds&quot;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> 
            <span class="s2">&quot;eval_metric&quot;</span> <span class="p">:</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span> 
            <span class="s2">&quot;eval_set&quot;</span> <span class="p">:</span> <span class="p">[(</span><span class="n">X_valid</span><span class="p">,</span><span class="n">y_valid</span><span class="p">)],</span>
            <span class="s1">&#39;eval_names&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">],</span>
            <span class="c1">#&#39;callbacks&#39;: [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],</span>
            <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s1">&#39;categorical_feature&#39;</span><span class="p">:</span> <span class="s1">&#39;auto&#39;</span><span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

from lightgbm import LGBMClassifier
import time

clf = LGBMClassifier(n_jobs=2)
search = RandomizedSearchCV(
    estimator=clf, 
    param_distributions=grid_params, 
    n_iter=100,
    scoring=&#39;roc_auc&#39;,
    cv=5,
    refit=True,
    random_state=42,
    verbose=True)

# log arguments
pipe_steps = repr(pipe.transformers_)
description = &quot;lightweight GB with full features poly degree = 1 narrowed area&quot;
experiment = &quot;Lgbm_full_features_poly1_smaller_area&quot;

start_time = time.time()
run_test(X_train, y_train, search, description, experiment, pipe_steps, cat_attribs=CATEGORY_COLS_lgbm,
        num_attribs=NUMERIC_COLS_lgbm, **fit_params)
end_time = time.time()
elapsed_time = end_time - start_time
print(f&quot;Elapsed time: {elapsed_time} seconds&quot;)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 5 folds for each of 100 candidates, totalling 500 fits
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242687	valid&#39;s auc: 0.767987
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242687	valid&#39;s auc: 0.767987
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242879	valid&#39;s auc: 0.767952
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242879	valid&#39;s auc: 0.767952
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242854	valid&#39;s auc: 0.767657
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242818	valid&#39;s auc: 0.767748
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242706	valid&#39;s auc: 0.768648
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242706	valid&#39;s auc: 0.768648
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242855	valid&#39;s auc: 0.768184
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242855	valid&#39;s auc: 0.768184
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242826	valid&#39;s auc: 0.767243
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242815	valid&#39;s auc: 0.767296
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242444	valid&#39;s auc: 0.768687
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242444	valid&#39;s auc: 0.768687
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242607	valid&#39;s auc: 0.768316
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242607	valid&#39;s auc: 0.768316
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242529	valid&#39;s auc: 0.769108
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242529	valid&#39;s auc: 0.769108
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242512	valid&#39;s auc: 0.768283
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242512	valid&#39;s auc: 0.768283
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242429	valid&#39;s auc: 0.768527
Did not meet early stopping. Best iteration is:
[94]	valid&#39;s binary_logloss: 0.24239	valid&#39;s auc: 0.76865
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242846	valid&#39;s auc: 0.767525
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242826	valid&#39;s auc: 0.76761
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242547	valid&#39;s auc: 0.768317
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242542	valid&#39;s auc: 0.768303
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242867	valid&#39;s auc: 0.767729
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242867	valid&#39;s auc: 0.767729
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242487	valid&#39;s auc: 0.769224
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242487	valid&#39;s auc: 0.769224
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242377	valid&#39;s auc: 0.768963
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242377	valid&#39;s auc: 0.768963
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242903	valid&#39;s auc: 0.76748
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242903	valid&#39;s auc: 0.76748
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242862	valid&#39;s auc: 0.767678
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242853	valid&#39;s auc: 0.767735
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242752	valid&#39;s auc: 0.76806
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242752	valid&#39;s auc: 0.76806
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242088	valid&#39;s auc: 0.769641
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242088	valid&#39;s auc: 0.769641
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242821	valid&#39;s auc: 0.767889
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242821	valid&#39;s auc: 0.767889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242933	valid&#39;s auc: 0.767697
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242933	valid&#39;s auc: 0.767697
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242688	valid&#39;s auc: 0.768207
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242688	valid&#39;s auc: 0.768207
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24248	valid&#39;s auc: 0.76961
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24248	valid&#39;s auc: 0.76961
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242193	valid&#39;s auc: 0.769999
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242193	valid&#39;s auc: 0.769999
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242691	valid&#39;s auc: 0.768199
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242691	valid&#39;s auc: 0.768199
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24258	valid&#39;s auc: 0.768445
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24258	valid&#39;s auc: 0.768445
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242778	valid&#39;s auc: 0.767445
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242769	valid&#39;s auc: 0.767493
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242524	valid&#39;s auc: 0.768781
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242524	valid&#39;s auc: 0.768781
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24251	valid&#39;s auc: 0.768775
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24251	valid&#39;s auc: 0.768775
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242485	valid&#39;s auc: 0.768415
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242485	valid&#39;s auc: 0.768415
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242922	valid&#39;s auc: 0.767878
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242921	valid&#39;s auc: 0.767888
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242637	valid&#39;s auc: 0.767769
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242637	valid&#39;s auc: 0.767769
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242485	valid&#39;s auc: 0.769381
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242485	valid&#39;s auc: 0.769381
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242265	valid&#39;s auc: 0.769719
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242258	valid&#39;s auc: 0.769762
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242786	valid&#39;s auc: 0.767349
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242779	valid&#39;s auc: 0.767364
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242695	valid&#39;s auc: 0.767661
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242695	valid&#39;s auc: 0.767661
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242813	valid&#39;s auc: 0.767407
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242813	valid&#39;s auc: 0.767407
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242696	valid&#39;s auc: 0.76841
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242693	valid&#39;s auc: 0.768403
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242591	valid&#39;s auc: 0.767899
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242591	valid&#39;s auc: 0.767899
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242599	valid&#39;s auc: 0.768066
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242589	valid&#39;s auc: 0.768086
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[76]	valid&#39;s binary_logloss: 0.242862	valid&#39;s auc: 0.767744
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24235	valid&#39;s auc: 0.769401
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242336	valid&#39;s auc: 0.769383
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242888	valid&#39;s auc: 0.768138
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242878	valid&#39;s auc: 0.768157
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242478	valid&#39;s auc: 0.768148
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242456	valid&#39;s auc: 0.76818
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242735	valid&#39;s auc: 0.767905
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242735	valid&#39;s auc: 0.767905
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243107	valid&#39;s auc: 0.76684
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243107	valid&#39;s auc: 0.76684
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243084	valid&#39;s auc: 0.766258
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243084	valid&#39;s auc: 0.766247
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242899	valid&#39;s auc: 0.767863
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242899	valid&#39;s auc: 0.767863
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242693	valid&#39;s auc: 0.768402
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242693	valid&#39;s auc: 0.768402
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242557	valid&#39;s auc: 0.768215
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242557	valid&#39;s auc: 0.768215
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242593	valid&#39;s auc: 0.76848
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242564	valid&#39;s auc: 0.768553
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242639	valid&#39;s auc: 0.76861
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242639	valid&#39;s auc: 0.76861
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242518	valid&#39;s auc: 0.768937
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242496	valid&#39;s auc: 0.768913
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242442	valid&#39;s auc: 0.769104
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242393	valid&#39;s auc: 0.769384
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242295	valid&#39;s auc: 0.769162
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242274	valid&#39;s auc: 0.769211
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242751	valid&#39;s auc: 0.76814
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242751	valid&#39;s auc: 0.76814
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242722	valid&#39;s auc: 0.767839
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242697	valid&#39;s auc: 0.767865
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242279	valid&#39;s auc: 0.769321
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242279	valid&#39;s auc: 0.769321
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242659	valid&#39;s auc: 0.768517
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242608	valid&#39;s auc: 0.768608
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24278	valid&#39;s auc: 0.767698
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24278	valid&#39;s auc: 0.767698
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242877	valid&#39;s auc: 0.767695
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242877	valid&#39;s auc: 0.767695
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242958	valid&#39;s auc: 0.7664
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242958	valid&#39;s auc: 0.7664
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242823	valid&#39;s auc: 0.768524
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242823	valid&#39;s auc: 0.768524
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242794	valid&#39;s auc: 0.767816
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242794	valid&#39;s auc: 0.767816
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242533	valid&#39;s auc: 0.768252
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242533	valid&#39;s auc: 0.768252
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242199	valid&#39;s auc: 0.76959
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242192	valid&#39;s auc: 0.769629
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242676	valid&#39;s auc: 0.767599
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242676	valid&#39;s auc: 0.767617
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242565	valid&#39;s auc: 0.768605
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242565	valid&#39;s auc: 0.768605
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242436	valid&#39;s auc: 0.768712
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242432	valid&#39;s auc: 0.768709
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242765	valid&#39;s auc: 0.768101
Did not meet early stopping. Best iteration is:
[93]	valid&#39;s binary_logloss: 0.242711	valid&#39;s auc: 0.768386
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242363	valid&#39;s auc: 0.769862
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242363	valid&#39;s auc: 0.769862
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242767	valid&#39;s auc: 0.767764
Did not meet early stopping. Best iteration is:
[92]	valid&#39;s binary_logloss: 0.242714	valid&#39;s auc: 0.767927
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243038	valid&#39;s auc: 0.767342
Early stopping, best iteration is:
[90]	valid&#39;s binary_logloss: 0.243034	valid&#39;s auc: 0.767313
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[88]	valid&#39;s binary_logloss: 0.242773	valid&#39;s auc: 0.768182
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242646	valid&#39;s auc: 0.768402
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242646	valid&#39;s auc: 0.768402
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24295	valid&#39;s auc: 0.767709
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242929	valid&#39;s auc: 0.767761
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242931	valid&#39;s auc: 0.767243
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242931	valid&#39;s auc: 0.767243
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24267	valid&#39;s auc: 0.768615
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24267	valid&#39;s auc: 0.768615
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242641	valid&#39;s auc: 0.768545
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242641	valid&#39;s auc: 0.768545
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242773	valid&#39;s auc: 0.767451
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242773	valid&#39;s auc: 0.767451
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242416	valid&#39;s auc: 0.76896
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242416	valid&#39;s auc: 0.76896
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242576	valid&#39;s auc: 0.768466
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242576	valid&#39;s auc: 0.768466
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242494	valid&#39;s auc: 0.768802
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242493	valid&#39;s auc: 0.768821
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242267	valid&#39;s auc: 0.769342
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242267	valid&#39;s auc: 0.769342
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243082	valid&#39;s auc: 0.766948
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243082	valid&#39;s auc: 0.766948
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243007	valid&#39;s auc: 0.767084
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243007	valid&#39;s auc: 0.767084
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243299	valid&#39;s auc: 0.766659
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243299	valid&#39;s auc: 0.766659
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242857	valid&#39;s auc: 0.768074
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242853	valid&#39;s auc: 0.768087
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24276	valid&#39;s auc: 0.76835
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24276	valid&#39;s auc: 0.76835
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242379	valid&#39;s auc: 0.768922
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242379	valid&#39;s auc: 0.768922
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242379	valid&#39;s auc: 0.769058
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.24237	valid&#39;s auc: 0.769107
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242281	valid&#39;s auc: 0.769047
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242281	valid&#39;s auc: 0.769047
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242436	valid&#39;s auc: 0.769282
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242436	valid&#39;s auc: 0.769282
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24254	valid&#39;s auc: 0.768465
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242509	valid&#39;s auc: 0.768558
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242411	valid&#39;s auc: 0.769015
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242411	valid&#39;s auc: 0.769015
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242548	valid&#39;s auc: 0.768832
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242548	valid&#39;s auc: 0.768832
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242635	valid&#39;s auc: 0.767508
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242635	valid&#39;s auc: 0.767508
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242342	valid&#39;s auc: 0.769591
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242342	valid&#39;s auc: 0.769591
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242253	valid&#39;s auc: 0.769858
Did not meet early stopping. Best iteration is:
[93]	valid&#39;s binary_logloss: 0.242206	valid&#39;s auc: 0.770012
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242609	valid&#39;s auc: 0.767938
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242609	valid&#39;s auc: 0.767938
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242521	valid&#39;s auc: 0.76863
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242521	valid&#39;s auc: 0.76863
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24277	valid&#39;s auc: 0.767942
Did not meet early stopping. Best iteration is:
[93]	valid&#39;s binary_logloss: 0.242757	valid&#39;s auc: 0.767918
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242712	valid&#39;s auc: 0.76823
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242708	valid&#39;s auc: 0.768309
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242628	valid&#39;s auc: 0.768546
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242628	valid&#39;s auc: 0.768546
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242622	valid&#39;s auc: 0.768015
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242622	valid&#39;s auc: 0.768015
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242988	valid&#39;s auc: 0.767618
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242988	valid&#39;s auc: 0.767618
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242899	valid&#39;s auc: 0.767164
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242899	valid&#39;s auc: 0.767164
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242812	valid&#39;s auc: 0.768153
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242812	valid&#39;s auc: 0.768153
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242892	valid&#39;s auc: 0.767524
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242892	valid&#39;s auc: 0.767524
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242556	valid&#39;s auc: 0.76817
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242556	valid&#39;s auc: 0.76817
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242934	valid&#39;s auc: 0.767301
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242927	valid&#39;s auc: 0.767323
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242726	valid&#39;s auc: 0.767781
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242723	valid&#39;s auc: 0.7678
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242638	valid&#39;s auc: 0.768874
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242638	valid&#39;s auc: 0.768874
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242677	valid&#39;s auc: 0.768257
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242643	valid&#39;s auc: 0.768353
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242644	valid&#39;s auc: 0.768338
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242626	valid&#39;s auc: 0.768363
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242619	valid&#39;s auc: 0.768487
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242617	valid&#39;s auc: 0.768522
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242821	valid&#39;s auc: 0.76783
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242795	valid&#39;s auc: 0.767893
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242594	valid&#39;s auc: 0.768836
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242581	valid&#39;s auc: 0.768831
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242577	valid&#39;s auc: 0.769679
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242577	valid&#39;s auc: 0.769679
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24272	valid&#39;s auc: 0.767524
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24272	valid&#39;s auc: 0.767524
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242324	valid&#39;s auc: 0.769267
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242237	valid&#39;s auc: 0.769525
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242465	valid&#39;s auc: 0.768898
Did not meet early stopping. Best iteration is:
[91]	valid&#39;s binary_logloss: 0.242415	valid&#39;s auc: 0.769097
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242622	valid&#39;s auc: 0.769219
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242607	valid&#39;s auc: 0.769163
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[79]	valid&#39;s binary_logloss: 0.242665	valid&#39;s auc: 0.768089
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242317	valid&#39;s auc: 0.769249
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242303	valid&#39;s auc: 0.76928
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[82]	valid&#39;s binary_logloss: 0.24309	valid&#39;s auc: 0.767073
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[83]	valid&#39;s binary_logloss: 0.242878	valid&#39;s auc: 0.767021
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242474	valid&#39;s auc: 0.768883
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242474	valid&#39;s auc: 0.768883
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[89]	valid&#39;s binary_logloss: 0.242376	valid&#39;s auc: 0.769041
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243022	valid&#39;s auc: 0.766918
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243022	valid&#39;s auc: 0.766918
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242678	valid&#39;s auc: 0.768669
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242675	valid&#39;s auc: 0.768641
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242655	valid&#39;s auc: 0.76816
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242655	valid&#39;s auc: 0.76816
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242486	valid&#39;s auc: 0.769375
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242486	valid&#39;s auc: 0.769375
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2423	valid&#39;s auc: 0.769773
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.2423	valid&#39;s auc: 0.769773
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242988	valid&#39;s auc: 0.766776
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242988	valid&#39;s auc: 0.766776
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242818	valid&#39;s auc: 0.768075
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242818	valid&#39;s auc: 0.768075
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243245	valid&#39;s auc: 0.766261
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243245	valid&#39;s auc: 0.766261
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24266	valid&#39;s auc: 0.768797
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24266	valid&#39;s auc: 0.768797
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242437	valid&#39;s auc: 0.769477
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242437	valid&#39;s auc: 0.769477
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242777	valid&#39;s auc: 0.767237
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242777	valid&#39;s auc: 0.767237
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242764	valid&#39;s auc: 0.768553
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242764	valid&#39;s auc: 0.768553
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242926	valid&#39;s auc: 0.767513
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242926	valid&#39;s auc: 0.767513
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242667	valid&#39;s auc: 0.768393
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242658	valid&#39;s auc: 0.768402
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242553	valid&#39;s auc: 0.768713
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242553	valid&#39;s auc: 0.768713
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242601	valid&#39;s auc: 0.768265
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242601	valid&#39;s auc: 0.768265
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242671	valid&#39;s auc: 0.76879
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242671	valid&#39;s auc: 0.76879
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242333	valid&#39;s auc: 0.769353
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242333	valid&#39;s auc: 0.769353
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242397	valid&#39;s auc: 0.769617
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242397	valid&#39;s auc: 0.769617
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242816	valid&#39;s auc: 0.768368
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242816	valid&#39;s auc: 0.768368
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242585	valid&#39;s auc: 0.767955
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242555	valid&#39;s auc: 0.767998
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24277	valid&#39;s auc: 0.768601
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242767	valid&#39;s auc: 0.768571
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242456	valid&#39;s auc: 0.768682
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242456	valid&#39;s auc: 0.768682
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242562	valid&#39;s auc: 0.768888
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242562	valid&#39;s auc: 0.768888
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[78]	valid&#39;s binary_logloss: 0.242701	valid&#39;s auc: 0.768266
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242501	valid&#39;s auc: 0.768552
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242501	valid&#39;s auc: 0.768552
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242575	valid&#39;s auc: 0.768638
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242546	valid&#39;s auc: 0.768763
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242608	valid&#39;s auc: 0.76775
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242608	valid&#39;s auc: 0.76775
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242275	valid&#39;s auc: 0.769847
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242275	valid&#39;s auc: 0.769847
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242268	valid&#39;s auc: 0.769281
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242256	valid&#39;s auc: 0.7693
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242798	valid&#39;s auc: 0.767808
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242798	valid&#39;s auc: 0.767808
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242656	valid&#39;s auc: 0.768524
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242648	valid&#39;s auc: 0.768615
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24291	valid&#39;s auc: 0.76685
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24291	valid&#39;s auc: 0.76685
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24307	valid&#39;s auc: 0.766825
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24307	valid&#39;s auc: 0.766825
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242669	valid&#39;s auc: 0.768349
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242669	valid&#39;s auc: 0.768349
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242548	valid&#39;s auc: 0.767542
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242548	valid&#39;s auc: 0.767542
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243012	valid&#39;s auc: 0.767435
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242978	valid&#39;s auc: 0.767521
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242685	valid&#39;s auc: 0.76791
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242685	valid&#39;s auc: 0.76791
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242582	valid&#39;s auc: 0.768635
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242582	valid&#39;s auc: 0.768635
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242582	valid&#39;s auc: 0.768596
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.24256	valid&#39;s auc: 0.768652
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242386	valid&#39;s auc: 0.76967
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242386	valid&#39;s auc: 0.76967
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24283	valid&#39;s auc: 0.767889
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24283	valid&#39;s auc: 0.767889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242604	valid&#39;s auc: 0.768051
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s binary_logloss: 0.242587	valid&#39;s auc: 0.768142
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242437	valid&#39;s auc: 0.769343
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242437	valid&#39;s auc: 0.769343
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242437	valid&#39;s auc: 0.769271
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242395	valid&#39;s auc: 0.769421
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242561	valid&#39;s auc: 0.768011
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242561	valid&#39;s auc: 0.768011
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242816	valid&#39;s auc: 0.768357
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242786	valid&#39;s auc: 0.768476
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242534	valid&#39;s auc: 0.76844
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242534	valid&#39;s auc: 0.76844
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242537	valid&#39;s auc: 0.7686
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242537	valid&#39;s auc: 0.7686
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242606	valid&#39;s auc: 0.768219
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242606	valid&#39;s auc: 0.768219
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242265	valid&#39;s auc: 0.768959
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242265	valid&#39;s auc: 0.768959
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242451	valid&#39;s auc: 0.768554
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242451	valid&#39;s auc: 0.768554
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242685	valid&#39;s auc: 0.767579
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242685	valid&#39;s auc: 0.767579
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242662	valid&#39;s auc: 0.768332
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242635	valid&#39;s auc: 0.768414
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242322	valid&#39;s auc: 0.769102
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242322	valid&#39;s auc: 0.769102
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24289	valid&#39;s auc: 0.767639
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242877	valid&#39;s auc: 0.767689
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242836	valid&#39;s auc: 0.767468
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242836	valid&#39;s auc: 0.767468
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242635	valid&#39;s auc: 0.768142
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242635	valid&#39;s auc: 0.768142
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243233	valid&#39;s auc: 0.766298
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243233	valid&#39;s auc: 0.766298
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24256	valid&#39;s auc: 0.768416
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24256	valid&#39;s auc: 0.768416
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242806	valid&#39;s auc: 0.76737
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242761	valid&#39;s auc: 0.767519
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242389	valid&#39;s auc: 0.769279
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242389	valid&#39;s auc: 0.769279
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242481	valid&#39;s auc: 0.768475
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242467	valid&#39;s auc: 0.768466
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242519	valid&#39;s auc: 0.768958
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242508	valid&#39;s auc: 0.768991
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24265	valid&#39;s auc: 0.768607
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242649	valid&#39;s auc: 0.76858
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24262	valid&#39;s auc: 0.768435
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24262	valid&#39;s auc: 0.768435
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242623	valid&#39;s auc: 0.76834
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242623	valid&#39;s auc: 0.76834
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242816	valid&#39;s auc: 0.768091
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242805	valid&#39;s auc: 0.768102
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242617	valid&#39;s auc: 0.769091
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242588	valid&#39;s auc: 0.769127
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242801	valid&#39;s auc: 0.76854
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242794	valid&#39;s auc: 0.768575
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242398	valid&#39;s auc: 0.769218
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242393	valid&#39;s auc: 0.769211
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242825	valid&#39;s auc: 0.767881
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242796	valid&#39;s auc: 0.768052
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2426	valid&#39;s auc: 0.768497
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242591	valid&#39;s auc: 0.768541
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242794	valid&#39;s auc: 0.768287
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242794	valid&#39;s auc: 0.768287
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24246	valid&#39;s auc: 0.76936
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242394	valid&#39;s auc: 0.76949
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242231	valid&#39;s auc: 0.769667
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24223	valid&#39;s auc: 0.76965
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242689	valid&#39;s auc: 0.767982
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242689	valid&#39;s auc: 0.767982
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242988	valid&#39;s auc: 0.766854
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242988	valid&#39;s auc: 0.766854
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242783	valid&#39;s auc: 0.768527
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242774	valid&#39;s auc: 0.76854
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242805	valid&#39;s auc: 0.767299
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242805	valid&#39;s auc: 0.767299
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242999	valid&#39;s auc: 0.767043
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24296	valid&#39;s auc: 0.767084
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242794	valid&#39;s auc: 0.768521
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242787	valid&#39;s auc: 0.768599
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242946	valid&#39;s auc: 0.767332
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242941	valid&#39;s auc: 0.76736
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242779	valid&#39;s auc: 0.768376
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242779	valid&#39;s auc: 0.768376
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242611	valid&#39;s auc: 0.768267
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242582	valid&#39;s auc: 0.768405
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243052	valid&#39;s auc: 0.766854
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243052	valid&#39;s auc: 0.766854
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242467	valid&#39;s auc: 0.768927
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242467	valid&#39;s auc: 0.768927
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242658	valid&#39;s auc: 0.767782
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242639	valid&#39;s auc: 0.767822
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242551	valid&#39;s auc: 0.768566
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242551	valid&#39;s auc: 0.768566
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242417	valid&#39;s auc: 0.769181
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242417	valid&#39;s auc: 0.769181
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[86]	valid&#39;s binary_logloss: 0.242581	valid&#39;s auc: 0.768282
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[84]	valid&#39;s binary_logloss: 0.242272	valid&#39;s auc: 0.769539
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242645	valid&#39;s auc: 0.768461
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242645	valid&#39;s auc: 0.768461
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242437	valid&#39;s auc: 0.769013
Did not meet early stopping. Best iteration is:
[94]	valid&#39;s binary_logloss: 0.242422	valid&#39;s auc: 0.769097
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[81]	valid&#39;s binary_logloss: 0.24258	valid&#39;s auc: 0.768802
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[83]	valid&#39;s binary_logloss: 0.242586	valid&#39;s auc: 0.7683
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242596	valid&#39;s auc: 0.768772
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.24259	valid&#39;s auc: 0.768699
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242741	valid&#39;s auc: 0.767479
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s binary_logloss: 0.2427	valid&#39;s auc: 0.767623
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24259	valid&#39;s auc: 0.76895
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s binary_logloss: 0.242539	valid&#39;s auc: 0.769075
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242712	valid&#39;s auc: 0.767773
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242701	valid&#39;s auc: 0.767793
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242816	valid&#39;s auc: 0.767295
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242816	valid&#39;s auc: 0.767295
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242769	valid&#39;s auc: 0.767761
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242769	valid&#39;s auc: 0.767761
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242541	valid&#39;s auc: 0.768299
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242541	valid&#39;s auc: 0.768299
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242776	valid&#39;s auc: 0.768081
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242776	valid&#39;s auc: 0.768081
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242257	valid&#39;s auc: 0.769497
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242257	valid&#39;s auc: 0.769497
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242563	valid&#39;s auc: 0.768936
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242563	valid&#39;s auc: 0.768936
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242717	valid&#39;s auc: 0.768559
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24271	valid&#39;s auc: 0.768572
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2421	valid&#39;s auc: 0.770121
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242091	valid&#39;s auc: 0.770161
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24272	valid&#39;s auc: 0.768522
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242686	valid&#39;s auc: 0.768692
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242498	valid&#39;s auc: 0.768966
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242485	valid&#39;s auc: 0.768937
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242365	valid&#39;s auc: 0.769251
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242365	valid&#39;s auc: 0.769251
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242823	valid&#39;s auc: 0.768436
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24281	valid&#39;s auc: 0.768477
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24269	valid&#39;s auc: 0.767665
Did not meet early stopping. Best iteration is:
[93]	valid&#39;s binary_logloss: 0.24268	valid&#39;s auc: 0.767657
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242749	valid&#39;s auc: 0.768507
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242749	valid&#39;s auc: 0.768507
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242459	valid&#39;s auc: 0.769716
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242459	valid&#39;s auc: 0.769716
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24254	valid&#39;s auc: 0.768487
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24254	valid&#39;s auc: 0.768487
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242361	valid&#39;s auc: 0.769818
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242361	valid&#39;s auc: 0.769818
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242305	valid&#39;s auc: 0.769257
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242297	valid&#39;s auc: 0.769279
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242648	valid&#39;s auc: 0.768363
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242642	valid&#39;s auc: 0.768311
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242389	valid&#39;s auc: 0.769425
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242389	valid&#39;s auc: 0.769425
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24289	valid&#39;s auc: 0.767411
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24289	valid&#39;s auc: 0.767411
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242905	valid&#39;s auc: 0.767497
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242905	valid&#39;s auc: 0.767497
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242976	valid&#39;s auc: 0.767262
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242976	valid&#39;s auc: 0.767262
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242819	valid&#39;s auc: 0.768174
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242819	valid&#39;s auc: 0.768174
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242603	valid&#39;s auc: 0.768526
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242592	valid&#39;s auc: 0.768602
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242615	valid&#39;s auc: 0.767975
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242585	valid&#39;s auc: 0.768129
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242566	valid&#39;s auc: 0.768921
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242566	valid&#39;s auc: 0.768921
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242797	valid&#39;s auc: 0.767449
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242757	valid&#39;s auc: 0.767565
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242884	valid&#39;s auc: 0.7676
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242884	valid&#39;s auc: 0.7676
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242561	valid&#39;s auc: 0.768692
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242561	valid&#39;s auc: 0.768692
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242533	valid&#39;s auc: 0.768488
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242523	valid&#39;s auc: 0.768572
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242995	valid&#39;s auc: 0.767669
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242995	valid&#39;s auc: 0.767669
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243054	valid&#39;s auc: 0.767097
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243051	valid&#39;s auc: 0.767083
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242748	valid&#39;s auc: 0.767909
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24274	valid&#39;s auc: 0.767922
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242418	valid&#39;s auc: 0.769249
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242371	valid&#39;s auc: 0.76941
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242661	valid&#39;s auc: 0.768025
Did not meet early stopping. Best iteration is:
[91]	valid&#39;s binary_logloss: 0.242638	valid&#39;s auc: 0.768107
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242932	valid&#39;s auc: 0.767564
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242932	valid&#39;s auc: 0.767564
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242594	valid&#39;s auc: 0.767699
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242594	valid&#39;s auc: 0.767699
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24221	valid&#39;s auc: 0.769482
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242172	valid&#39;s auc: 0.769556
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242359	valid&#39;s auc: 0.769157
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242359	valid&#39;s auc: 0.769157
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242781	valid&#39;s auc: 0.767386
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242781	valid&#39;s auc: 0.767386
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242214	valid&#39;s auc: 0.770088
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242214	valid&#39;s auc: 0.770088
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[88]	valid&#39;s binary_logloss: 0.242715	valid&#39;s auc: 0.768199
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242587	valid&#39;s auc: 0.76907
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s binary_logloss: 0.242562	valid&#39;s auc: 0.769153
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242525	valid&#39;s auc: 0.76913
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.2425	valid&#39;s auc: 0.769278
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242496	valid&#39;s auc: 0.76876
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242496	valid&#39;s auc: 0.76876
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242636	valid&#39;s auc: 0.768632
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242636	valid&#39;s auc: 0.768632
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242513	valid&#39;s auc: 0.767916
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242513	valid&#39;s auc: 0.767916
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242739	valid&#39;s auc: 0.768498
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242739	valid&#39;s auc: 0.768498
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242593	valid&#39;s auc: 0.768915
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242593	valid&#39;s auc: 0.768915
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242505	valid&#39;s auc: 0.76893
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242449	valid&#39;s auc: 0.769081
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[87]	valid&#39;s binary_logloss: 0.242832	valid&#39;s auc: 0.767785
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242582	valid&#39;s auc: 0.768184
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242582	valid&#39;s auc: 0.768184
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242477	valid&#39;s auc: 0.769134
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242477	valid&#39;s auc: 0.769134
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24211	valid&#39;s auc: 0.770283
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242082	valid&#39;s auc: 0.77037
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24211	valid&#39;s auc: 0.769899
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242063	valid&#39;s auc: 0.770077
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242189	valid&#39;s auc: 0.770291
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242189	valid&#39;s auc: 0.770291
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242615	valid&#39;s auc: 0.768018
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242598	valid&#39;s auc: 0.768081
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242525	valid&#39;s auc: 0.768783
Did not meet early stopping. Best iteration is:
[92]	valid&#39;s binary_logloss: 0.242522	valid&#39;s auc: 0.76875
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242269	valid&#39;s auc: 0.77019
Did not meet early stopping. Best iteration is:
[91]	valid&#39;s binary_logloss: 0.242173	valid&#39;s auc: 0.770388
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242247	valid&#39;s auc: 0.769313
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242239	valid&#39;s auc: 0.769374
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242932	valid&#39;s auc: 0.76789
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242932	valid&#39;s auc: 0.76789
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24295	valid&#39;s auc: 0.767527
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242937	valid&#39;s auc: 0.767584
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24296	valid&#39;s auc: 0.767648
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24296	valid&#39;s auc: 0.767648
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242457	valid&#39;s auc: 0.769085
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242457	valid&#39;s auc: 0.769085
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242805	valid&#39;s auc: 0.767762
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242805	valid&#39;s auc: 0.767762
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243048	valid&#39;s auc: 0.767195
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243048	valid&#39;s auc: 0.767195
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242952	valid&#39;s auc: 0.766957
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242952	valid&#39;s auc: 0.766957
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.2427	valid&#39;s auc: 0.768387
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.2427	valid&#39;s auc: 0.768387
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242651	valid&#39;s auc: 0.767958
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242651	valid&#39;s auc: 0.767958
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242555	valid&#39;s auc: 0.768256
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242548	valid&#39;s auc: 0.768242
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[70]	valid&#39;s binary_logloss: 0.242833	valid&#39;s auc: 0.767883
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242559	valid&#39;s auc: 0.768351
Early stopping, best iteration is:
[90]	valid&#39;s binary_logloss: 0.242521	valid&#39;s auc: 0.76853
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[87]	valid&#39;s binary_logloss: 0.242577	valid&#39;s auc: 0.768853
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[79]	valid&#39;s binary_logloss: 0.242643	valid&#39;s auc: 0.768197
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242894	valid&#39;s auc: 0.76704
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24289	valid&#39;s auc: 0.767017
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242977	valid&#39;s auc: 0.767359
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242975	valid&#39;s auc: 0.767391
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242958	valid&#39;s auc: 0.766552
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242958	valid&#39;s auc: 0.766552
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243029	valid&#39;s auc: 0.766823
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243029	valid&#39;s auc: 0.766823
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242973	valid&#39;s auc: 0.767275
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242971	valid&#39;s auc: 0.767265
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242237	valid&#39;s auc: 0.769793
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242237	valid&#39;s auc: 0.769793
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242628	valid&#39;s auc: 0.768513
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242628	valid&#39;s auc: 0.768513
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242613	valid&#39;s auc: 0.768376
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242613	valid&#39;s auc: 0.768376
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242758	valid&#39;s auc: 0.768061
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.24269	valid&#39;s auc: 0.76836
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242362	valid&#39;s auc: 0.769894
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242358	valid&#39;s auc: 0.76988
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242397	valid&#39;s auc: 0.768766
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242397	valid&#39;s auc: 0.768766
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242574	valid&#39;s auc: 0.768822
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242574	valid&#39;s auc: 0.768822
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243001	valid&#39;s auc: 0.766766
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243001	valid&#39;s auc: 0.766766
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242929	valid&#39;s auc: 0.767859
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242929	valid&#39;s auc: 0.767859
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242582	valid&#39;s auc: 0.76884
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242573	valid&#39;s auc: 0.768891
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242937	valid&#39;s auc: 0.766855
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242937	valid&#39;s auc: 0.766855
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242436	valid&#39;s auc: 0.768892
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242436	valid&#39;s auc: 0.768892
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242662	valid&#39;s auc: 0.767593
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242662	valid&#39;s auc: 0.767593
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242465	valid&#39;s auc: 0.769656
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242465	valid&#39;s auc: 0.769656
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242691	valid&#39;s auc: 0.768283
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242691	valid&#39;s auc: 0.768283
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242874	valid&#39;s auc: 0.767023
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s binary_logloss: 0.242849	valid&#39;s auc: 0.766988
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242465	valid&#39;s auc: 0.768835
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242465	valid&#39;s auc: 0.768835
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242533	valid&#39;s auc: 0.768814
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242495	valid&#39;s auc: 0.768935
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242501	valid&#39;s auc: 0.769054
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242501	valid&#39;s auc: 0.769054
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242407	valid&#39;s auc: 0.769104
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242407	valid&#39;s auc: 0.769104
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242607	valid&#39;s auc: 0.768272
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242607	valid&#39;s auc: 0.768272
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242696	valid&#39;s auc: 0.768453
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242663	valid&#39;s auc: 0.768522
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242435	valid&#39;s auc: 0.768381
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242435	valid&#39;s auc: 0.768381
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242531	valid&#39;s auc: 0.769096
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242531	valid&#39;s auc: 0.769096
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242203	valid&#39;s auc: 0.76976
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242203	valid&#39;s auc: 0.76976
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242654	valid&#39;s auc: 0.768793
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s binary_logloss: 0.242605	valid&#39;s auc: 0.768937
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243142	valid&#39;s auc: 0.767352
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243115	valid&#39;s auc: 0.767452
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243149	valid&#39;s auc: 0.766827
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.243124	valid&#39;s auc: 0.766865
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242743	valid&#39;s auc: 0.768421
Did not meet early stopping. Best iteration is:
[94]	valid&#39;s binary_logloss: 0.242718	valid&#39;s auc: 0.768364
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242726	valid&#39;s auc: 0.767867
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242726	valid&#39;s auc: 0.767867
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242698	valid&#39;s auc: 0.768453
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242696	valid&#39;s auc: 0.768426
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242559	valid&#39;s auc: 0.76914
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242555	valid&#39;s auc: 0.769188
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[87]	valid&#39;s binary_logloss: 0.242695	valid&#39;s auc: 0.767349
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242572	valid&#39;s auc: 0.768852
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242572	valid&#39;s auc: 0.768852
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242776	valid&#39;s auc: 0.767709
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242776	valid&#39;s auc: 0.767709
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242561	valid&#39;s auc: 0.767664
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242559	valid&#39;s auc: 0.767715
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242964	valid&#39;s auc: 0.767995
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242964	valid&#39;s auc: 0.767995
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242872	valid&#39;s auc: 0.766948
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242863	valid&#39;s auc: 0.766978
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242414	valid&#39;s auc: 0.769107
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242414	valid&#39;s auc: 0.769107
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242188	valid&#39;s auc: 0.769605
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242188	valid&#39;s auc: 0.769605
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242257	valid&#39;s auc: 0.769758
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242257	valid&#39;s auc: 0.769758
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242243	valid&#39;s auc: 0.76947
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242243	valid&#39;s auc: 0.76947
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242591	valid&#39;s auc: 0.768084
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242591	valid&#39;s auc: 0.768084
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242336	valid&#39;s auc: 0.769859
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242336	valid&#39;s auc: 0.769859
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242519	valid&#39;s auc: 0.768455
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242519	valid&#39;s auc: 0.768455
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242193	valid&#39;s auc: 0.769955
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242193	valid&#39;s auc: 0.769955
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242777	valid&#39;s auc: 0.768436
Did not meet early stopping. Best iteration is:
[94]	valid&#39;s binary_logloss: 0.242772	valid&#39;s auc: 0.768461
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242771	valid&#39;s auc: 0.767849
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242747	valid&#39;s auc: 0.767945
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242888	valid&#39;s auc: 0.768389
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242866	valid&#39;s auc: 0.76843
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[87]	valid&#39;s binary_logloss: 0.242511	valid&#39;s auc: 0.769405
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242678	valid&#39;s auc: 0.76798
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242675	valid&#39;s auc: 0.767931
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24311	valid&#39;s auc: 0.767269
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24311	valid&#39;s auc: 0.767269
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242601	valid&#39;s auc: 0.768217
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242601	valid&#39;s auc: 0.768217
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243055	valid&#39;s auc: 0.767798
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.243035	valid&#39;s auc: 0.767797
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24289	valid&#39;s auc: 0.76768
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24289	valid&#39;s auc: 0.76768
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242621	valid&#39;s auc: 0.768182
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242621	valid&#39;s auc: 0.768182
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242696	valid&#39;s auc: 0.768372
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242686	valid&#39;s auc: 0.768358
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242829	valid&#39;s auc: 0.767947
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242829	valid&#39;s auc: 0.767947
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242991	valid&#39;s auc: 0.767444
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242982	valid&#39;s auc: 0.767519
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242513	valid&#39;s auc: 0.768469
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242505	valid&#39;s auc: 0.768488
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242487	valid&#39;s auc: 0.768129
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242487	valid&#39;s auc: 0.768129
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242477	valid&#39;s auc: 0.769532
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242477	valid&#39;s auc: 0.769532
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242485	valid&#39;s auc: 0.768832
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242485	valid&#39;s auc: 0.768832
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242389	valid&#39;s auc: 0.769288
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242386	valid&#39;s auc: 0.769332
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242451	valid&#39;s auc: 0.769529
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242451	valid&#39;s auc: 0.769529
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242725	valid&#39;s auc: 0.768017
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242725	valid&#39;s auc: 0.768017
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242617	valid&#39;s auc: 0.768313
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242617	valid&#39;s auc: 0.768313
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242757	valid&#39;s auc: 0.767745
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242757	valid&#39;s auc: 0.767745
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242447	valid&#39;s auc: 0.76946
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242447	valid&#39;s auc: 0.76946
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242685	valid&#39;s auc: 0.768258
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242668	valid&#39;s auc: 0.768361
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242494	valid&#39;s auc: 0.768353
Early stopping, best iteration is:
[90]	valid&#39;s binary_logloss: 0.2424	valid&#39;s auc: 0.76876
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242328	valid&#39;s auc: 0.769252
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242328	valid&#39;s auc: 0.769252
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242481	valid&#39;s auc: 0.769005
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242429	valid&#39;s auc: 0.769186
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242409	valid&#39;s auc: 0.768618
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s binary_logloss: 0.242339	valid&#39;s auc: 0.768857
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[77]	valid&#39;s binary_logloss: 0.242522	valid&#39;s auc: 0.768629
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242752	valid&#39;s auc: 0.76743
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242752	valid&#39;s auc: 0.76743
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242438	valid&#39;s auc: 0.768381
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242438	valid&#39;s auc: 0.768381
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242955	valid&#39;s auc: 0.76701
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242955	valid&#39;s auc: 0.76701
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24295	valid&#39;s auc: 0.767808
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24295	valid&#39;s auc: 0.767808
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242706	valid&#39;s auc: 0.768057
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242706	valid&#39;s auc: 0.768057
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242526	valid&#39;s auc: 0.768096
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242511	valid&#39;s auc: 0.768174
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242965	valid&#39;s auc: 0.767472
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242964	valid&#39;s auc: 0.767464
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242948	valid&#39;s auc: 0.766995
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242948	valid&#39;s auc: 0.766995
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243017	valid&#39;s auc: 0.767544
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243017	valid&#39;s auc: 0.767544
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242798	valid&#39;s auc: 0.767654
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242787	valid&#39;s auc: 0.767706
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24264	valid&#39;s auc: 0.76793
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242609	valid&#39;s auc: 0.76808
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24293	valid&#39;s auc: 0.767529
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242928	valid&#39;s auc: 0.767549
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242958	valid&#39;s auc: 0.767177
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242958	valid&#39;s auc: 0.767177
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242701	valid&#39;s auc: 0.768582
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242701	valid&#39;s auc: 0.768582
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242936	valid&#39;s auc: 0.767584
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242936	valid&#39;s auc: 0.767584
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242637	valid&#39;s auc: 0.768527
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242637	valid&#39;s auc: 0.768527
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242543	valid&#39;s auc: 0.768372
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242543	valid&#39;s auc: 0.768372
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242758	valid&#39;s auc: 0.767623
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242744	valid&#39;s auc: 0.767692
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242943	valid&#39;s auc: 0.767815
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242943	valid&#39;s auc: 0.767815
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242508	valid&#39;s auc: 0.768762
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242494	valid&#39;s auc: 0.768818
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242804	valid&#39;s auc: 0.767296
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s binary_logloss: 0.242787	valid&#39;s auc: 0.767418
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242733	valid&#39;s auc: 0.768216
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242733	valid&#39;s auc: 0.768216
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242508	valid&#39;s auc: 0.768449
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242508	valid&#39;s auc: 0.768449
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242568	valid&#39;s auc: 0.768275
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242568	valid&#39;s auc: 0.768275
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242501	valid&#39;s auc: 0.768566
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.2425	valid&#39;s auc: 0.768576
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242446	valid&#39;s auc: 0.768757
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242446	valid&#39;s auc: 0.768757
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242348	valid&#39;s auc: 0.769481
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242309	valid&#39;s auc: 0.769605
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242649	valid&#39;s auc: 0.768027
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242644	valid&#39;s auc: 0.768037
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242618	valid&#39;s auc: 0.769091
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242618	valid&#39;s auc: 0.769091
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242407	valid&#39;s auc: 0.769171
Did not meet early stopping. Best iteration is:
[94]	valid&#39;s binary_logloss: 0.2424	valid&#39;s auc: 0.769241
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242457	valid&#39;s auc: 0.768327
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242455	valid&#39;s auc: 0.768346
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242809	valid&#39;s auc: 0.768134
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242809	valid&#39;s auc: 0.768134
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242737	valid&#39;s auc: 0.768234
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242735	valid&#39;s auc: 0.76825
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242848	valid&#39;s auc: 0.76837
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242848	valid&#39;s auc: 0.76837
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242529	valid&#39;s auc: 0.768401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242529	valid&#39;s auc: 0.768401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24253	valid&#39;s auc: 0.768252
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242529	valid&#39;s auc: 0.76828
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24279	valid&#39;s auc: 0.768348
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24279	valid&#39;s auc: 0.768348
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242604	valid&#39;s auc: 0.768286
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242604	valid&#39;s auc: 0.768286
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242894	valid&#39;s auc: 0.7679
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242884	valid&#39;s auc: 0.767972
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242448	valid&#39;s auc: 0.769134
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242448	valid&#39;s auc: 0.769134
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242924	valid&#39;s auc: 0.767596
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242904	valid&#39;s auc: 0.767716
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243212	valid&#39;s auc: 0.767231
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243212	valid&#39;s auc: 0.767231
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243018	valid&#39;s auc: 0.767478
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243018	valid&#39;s auc: 0.767478
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243147	valid&#39;s auc: 0.766832
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243147	valid&#39;s auc: 0.766832
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[89]	valid&#39;s binary_logloss: 0.242379	valid&#39;s auc: 0.768932
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242627	valid&#39;s auc: 0.768318
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24262	valid&#39;s auc: 0.768355
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242818	valid&#39;s auc: 0.767687
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242818	valid&#39;s auc: 0.767687
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242885	valid&#39;s auc: 0.766884
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242885	valid&#39;s auc: 0.766884
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242862	valid&#39;s auc: 0.768267
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242862	valid&#39;s auc: 0.768267
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24262	valid&#39;s auc: 0.768084
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24262	valid&#39;s auc: 0.768084
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242456	valid&#39;s auc: 0.76817
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242456	valid&#39;s auc: 0.76817
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242578	valid&#39;s auc: 0.76839
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242578	valid&#39;s auc: 0.76839
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24266	valid&#39;s auc: 0.767305
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24266	valid&#39;s auc: 0.767305
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242437	valid&#39;s auc: 0.769107
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242431	valid&#39;s auc: 0.7691
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242373	valid&#39;s auc: 0.769344
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242354	valid&#39;s auc: 0.769396
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242721	valid&#39;s auc: 0.767709
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242721	valid&#39;s auc: 0.767709
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242531	valid&#39;s auc: 0.768688
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242516	valid&#39;s auc: 0.768744
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242937	valid&#39;s auc: 0.767043
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242912	valid&#39;s auc: 0.767063
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242862	valid&#39;s auc: 0.767581
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242862	valid&#39;s auc: 0.767581
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242548	valid&#39;s auc: 0.768324
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242544	valid&#39;s auc: 0.768353
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242856	valid&#39;s auc: 0.767042
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242836	valid&#39;s auc: 0.767132
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242892	valid&#39;s auc: 0.767775
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242892	valid&#39;s auc: 0.767775
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242804	valid&#39;s auc: 0.767906
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242804	valid&#39;s auc: 0.767906
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242608	valid&#39;s auc: 0.768704
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242608	valid&#39;s auc: 0.768704
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242425	valid&#39;s auc: 0.768949
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242425	valid&#39;s auc: 0.768949
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242773	valid&#39;s auc: 0.768097
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24277	valid&#39;s auc: 0.768123
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243086	valid&#39;s auc: 0.767297
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24308	valid&#39;s auc: 0.767322
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242815	valid&#39;s auc: 0.768152
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242789	valid&#39;s auc: 0.768201
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242736	valid&#39;s auc: 0.768024
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242705	valid&#39;s auc: 0.768061
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242529	valid&#39;s auc: 0.768837
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242519	valid&#39;s auc: 0.768873
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242516	valid&#39;s auc: 0.768747
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24251	valid&#39;s auc: 0.768736
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242952	valid&#39;s auc: 0.767433
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242937	valid&#39;s auc: 0.767483
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24288	valid&#39;s auc: 0.767693
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242865	valid&#39;s auc: 0.767787
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243161	valid&#39;s auc: 0.767391
Did not meet early stopping. Best iteration is:
[91]	valid&#39;s binary_logloss: 0.243127	valid&#39;s auc: 0.767388
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242403	valid&#39;s auc: 0.769984
Early stopping, best iteration is:
[90]	valid&#39;s binary_logloss: 0.242333	valid&#39;s auc: 0.77028
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242575	valid&#39;s auc: 0.768229
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242575	valid&#39;s auc: 0.768229
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242499	valid&#39;s auc: 0.769141
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242498	valid&#39;s auc: 0.769159
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242738	valid&#39;s auc: 0.767602
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.24271	valid&#39;s auc: 0.767711
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24242	valid&#39;s auc: 0.768895
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24242	valid&#39;s auc: 0.768895
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242297	valid&#39;s auc: 0.769645
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s binary_logloss: 0.242296	valid&#39;s auc: 0.769671
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24263	valid&#39;s auc: 0.768121
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.24263	valid&#39;s auc: 0.768121
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242642	valid&#39;s auc: 0.769249
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242642	valid&#39;s auc: 0.769249
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.24262	valid&#39;s auc: 0.76804
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242614	valid&#39;s auc: 0.768053
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242804	valid&#39;s auc: 0.768213
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242785	valid&#39;s auc: 0.768232
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242354	valid&#39;s auc: 0.769005
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242327	valid&#39;s auc: 0.769136
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242597	valid&#39;s auc: 0.767627
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242565	valid&#39;s auc: 0.767719
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242608	valid&#39;s auc: 0.768699
Did not meet early stopping. Best iteration is:
[94]	valid&#39;s binary_logloss: 0.24259	valid&#39;s auc: 0.768792
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242436	valid&#39;s auc: 0.769172
Early stopping, best iteration is:
[90]	valid&#39;s binary_logloss: 0.242408	valid&#39;s auc: 0.769082
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242287	valid&#39;s auc: 0.769636
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242287	valid&#39;s auc: 0.769633
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[70]	valid&#39;s binary_logloss: 0.242801	valid&#39;s auc: 0.768032
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242577	valid&#39;s auc: 0.76839
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242567	valid&#39;s auc: 0.768431
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243007	valid&#39;s auc: 0.767136
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243007	valid&#39;s auc: 0.767136
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242991	valid&#39;s auc: 0.767714
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242991	valid&#39;s auc: 0.767714
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[82]	valid&#39;s binary_logloss: 0.242765	valid&#39;s auc: 0.768553
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242686	valid&#39;s auc: 0.768549
Did not meet early stopping. Best iteration is:
[92]	valid&#39;s binary_logloss: 0.242652	valid&#39;s auc: 0.768572
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242905	valid&#39;s auc: 0.766992
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s binary_logloss: 0.242877	valid&#39;s auc: 0.767047
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242396	valid&#39;s auc: 0.76896
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242396	valid&#39;s auc: 0.76896
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242907	valid&#39;s auc: 0.766956
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242907	valid&#39;s auc: 0.766956
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242668	valid&#39;s auc: 0.768697
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s binary_logloss: 0.242633	valid&#39;s auc: 0.768785
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242258	valid&#39;s auc: 0.770149
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242258	valid&#39;s auc: 0.770149
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243106	valid&#39;s auc: 0.766878
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.243101	valid&#39;s auc: 0.766937
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243173	valid&#39;s auc: 0.766955
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243173	valid&#39;s auc: 0.766955
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242986	valid&#39;s auc: 0.767555
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242986	valid&#39;s auc: 0.767555
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243045	valid&#39;s auc: 0.767477
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243045	valid&#39;s auc: 0.767477
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242839	valid&#39;s auc: 0.767812
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242839	valid&#39;s auc: 0.767812
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242641	valid&#39;s auc: 0.768242
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242641	valid&#39;s auc: 0.768242
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.243085	valid&#39;s auc: 0.767089
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.243085	valid&#39;s auc: 0.767089
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242665	valid&#39;s auc: 0.767531
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242649	valid&#39;s auc: 0.767574
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242555	valid&#39;s auc: 0.768967
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242555	valid&#39;s auc: 0.768967
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242638	valid&#39;s auc: 0.76822
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242626	valid&#39;s auc: 0.768226
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242497	valid&#39;s auc: 0.768419
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242497	valid&#39;s auc: 0.768419
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242436	valid&#39;s auc: 0.769506
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242436	valid&#39;s auc: 0.769506
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242251	valid&#39;s auc: 0.769552
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242235	valid&#39;s auc: 0.769589
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242576	valid&#39;s auc: 0.768875
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242576	valid&#39;s auc: 0.768875
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242514	valid&#39;s auc: 0.769598
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s binary_logloss: 0.242511	valid&#39;s auc: 0.769601
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 118.6min finished
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s binary_logloss: 0.242525	valid&#39;s auc: 0.767915
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s binary_logloss: 0.242525	valid&#39;s auc: 0.767915
Elapsed time: 7130.172663927078 seconds
Wall time: 1h 58min 50s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>it doesn't improve the performance of the model from the search with narrowed area</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="full-features-with-poly-degree=1-and-pca()-feature-reduction">full features with poly degree=1 and pca() feature reduction<a class="anchor-link" href="#full-features-with-poly-degree=1-and-pca()-feature-reduction">&#182;</a></h2><p>we will try using principle component analysis to perform feature reduction after polynomial=1 transformation to reduce the total no. of features</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># select numerica and categorical features</span>

<span class="n">NUMERIC_COLS_lgbm</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_REGISTRATION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_ID_PUBLISH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;TOTALAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_LAST_PHONE_CHANGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span>
 <span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>

<span class="n">CATEGORY_COLS_lgbm</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_TYPE_SUITE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_FAMILY_STATUS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_HOUSING_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_MOBIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_CONT_MOBILE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMAIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WEEKDAY_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_LIVE_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_LIVE_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUSETYPE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EMERGENCYSTATE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_4&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_5&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_6&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_7&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_8&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_9&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_10&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_11&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_12&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_13&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_14&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_15&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_16&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_17&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_18&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_19&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_20&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_21&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

# create train data
lgbm_full_poly1_pca_pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_lgbm, num_attribs=NUMERIC_COLS_lgbm, poly_degree=1)
X, Y, pipe = pre_process(phase = &quot;train&quot;, preproc_pipeline = lgbm_full_poly1_pca_pipeline)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>loaded 307511 records
features from previous application
features from bureau
features from credit card balance
features from installments
features from application
start pipeline
Wall time: 1min 19s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">randint</span> <span class="k">as</span> <span class="n">sp_randint</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">uniform</span> <span class="k">as</span> <span class="n">sp_uniform</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">grid_params</span> <span class="o">=</span><span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
             <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> 
             <span class="s1">&#39;min_child_samples&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> 
             <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1e1</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">],</span> <span class="c1"># a little different</span>
             <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.14</span><span class="p">),</span>
             <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.8</span><span class="p">),</span>
             <span class="s1">&#39;bagging_fraction&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.6</span><span class="p">),</span>
             <span class="s1">&#39;feature_fraction&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.6</span><span class="p">),</span>
             <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
             <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

from lightgbm import LGBMClassifier
import time
from tempfile import mkdtemp
from shutil import rmtree
from sklearn.decomposition import PCA

#make a cache for memory
cachedir = mkdtemp()

for k in [50, 100, 150]:
    
    print(&quot;starting pca n={}&quot;.format(k))
    pca = PCA(n_components=k)
    
    X_train_ = pca.fit_transform(X_train)
    X_valid_ = pca.transform(X_valid)
    
    fit_params={&quot;early_stopping_rounds&quot;:10, 
            &quot;eval_metric&quot; : &#39;auc&#39;, 
            &quot;eval_set&quot; : [(X_valid_,y_valid)],
            &#39;eval_names&#39;: [&#39;valid&#39;],
            #&#39;callbacks&#39;: [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],
            &#39;verbose&#39;: 100,
            &#39;categorical_feature&#39;: &#39;auto&#39;}
    
    clf = LGBMClassifier(n_jobs=2)
    search = RandomizedSearchCV(
        estimator=clf, 
        param_distributions=grid_params, 
        n_iter=100,
        scoring=&#39;roc_auc&#39;,
        cv=5,
        refit=True,
        random_state=42,
        verbose=True)

    # log arguments
    pipe_steps = repr(pipe.transformers_)
    description = &quot;lgbm full features poly degree=1 pca_n=&quot; + str(k) 
    experiment = &quot;Lgbm_full_features_poly1_pca_&quot; + str(k)

    start_time = time.time()
    run_test(X_train_, y_train, search, description, experiment, pipe_steps, cat_attribs=CATEGORY_COLS_lgbm,
            num_attribs=NUMERIC_COLS_lgbm, **fit_params)
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(&quot;finishing pca n={}&quot;.format(k))
    print(f&quot;Elapsed time: {elapsed_time} seconds&quot;)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>starting pca n=50
Fitting 5 folds for each of 100 candidates, totalling 500 fits
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743174	valid&#39;s binary_logloss: 0.250144
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743174	valid&#39;s binary_logloss: 0.250144
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741739	valid&#39;s binary_logloss: 0.250357
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741739	valid&#39;s binary_logloss: 0.250357
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743432	valid&#39;s binary_logloss: 0.25022
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743432	valid&#39;s binary_logloss: 0.25022
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744312	valid&#39;s binary_logloss: 0.249971
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744312	valid&#39;s binary_logloss: 0.249971
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743094	valid&#39;s binary_logloss: 0.250125
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.743116	valid&#39;s binary_logloss: 0.25013
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740996	valid&#39;s binary_logloss: 0.250717
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741026	valid&#39;s binary_logloss: 0.250721
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742338	valid&#39;s binary_logloss: 0.250435
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.742359	valid&#39;s binary_logloss: 0.250448
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742663	valid&#39;s binary_logloss: 0.250377
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742663	valid&#39;s binary_logloss: 0.250377
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741885	valid&#39;s binary_logloss: 0.250502
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741885	valid&#39;s binary_logloss: 0.250502
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74141	valid&#39;s binary_logloss: 0.250604
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741438	valid&#39;s binary_logloss: 0.250615
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743197	valid&#39;s binary_logloss: 0.250083
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743197	valid&#39;s binary_logloss: 0.250083
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74269	valid&#39;s binary_logloss: 0.250329
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74269	valid&#39;s binary_logloss: 0.250329
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743221	valid&#39;s binary_logloss: 0.250222
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743221	valid&#39;s binary_logloss: 0.250222
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743026	valid&#39;s binary_logloss: 0.250113
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743026	valid&#39;s binary_logloss: 0.250113
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744248	valid&#39;s binary_logloss: 0.249902
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744248	valid&#39;s binary_logloss: 0.249902
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741218	valid&#39;s binary_logloss: 0.251116
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741218	valid&#39;s binary_logloss: 0.251116
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739181	valid&#39;s binary_logloss: 0.251474
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739181	valid&#39;s binary_logloss: 0.251474
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740152	valid&#39;s binary_logloss: 0.251291
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740152	valid&#39;s binary_logloss: 0.251291
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740094	valid&#39;s binary_logloss: 0.251221
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740094	valid&#39;s binary_logloss: 0.251221
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741112	valid&#39;s binary_logloss: 0.25107
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741112	valid&#39;s binary_logloss: 0.25107
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740538	valid&#39;s binary_logloss: 0.250957
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740538	valid&#39;s binary_logloss: 0.250957
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741127	valid&#39;s binary_logloss: 0.250939
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741127	valid&#39;s binary_logloss: 0.250939
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740311	valid&#39;s binary_logloss: 0.251033
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740311	valid&#39;s binary_logloss: 0.251033
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740481	valid&#39;s binary_logloss: 0.250922
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740481	valid&#39;s binary_logloss: 0.250922
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740834	valid&#39;s binary_logloss: 0.250895
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.740848	valid&#39;s binary_logloss: 0.250931
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.728593	valid&#39;s binary_logloss: 0.25615
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.728593	valid&#39;s binary_logloss: 0.25615
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.728629	valid&#39;s binary_logloss: 0.256227
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.728629	valid&#39;s binary_logloss: 0.256227
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.727143	valid&#39;s binary_logloss: 0.256417
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.727143	valid&#39;s binary_logloss: 0.256417
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729051	valid&#39;s binary_logloss: 0.256095
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729051	valid&#39;s binary_logloss: 0.256095
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729273	valid&#39;s binary_logloss: 0.256057
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729273	valid&#39;s binary_logloss: 0.256057
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.713959	valid&#39;s binary_logloss: 0.262753
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.713959	valid&#39;s binary_logloss: 0.262753
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711352	valid&#39;s binary_logloss: 0.262963
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711352	valid&#39;s binary_logloss: 0.262963
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.713039	valid&#39;s binary_logloss: 0.262877
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.713039	valid&#39;s binary_logloss: 0.262877
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.714346	valid&#39;s binary_logloss: 0.262769
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.714346	valid&#39;s binary_logloss: 0.262769
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.713528	valid&#39;s binary_logloss: 0.262771
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.713528	valid&#39;s binary_logloss: 0.262771
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74055	valid&#39;s binary_logloss: 0.251032
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74055	valid&#39;s binary_logloss: 0.251032
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739417	valid&#39;s binary_logloss: 0.251318
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739417	valid&#39;s binary_logloss: 0.251318
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740495	valid&#39;s binary_logloss: 0.251158
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740495	valid&#39;s binary_logloss: 0.251158
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74145	valid&#39;s binary_logloss: 0.25084
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74145	valid&#39;s binary_logloss: 0.25084
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741441	valid&#39;s binary_logloss: 0.250976
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741441	valid&#39;s binary_logloss: 0.250976
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740744	valid&#39;s binary_logloss: 0.250911
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740744	valid&#39;s binary_logloss: 0.250911
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741145	valid&#39;s binary_logloss: 0.250796
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741145	valid&#39;s binary_logloss: 0.250796
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740918	valid&#39;s binary_logloss: 0.250886
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740918	valid&#39;s binary_logloss: 0.250886
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742279	valid&#39;s binary_logloss: 0.250595
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742279	valid&#39;s binary_logloss: 0.250595
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741349	valid&#39;s binary_logloss: 0.250898
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741349	valid&#39;s binary_logloss: 0.250919
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739259	valid&#39;s binary_logloss: 0.252012
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739259	valid&#39;s binary_logloss: 0.252012
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73809	valid&#39;s binary_logloss: 0.252187
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73809	valid&#39;s binary_logloss: 0.252187
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739605	valid&#39;s binary_logloss: 0.25189
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739605	valid&#39;s binary_logloss: 0.25189
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738929	valid&#39;s binary_logloss: 0.251972
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738929	valid&#39;s binary_logloss: 0.251972
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739659	valid&#39;s binary_logloss: 0.251838
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739659	valid&#39;s binary_logloss: 0.251838
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742715	valid&#39;s binary_logloss: 0.25036
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742715	valid&#39;s binary_logloss: 0.25036
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742924	valid&#39;s binary_logloss: 0.250303
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742924	valid&#39;s binary_logloss: 0.250303
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742454	valid&#39;s binary_logloss: 0.250591
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742454	valid&#39;s binary_logloss: 0.250591
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742738	valid&#39;s binary_logloss: 0.250372
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.742741	valid&#39;s binary_logloss: 0.25038
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743409	valid&#39;s binary_logloss: 0.250316
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743409	valid&#39;s binary_logloss: 0.250316
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74315	valid&#39;s binary_logloss: 0.250018
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74315	valid&#39;s binary_logloss: 0.250018
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74331	valid&#39;s binary_logloss: 0.250112
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74331	valid&#39;s binary_logloss: 0.250112
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74226	valid&#39;s binary_logloss: 0.250571
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74226	valid&#39;s binary_logloss: 0.250571
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742773	valid&#39;s binary_logloss: 0.250133
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742773	valid&#39;s binary_logloss: 0.250133
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742051	valid&#39;s binary_logloss: 0.250372
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742051	valid&#39;s binary_logloss: 0.250372
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744218	valid&#39;s binary_logloss: 0.249858
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744255	valid&#39;s binary_logloss: 0.249861
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743922	valid&#39;s binary_logloss: 0.250027
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743922	valid&#39;s binary_logloss: 0.250027
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74331	valid&#39;s binary_logloss: 0.250229
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74331	valid&#39;s binary_logloss: 0.250229
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744862	valid&#39;s binary_logloss: 0.249704
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744873	valid&#39;s binary_logloss: 0.249708
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743405	valid&#39;s binary_logloss: 0.250016
Did not meet early stopping. Best iteration is:
[94]	valid&#39;s auc: 0.743459	valid&#39;s binary_logloss: 0.250007
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741846	valid&#39;s binary_logloss: 0.250376
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741846	valid&#39;s binary_logloss: 0.250376
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743033	valid&#39;s binary_logloss: 0.250199
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743046	valid&#39;s binary_logloss: 0.250208
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74287	valid&#39;s binary_logloss: 0.250174
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74287	valid&#39;s binary_logloss: 0.250174
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742276	valid&#39;s binary_logloss: 0.250333
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742276	valid&#39;s binary_logloss: 0.250333
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743065	valid&#39;s binary_logloss: 0.250202
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743065	valid&#39;s binary_logloss: 0.250202
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721431	valid&#39;s binary_logloss: 0.260289
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721431	valid&#39;s binary_logloss: 0.260289
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.7198	valid&#39;s binary_logloss: 0.260469
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.7198	valid&#39;s binary_logloss: 0.260469
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720588	valid&#39;s binary_logloss: 0.260425
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.720599	valid&#39;s binary_logloss: 0.260511
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[30]	valid&#39;s auc: 0.711767	valid&#39;s binary_logloss: 0.2706
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721703	valid&#39;s binary_logloss: 0.260328
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.721704	valid&#39;s binary_logloss: 0.260415
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734049	valid&#39;s binary_logloss: 0.254028
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734049	valid&#39;s binary_logloss: 0.254028
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73322	valid&#39;s binary_logloss: 0.254142
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73322	valid&#39;s binary_logloss: 0.254142
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733495	valid&#39;s binary_logloss: 0.254162
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733495	valid&#39;s binary_logloss: 0.254162
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733898	valid&#39;s binary_logloss: 0.253915
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733898	valid&#39;s binary_logloss: 0.253915
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733032	valid&#39;s binary_logloss: 0.254174
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733032	valid&#39;s binary_logloss: 0.254174
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741165	valid&#39;s binary_logloss: 0.250818
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741165	valid&#39;s binary_logloss: 0.250818
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740921	valid&#39;s binary_logloss: 0.250902
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740921	valid&#39;s binary_logloss: 0.250902
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742355	valid&#39;s binary_logloss: 0.250628
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742355	valid&#39;s binary_logloss: 0.250628
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742191	valid&#39;s binary_logloss: 0.250751
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742191	valid&#39;s binary_logloss: 0.250751
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742662	valid&#39;s binary_logloss: 0.250502
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742662	valid&#39;s binary_logloss: 0.250502
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[86]	valid&#39;s auc: 0.74262	valid&#39;s binary_logloss: 0.250336
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[67]	valid&#39;s auc: 0.740607	valid&#39;s binary_logloss: 0.250499
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[83]	valid&#39;s auc: 0.7431	valid&#39;s binary_logloss: 0.250332
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[53]	valid&#39;s auc: 0.741068	valid&#39;s binary_logloss: 0.250538
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[72]	valid&#39;s auc: 0.741062	valid&#39;s binary_logloss: 0.250496
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739657	valid&#39;s binary_logloss: 0.251378
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739657	valid&#39;s binary_logloss: 0.251378
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739597	valid&#39;s binary_logloss: 0.251329
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739597	valid&#39;s binary_logloss: 0.251329
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739239	valid&#39;s binary_logloss: 0.25136
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739239	valid&#39;s binary_logloss: 0.25136
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740508	valid&#39;s binary_logloss: 0.251074
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740508	valid&#39;s binary_logloss: 0.251074
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740514	valid&#39;s binary_logloss: 0.250973
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740514	valid&#39;s binary_logloss: 0.250973
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740319	valid&#39;s binary_logloss: 0.251544
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740319	valid&#39;s binary_logloss: 0.251544
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740342	valid&#39;s binary_logloss: 0.251546
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740342	valid&#39;s binary_logloss: 0.251546
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739225	valid&#39;s binary_logloss: 0.251758
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739225	valid&#39;s binary_logloss: 0.251758
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739661	valid&#39;s binary_logloss: 0.251616
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739661	valid&#39;s binary_logloss: 0.251616
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739274	valid&#39;s binary_logloss: 0.251684
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739274	valid&#39;s binary_logloss: 0.251684
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743579	valid&#39;s binary_logloss: 0.25009
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743579	valid&#39;s binary_logloss: 0.25009
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74067	valid&#39;s binary_logloss: 0.250943
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74067	valid&#39;s binary_logloss: 0.250943
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743411	valid&#39;s binary_logloss: 0.250161
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743411	valid&#39;s binary_logloss: 0.250161
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743444	valid&#39;s binary_logloss: 0.250037
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743444	valid&#39;s binary_logloss: 0.250037
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743245	valid&#39;s binary_logloss: 0.250351
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743245	valid&#39;s binary_logloss: 0.250351
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719025	valid&#39;s binary_logloss: 0.26201
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719025	valid&#39;s binary_logloss: 0.26201
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.716281	valid&#39;s binary_logloss: 0.262184
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.716281	valid&#39;s binary_logloss: 0.262184
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.716808	valid&#39;s binary_logloss: 0.262215
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.716808	valid&#39;s binary_logloss: 0.262215
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719183	valid&#39;s binary_logloss: 0.26202
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719183	valid&#39;s binary_logloss: 0.26202
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.71915	valid&#39;s binary_logloss: 0.261958
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.71915	valid&#39;s binary_logloss: 0.261958
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730741	valid&#39;s binary_logloss: 0.255464
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730741	valid&#39;s binary_logloss: 0.255464
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.728898	valid&#39;s binary_logloss: 0.255796
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.728898	valid&#39;s binary_logloss: 0.255796
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729936	valid&#39;s binary_logloss: 0.255623
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729936	valid&#39;s binary_logloss: 0.255623
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730989	valid&#39;s binary_logloss: 0.255458
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730989	valid&#39;s binary_logloss: 0.255458
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730221	valid&#39;s binary_logloss: 0.255634
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730221	valid&#39;s binary_logloss: 0.255634
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742476	valid&#39;s binary_logloss: 0.250206
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742476	valid&#39;s binary_logloss: 0.250206
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741102	valid&#39;s binary_logloss: 0.250555
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741102	valid&#39;s binary_logloss: 0.250555
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74422	valid&#39;s binary_logloss: 0.249948
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744252	valid&#39;s binary_logloss: 0.249955
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743107	valid&#39;s binary_logloss: 0.25025
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743107	valid&#39;s binary_logloss: 0.25025
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742496	valid&#39;s binary_logloss: 0.250355
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742496	valid&#39;s binary_logloss: 0.250355
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.727262	valid&#39;s binary_logloss: 0.25648
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.727262	valid&#39;s binary_logloss: 0.25648
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.728288	valid&#39;s binary_logloss: 0.256392
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.728288	valid&#39;s binary_logloss: 0.256392
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.727043	valid&#39;s binary_logloss: 0.256568
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.727043	valid&#39;s binary_logloss: 0.256568
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.727821	valid&#39;s binary_logloss: 0.256406
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.727821	valid&#39;s binary_logloss: 0.256406
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.728253	valid&#39;s binary_logloss: 0.256384
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.728253	valid&#39;s binary_logloss: 0.256384
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741167	valid&#39;s binary_logloss: 0.250627
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741167	valid&#39;s binary_logloss: 0.250627
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741803	valid&#39;s binary_logloss: 0.250604
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741871	valid&#39;s binary_logloss: 0.250595
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741425	valid&#39;s binary_logloss: 0.250536
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741425	valid&#39;s binary_logloss: 0.250536
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742833	valid&#39;s binary_logloss: 0.250254
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742833	valid&#39;s binary_logloss: 0.250254
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742025	valid&#39;s binary_logloss: 0.250546
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742025	valid&#39;s binary_logloss: 0.250546
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732074	valid&#39;s binary_logloss: 0.254834
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732074	valid&#39;s binary_logloss: 0.254834
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731028	valid&#39;s binary_logloss: 0.255022
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731028	valid&#39;s binary_logloss: 0.255022
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731323	valid&#39;s binary_logloss: 0.255011
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731323	valid&#39;s binary_logloss: 0.255011
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732229	valid&#39;s binary_logloss: 0.254738
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732229	valid&#39;s binary_logloss: 0.254738
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732819	valid&#39;s binary_logloss: 0.254757
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732819	valid&#39;s binary_logloss: 0.254757
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738417	valid&#39;s binary_logloss: 0.251932
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738417	valid&#39;s binary_logloss: 0.251932
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739057	valid&#39;s binary_logloss: 0.251949
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739057	valid&#39;s binary_logloss: 0.251949
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738414	valid&#39;s binary_logloss: 0.252042
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738414	valid&#39;s binary_logloss: 0.252042
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739019	valid&#39;s binary_logloss: 0.251912
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739019	valid&#39;s binary_logloss: 0.251912
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739922	valid&#39;s binary_logloss: 0.25185
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739922	valid&#39;s binary_logloss: 0.25185
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743119	valid&#39;s binary_logloss: 0.250003
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743119	valid&#39;s binary_logloss: 0.250003
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742673	valid&#39;s binary_logloss: 0.2503
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742673	valid&#39;s binary_logloss: 0.2503
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743902	valid&#39;s binary_logloss: 0.249937
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743912	valid&#39;s binary_logloss: 0.249932
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743795	valid&#39;s binary_logloss: 0.249979
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743795	valid&#39;s binary_logloss: 0.249979
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742944	valid&#39;s binary_logloss: 0.250007
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742944	valid&#39;s binary_logloss: 0.250007
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735945	valid&#39;s binary_logloss: 0.25308
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735945	valid&#39;s binary_logloss: 0.25308
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735121	valid&#39;s binary_logloss: 0.253318
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735121	valid&#39;s binary_logloss: 0.253318
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735564	valid&#39;s binary_logloss: 0.253197
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735564	valid&#39;s binary_logloss: 0.253197
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736218	valid&#39;s binary_logloss: 0.253083
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736218	valid&#39;s binary_logloss: 0.253083
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736149	valid&#39;s binary_logloss: 0.253169
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736149	valid&#39;s binary_logloss: 0.253169
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743689	valid&#39;s binary_logloss: 0.25004
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743689	valid&#39;s binary_logloss: 0.25004
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743512	valid&#39;s binary_logloss: 0.250053
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743512	valid&#39;s binary_logloss: 0.250053
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743096	valid&#39;s binary_logloss: 0.250293
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743096	valid&#39;s binary_logloss: 0.250293
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742003	valid&#39;s binary_logloss: 0.250404
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742003	valid&#39;s binary_logloss: 0.250404
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74395	valid&#39;s binary_logloss: 0.25001
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74395	valid&#39;s binary_logloss: 0.25001
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738365	valid&#39;s binary_logloss: 0.252266
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738365	valid&#39;s binary_logloss: 0.252266
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738419	valid&#39;s binary_logloss: 0.252183
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738419	valid&#39;s binary_logloss: 0.252183
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73886	valid&#39;s binary_logloss: 0.252256
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73886	valid&#39;s binary_logloss: 0.252256
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738636	valid&#39;s binary_logloss: 0.25229
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738636	valid&#39;s binary_logloss: 0.25229
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739609	valid&#39;s binary_logloss: 0.252109
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739609	valid&#39;s binary_logloss: 0.252109
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735972	valid&#39;s binary_logloss: 0.253159
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735972	valid&#39;s binary_logloss: 0.253159
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735018	valid&#39;s binary_logloss: 0.253509
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735018	valid&#39;s binary_logloss: 0.253509
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735114	valid&#39;s binary_logloss: 0.253501
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735114	valid&#39;s binary_logloss: 0.253501
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73578	valid&#39;s binary_logloss: 0.253202
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73578	valid&#39;s binary_logloss: 0.253202
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736616	valid&#39;s binary_logloss: 0.253105
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736616	valid&#39;s binary_logloss: 0.253105
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741103	valid&#39;s binary_logloss: 0.250854
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741103	valid&#39;s binary_logloss: 0.250854
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741739	valid&#39;s binary_logloss: 0.250796
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741739	valid&#39;s binary_logloss: 0.250796
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740925	valid&#39;s binary_logloss: 0.250902
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740925	valid&#39;s binary_logloss: 0.250902
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74267	valid&#39;s binary_logloss: 0.250489
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74267	valid&#39;s binary_logloss: 0.250489
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741895	valid&#39;s binary_logloss: 0.250713
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741895	valid&#39;s binary_logloss: 0.250713
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733044	valid&#39;s binary_logloss: 0.254338
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733044	valid&#39;s binary_logloss: 0.254338
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732766	valid&#39;s binary_logloss: 0.254551
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732766	valid&#39;s binary_logloss: 0.254551
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733136	valid&#39;s binary_logloss: 0.254506
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733136	valid&#39;s binary_logloss: 0.254506
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733191	valid&#39;s binary_logloss: 0.254384
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733191	valid&#39;s binary_logloss: 0.254384
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73319	valid&#39;s binary_logloss: 0.254428
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73319	valid&#39;s binary_logloss: 0.254428
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711985	valid&#39;s binary_logloss: 0.263446
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711985	valid&#39;s binary_logloss: 0.263446
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.709138	valid&#39;s binary_logloss: 0.263674
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.709138	valid&#39;s binary_logloss: 0.263674
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.709635	valid&#39;s binary_logloss: 0.263686
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.709635	valid&#39;s binary_logloss: 0.263686
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711751	valid&#39;s binary_logloss: 0.263558
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711751	valid&#39;s binary_logloss: 0.263558
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711452	valid&#39;s binary_logloss: 0.263469
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711452	valid&#39;s binary_logloss: 0.263469
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72331	valid&#39;s binary_logloss: 0.258692
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72331	valid&#39;s binary_logloss: 0.258692
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722551	valid&#39;s binary_logloss: 0.258834
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722551	valid&#39;s binary_logloss: 0.258834
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72197	valid&#39;s binary_logloss: 0.258927
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72197	valid&#39;s binary_logloss: 0.258927
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722628	valid&#39;s binary_logloss: 0.25881
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722628	valid&#39;s binary_logloss: 0.25881
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723303	valid&#39;s binary_logloss: 0.258687
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723303	valid&#39;s binary_logloss: 0.258687
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745267	valid&#39;s binary_logloss: 0.249592
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745267	valid&#39;s binary_logloss: 0.249592
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742931	valid&#39;s binary_logloss: 0.250308
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742931	valid&#39;s binary_logloss: 0.250308
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744431	valid&#39;s binary_logloss: 0.249926
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744431	valid&#39;s binary_logloss: 0.249926
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743324	valid&#39;s binary_logloss: 0.249864
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743324	valid&#39;s binary_logloss: 0.249864
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743571	valid&#39;s binary_logloss: 0.250197
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743652	valid&#39;s binary_logloss: 0.250177
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735278	valid&#39;s binary_logloss: 0.253476
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735278	valid&#39;s binary_logloss: 0.253476
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735038	valid&#39;s binary_logloss: 0.25362
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735038	valid&#39;s binary_logloss: 0.25362
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735491	valid&#39;s binary_logloss: 0.253533
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735491	valid&#39;s binary_logloss: 0.253533
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735183	valid&#39;s binary_logloss: 0.253503
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735183	valid&#39;s binary_logloss: 0.253503
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736343	valid&#39;s binary_logloss: 0.253354
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736343	valid&#39;s binary_logloss: 0.253354
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744982	valid&#39;s binary_logloss: 0.249687
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744996	valid&#39;s binary_logloss: 0.249689
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742029	valid&#39;s binary_logloss: 0.250127
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742029	valid&#39;s binary_logloss: 0.250127
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745287	valid&#39;s binary_logloss: 0.249585
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745287	valid&#39;s binary_logloss: 0.249585
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743136	valid&#39;s binary_logloss: 0.25005
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743136	valid&#39;s binary_logloss: 0.25005
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743759	valid&#39;s binary_logloss: 0.249787
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743759	valid&#39;s binary_logloss: 0.249787
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730752	valid&#39;s binary_logloss: 0.255396
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730752	valid&#39;s binary_logloss: 0.255396
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729892	valid&#39;s binary_logloss: 0.255494
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729892	valid&#39;s binary_logloss: 0.255494
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730996	valid&#39;s binary_logloss: 0.255354
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730996	valid&#39;s binary_logloss: 0.255354
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730783	valid&#39;s binary_logloss: 0.255324
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730783	valid&#39;s binary_logloss: 0.255324
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730831	valid&#39;s binary_logloss: 0.255355
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730831	valid&#39;s binary_logloss: 0.255355
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734325	valid&#39;s binary_logloss: 0.253922
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734325	valid&#39;s binary_logloss: 0.253922
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733527	valid&#39;s binary_logloss: 0.254102
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733527	valid&#39;s binary_logloss: 0.254102
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733639	valid&#39;s binary_logloss: 0.254094
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733639	valid&#39;s binary_logloss: 0.254094
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734196	valid&#39;s binary_logloss: 0.253932
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734196	valid&#39;s binary_logloss: 0.253932
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734106	valid&#39;s binary_logloss: 0.254032
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734106	valid&#39;s binary_logloss: 0.254032
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742263	valid&#39;s binary_logloss: 0.250281
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s auc: 0.742473	valid&#39;s binary_logloss: 0.250208
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742203	valid&#39;s binary_logloss: 0.250436
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s auc: 0.742214	valid&#39;s binary_logloss: 0.250435
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74329	valid&#39;s binary_logloss: 0.249954
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743355	valid&#39;s binary_logloss: 0.249938
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742405	valid&#39;s binary_logloss: 0.250077
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742405	valid&#39;s binary_logloss: 0.250077
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742838	valid&#39;s binary_logloss: 0.250255
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742838	valid&#39;s binary_logloss: 0.250255
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724266	valid&#39;s binary_logloss: 0.257793
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724266	valid&#39;s binary_logloss: 0.257793
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724353	valid&#39;s binary_logloss: 0.257761
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724353	valid&#39;s binary_logloss: 0.257761
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723421	valid&#39;s binary_logloss: 0.257873
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723421	valid&#39;s binary_logloss: 0.257873
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724844	valid&#39;s binary_logloss: 0.257604
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724844	valid&#39;s binary_logloss: 0.257604
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725335	valid&#39;s binary_logloss: 0.257614
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725335	valid&#39;s binary_logloss: 0.257614
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742731	valid&#39;s binary_logloss: 0.25043
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74275	valid&#39;s binary_logloss: 0.250437
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742504	valid&#39;s binary_logloss: 0.250417
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742504	valid&#39;s binary_logloss: 0.250417
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742237	valid&#39;s binary_logloss: 0.250565
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742237	valid&#39;s binary_logloss: 0.250565
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742387	valid&#39;s binary_logloss: 0.25043
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742387	valid&#39;s binary_logloss: 0.25043
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742487	valid&#39;s binary_logloss: 0.250419
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742487	valid&#39;s binary_logloss: 0.250419
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737366	valid&#39;s binary_logloss: 0.252403
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737366	valid&#39;s binary_logloss: 0.252403
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737521	valid&#39;s binary_logloss: 0.252398
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737521	valid&#39;s binary_logloss: 0.252398
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73957	valid&#39;s binary_logloss: 0.252095
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73957	valid&#39;s binary_logloss: 0.252095
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739126	valid&#39;s binary_logloss: 0.252117
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739126	valid&#39;s binary_logloss: 0.252117
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739482	valid&#39;s binary_logloss: 0.25217
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739482	valid&#39;s binary_logloss: 0.25217
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738181	valid&#39;s binary_logloss: 0.252249
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738181	valid&#39;s binary_logloss: 0.252249
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737828	valid&#39;s binary_logloss: 0.252394
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737828	valid&#39;s binary_logloss: 0.252394
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737899	valid&#39;s binary_logloss: 0.252439
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737899	valid&#39;s binary_logloss: 0.252439
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738957	valid&#39;s binary_logloss: 0.252184
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738957	valid&#39;s binary_logloss: 0.252184
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737504	valid&#39;s binary_logloss: 0.252441
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737504	valid&#39;s binary_logloss: 0.252441
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740195	valid&#39;s binary_logloss: 0.251237
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740195	valid&#39;s binary_logloss: 0.251237
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738772	valid&#39;s binary_logloss: 0.251574
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.738791	valid&#39;s binary_logloss: 0.251594
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740855	valid&#39;s binary_logloss: 0.251258
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.74091	valid&#39;s binary_logloss: 0.251283
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741625	valid&#39;s binary_logloss: 0.250982
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741695	valid&#39;s binary_logloss: 0.250995
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741169	valid&#39;s binary_logloss: 0.251139
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741169	valid&#39;s binary_logloss: 0.251139
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745013	valid&#39;s binary_logloss: 0.249568
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745013	valid&#39;s binary_logloss: 0.249568
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743597	valid&#39;s binary_logloss: 0.250088
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743597	valid&#39;s binary_logloss: 0.250088
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744457	valid&#39;s binary_logloss: 0.249951
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.744462	valid&#39;s binary_logloss: 0.249947
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743238	valid&#39;s binary_logloss: 0.250117
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74328	valid&#39;s binary_logloss: 0.250109
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744162	valid&#39;s binary_logloss: 0.249903
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s auc: 0.744313	valid&#39;s binary_logloss: 0.249879
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737196	valid&#39;s binary_logloss: 0.252572
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737196	valid&#39;s binary_logloss: 0.252572
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736769	valid&#39;s binary_logloss: 0.252607
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736769	valid&#39;s binary_logloss: 0.252607
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736461	valid&#39;s binary_logloss: 0.252764
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736461	valid&#39;s binary_logloss: 0.252764
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737549	valid&#39;s binary_logloss: 0.252442
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737549	valid&#39;s binary_logloss: 0.252442
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736496	valid&#39;s binary_logloss: 0.252691
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736496	valid&#39;s binary_logloss: 0.252691
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739149	valid&#39;s binary_logloss: 0.251957
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739149	valid&#39;s binary_logloss: 0.251957
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738613	valid&#39;s binary_logloss: 0.252093
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738613	valid&#39;s binary_logloss: 0.252093
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739336	valid&#39;s binary_logloss: 0.251921
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739336	valid&#39;s binary_logloss: 0.251921
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738476	valid&#39;s binary_logloss: 0.252086
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738476	valid&#39;s binary_logloss: 0.252086
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739003	valid&#39;s binary_logloss: 0.252054
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739003	valid&#39;s binary_logloss: 0.252054
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[88]	valid&#39;s auc: 0.743836	valid&#39;s binary_logloss: 0.249889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741985	valid&#39;s binary_logloss: 0.250318
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.742062	valid&#39;s binary_logloss: 0.250285
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743273	valid&#39;s binary_logloss: 0.249865
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743273	valid&#39;s binary_logloss: 0.249865
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742673	valid&#39;s binary_logloss: 0.250173
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s auc: 0.742729	valid&#39;s binary_logloss: 0.250167
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743364	valid&#39;s binary_logloss: 0.250197
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.743372	valid&#39;s binary_logloss: 0.250205
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740526	valid&#39;s binary_logloss: 0.25094
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740526	valid&#39;s binary_logloss: 0.25094
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740714	valid&#39;s binary_logloss: 0.250905
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740714	valid&#39;s binary_logloss: 0.250905
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740801	valid&#39;s binary_logloss: 0.251053
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740801	valid&#39;s binary_logloss: 0.251053
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741961	valid&#39;s binary_logloss: 0.250522
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741961	valid&#39;s binary_logloss: 0.250522
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740943	valid&#39;s binary_logloss: 0.25089
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740943	valid&#39;s binary_logloss: 0.25089
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717547	valid&#39;s binary_logloss: 0.260741
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717547	valid&#39;s binary_logloss: 0.260741
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715977	valid&#39;s binary_logloss: 0.260949
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715977	valid&#39;s binary_logloss: 0.260949
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715865	valid&#39;s binary_logloss: 0.261006
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715865	valid&#39;s binary_logloss: 0.261006
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.716876	valid&#39;s binary_logloss: 0.26082
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.716876	valid&#39;s binary_logloss: 0.26082
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717856	valid&#39;s binary_logloss: 0.260754
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717856	valid&#39;s binary_logloss: 0.260754
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736931	valid&#39;s binary_logloss: 0.252619
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736931	valid&#39;s binary_logloss: 0.252619
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737156	valid&#39;s binary_logloss: 0.252582
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737156	valid&#39;s binary_logloss: 0.252582
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737571	valid&#39;s binary_logloss: 0.25255
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737571	valid&#39;s binary_logloss: 0.25255
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737494	valid&#39;s binary_logloss: 0.25245
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737494	valid&#39;s binary_logloss: 0.25245
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737387	valid&#39;s binary_logloss: 0.252481
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737387	valid&#39;s binary_logloss: 0.252481
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741495	valid&#39;s binary_logloss: 0.250443
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.74155	valid&#39;s binary_logloss: 0.250453
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740407	valid&#39;s binary_logloss: 0.25086
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74047	valid&#39;s binary_logloss: 0.250859
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742129	valid&#39;s binary_logloss: 0.2504
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742129	valid&#39;s binary_logloss: 0.2504
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742225	valid&#39;s binary_logloss: 0.250253
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742225	valid&#39;s binary_logloss: 0.250253
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742704	valid&#39;s binary_logloss: 0.250341
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742704	valid&#39;s binary_logloss: 0.250341
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737423	valid&#39;s binary_logloss: 0.252412
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737423	valid&#39;s binary_logloss: 0.252412
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737641	valid&#39;s binary_logloss: 0.252354
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737641	valid&#39;s binary_logloss: 0.252354
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738014	valid&#39;s binary_logloss: 0.252358
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738014	valid&#39;s binary_logloss: 0.252358
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738684	valid&#39;s binary_logloss: 0.252242
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738684	valid&#39;s binary_logloss: 0.252242
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738413	valid&#39;s binary_logloss: 0.252286
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738413	valid&#39;s binary_logloss: 0.252286
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735679	valid&#39;s binary_logloss: 0.253031
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735679	valid&#39;s binary_logloss: 0.253031
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736426	valid&#39;s binary_logloss: 0.252953
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736426	valid&#39;s binary_logloss: 0.252953
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735499	valid&#39;s binary_logloss: 0.253166
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735499	valid&#39;s binary_logloss: 0.253166
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737577	valid&#39;s binary_logloss: 0.252568
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737577	valid&#39;s binary_logloss: 0.252568
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736814	valid&#39;s binary_logloss: 0.252795
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736814	valid&#39;s binary_logloss: 0.252795
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724113	valid&#39;s binary_logloss: 0.260581
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724113	valid&#39;s binary_logloss: 0.260581
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723557	valid&#39;s binary_logloss: 0.260694
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723557	valid&#39;s binary_logloss: 0.260694
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723734	valid&#39;s binary_logloss: 0.260697
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723734	valid&#39;s binary_logloss: 0.260697
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724722	valid&#39;s binary_logloss: 0.260601
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724722	valid&#39;s binary_logloss: 0.260601
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724994	valid&#39;s binary_logloss: 0.260582
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724994	valid&#39;s binary_logloss: 0.260582
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731502	valid&#39;s binary_logloss: 0.255495
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731502	valid&#39;s binary_logloss: 0.255495
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.728972	valid&#39;s binary_logloss: 0.255835
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.728972	valid&#39;s binary_logloss: 0.255835
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729767	valid&#39;s binary_logloss: 0.255772
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729767	valid&#39;s binary_logloss: 0.255772
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731373	valid&#39;s binary_logloss: 0.255488
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731373	valid&#39;s binary_logloss: 0.255488
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730756	valid&#39;s binary_logloss: 0.255594
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730756	valid&#39;s binary_logloss: 0.255594
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744131	valid&#39;s binary_logloss: 0.249916
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744131	valid&#39;s binary_logloss: 0.249916
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743804	valid&#39;s binary_logloss: 0.250245
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743804	valid&#39;s binary_logloss: 0.250245
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742033	valid&#39;s binary_logloss: 0.250493
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742033	valid&#39;s binary_logloss: 0.250493
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742748	valid&#39;s binary_logloss: 0.250329
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742748	valid&#39;s binary_logloss: 0.250329
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742305	valid&#39;s binary_logloss: 0.250568
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742305	valid&#39;s binary_logloss: 0.250568
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717596	valid&#39;s binary_logloss: 0.260517
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717596	valid&#39;s binary_logloss: 0.260517
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717606	valid&#39;s binary_logloss: 0.260502
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717606	valid&#39;s binary_logloss: 0.260502
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717166	valid&#39;s binary_logloss: 0.260597
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717166	valid&#39;s binary_logloss: 0.260597
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717892	valid&#39;s binary_logloss: 0.260553
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717892	valid&#39;s binary_logloss: 0.260553
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718888	valid&#39;s binary_logloss: 0.260371
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718888	valid&#39;s binary_logloss: 0.260371
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724801	valid&#39;s binary_logloss: 0.258207
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724801	valid&#39;s binary_logloss: 0.258207
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722966	valid&#39;s binary_logloss: 0.25836
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722966	valid&#39;s binary_logloss: 0.25836
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723745	valid&#39;s binary_logloss: 0.258293
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723745	valid&#39;s binary_logloss: 0.258293
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724244	valid&#39;s binary_logloss: 0.258247
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724244	valid&#39;s binary_logloss: 0.258247
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72516	valid&#39;s binary_logloss: 0.258167
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72516	valid&#39;s binary_logloss: 0.258167
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712202	valid&#39;s binary_logloss: 0.263016
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712202	valid&#39;s binary_logloss: 0.263016
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.710048	valid&#39;s binary_logloss: 0.263165
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.710048	valid&#39;s binary_logloss: 0.263165
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.709454	valid&#39;s binary_logloss: 0.263218
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.709454	valid&#39;s binary_logloss: 0.263218
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711072	valid&#39;s binary_logloss: 0.263035
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711072	valid&#39;s binary_logloss: 0.263035
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711298	valid&#39;s binary_logloss: 0.26305
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711298	valid&#39;s binary_logloss: 0.26305
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739512	valid&#39;s binary_logloss: 0.25181
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739512	valid&#39;s binary_logloss: 0.25181
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738043	valid&#39;s binary_logloss: 0.252069
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738043	valid&#39;s binary_logloss: 0.252069
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738219	valid&#39;s binary_logloss: 0.251946
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738219	valid&#39;s binary_logloss: 0.251946
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738854	valid&#39;s binary_logloss: 0.251871
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738854	valid&#39;s binary_logloss: 0.251871
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739622	valid&#39;s binary_logloss: 0.251703
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.739637	valid&#39;s binary_logloss: 0.25175
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722661	valid&#39;s binary_logloss: 0.261149
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722661	valid&#39;s binary_logloss: 0.261149
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722391	valid&#39;s binary_logloss: 0.261254
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722391	valid&#39;s binary_logloss: 0.261254
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723174	valid&#39;s binary_logloss: 0.261149
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723174	valid&#39;s binary_logloss: 0.261149
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723162	valid&#39;s binary_logloss: 0.26118
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723162	valid&#39;s binary_logloss: 0.26118
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723059	valid&#39;s binary_logloss: 0.261174
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723059	valid&#39;s binary_logloss: 0.261174
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739812	valid&#39;s binary_logloss: 0.251316
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739812	valid&#39;s binary_logloss: 0.251316
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738754	valid&#39;s binary_logloss: 0.251587
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738754	valid&#39;s binary_logloss: 0.251587
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740113	valid&#39;s binary_logloss: 0.251257
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740113	valid&#39;s binary_logloss: 0.251257
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741375	valid&#39;s binary_logloss: 0.250992
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741375	valid&#39;s binary_logloss: 0.250992
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739718	valid&#39;s binary_logloss: 0.251296
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739718	valid&#39;s binary_logloss: 0.251296
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722545	valid&#39;s binary_logloss: 0.259606
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722545	valid&#39;s binary_logloss: 0.259606
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719115	valid&#39;s binary_logloss: 0.260004
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719115	valid&#39;s binary_logloss: 0.260004
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72064	valid&#39;s binary_logloss: 0.259866
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72064	valid&#39;s binary_logloss: 0.259866
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721625	valid&#39;s binary_logloss: 0.259718
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721625	valid&#39;s binary_logloss: 0.259718
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722738	valid&#39;s binary_logloss: 0.259631
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722738	valid&#39;s binary_logloss: 0.259631
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742791	valid&#39;s binary_logloss: 0.250191
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742791	valid&#39;s binary_logloss: 0.250191
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743561	valid&#39;s binary_logloss: 0.250195
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743563	valid&#39;s binary_logloss: 0.250209
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743392	valid&#39;s binary_logloss: 0.25006
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743392	valid&#39;s binary_logloss: 0.25006
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743064	valid&#39;s binary_logloss: 0.250267
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743064	valid&#39;s binary_logloss: 0.250267
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743527	valid&#39;s binary_logloss: 0.250257
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743527	valid&#39;s binary_logloss: 0.250257
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733046	valid&#39;s binary_logloss: 0.255322
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733046	valid&#39;s binary_logloss: 0.255322
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732107	valid&#39;s binary_logloss: 0.255457
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732107	valid&#39;s binary_logloss: 0.255457
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733563	valid&#39;s binary_logloss: 0.255242
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733563	valid&#39;s binary_logloss: 0.255242
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733786	valid&#39;s binary_logloss: 0.255227
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733786	valid&#39;s binary_logloss: 0.255227
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733418	valid&#39;s binary_logloss: 0.255242
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733418	valid&#39;s binary_logloss: 0.255242
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738642	valid&#39;s binary_logloss: 0.251976
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738642	valid&#39;s binary_logloss: 0.251976
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73811	valid&#39;s binary_logloss: 0.252044
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73811	valid&#39;s binary_logloss: 0.252044
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737896	valid&#39;s binary_logloss: 0.252237
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737896	valid&#39;s binary_logloss: 0.252237
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739315	valid&#39;s binary_logloss: 0.251764
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739315	valid&#39;s binary_logloss: 0.251764
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738302	valid&#39;s binary_logloss: 0.251976
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738302	valid&#39;s binary_logloss: 0.251976
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741563	valid&#39;s binary_logloss: 0.250863
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741563	valid&#39;s binary_logloss: 0.250863
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741341	valid&#39;s binary_logloss: 0.251026
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741341	valid&#39;s binary_logloss: 0.251026
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741823	valid&#39;s binary_logloss: 0.251092
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741823	valid&#39;s binary_logloss: 0.251092
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74236	valid&#39;s binary_logloss: 0.250691
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74236	valid&#39;s binary_logloss: 0.250691
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743311	valid&#39;s binary_logloss: 0.250623
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743311	valid&#39;s binary_logloss: 0.250623
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74202	valid&#39;s binary_logloss: 0.250484
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74202	valid&#39;s binary_logloss: 0.250484
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741962	valid&#39;s binary_logloss: 0.250701
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741971	valid&#39;s binary_logloss: 0.250724
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742515	valid&#39;s binary_logloss: 0.250462
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742515	valid&#39;s binary_logloss: 0.250462
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742531	valid&#39;s binary_logloss: 0.250382
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742531	valid&#39;s binary_logloss: 0.250382
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742145	valid&#39;s binary_logloss: 0.250597
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742145	valid&#39;s binary_logloss: 0.250597
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743578	valid&#39;s binary_logloss: 0.249885
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743578	valid&#39;s binary_logloss: 0.249885
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74429	valid&#39;s binary_logloss: 0.249968
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74435	valid&#39;s binary_logloss: 0.24996
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742819	valid&#39;s binary_logloss: 0.250364
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742819	valid&#39;s binary_logloss: 0.250364
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742555	valid&#39;s binary_logloss: 0.25019
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.742566	valid&#39;s binary_logloss: 0.250201
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74433	valid&#39;s binary_logloss: 0.249875
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74433	valid&#39;s binary_logloss: 0.249875
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741545	valid&#39;s binary_logloss: 0.250864
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741545	valid&#39;s binary_logloss: 0.250864
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741109	valid&#39;s binary_logloss: 0.250941
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741109	valid&#39;s binary_logloss: 0.250941
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741291	valid&#39;s binary_logloss: 0.250858
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741291	valid&#39;s binary_logloss: 0.250858
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739703	valid&#39;s binary_logloss: 0.251326
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739703	valid&#39;s binary_logloss: 0.251326
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741763	valid&#39;s binary_logloss: 0.250893
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741763	valid&#39;s binary_logloss: 0.250893
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740019	valid&#39;s binary_logloss: 0.251256
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.740022	valid&#39;s binary_logloss: 0.251281
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740927	valid&#39;s binary_logloss: 0.251071
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740927	valid&#39;s binary_logloss: 0.251071
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739902	valid&#39;s binary_logloss: 0.251266
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739902	valid&#39;s binary_logloss: 0.251266
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74066	valid&#39;s binary_logloss: 0.251124
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74066	valid&#39;s binary_logloss: 0.251124
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741722	valid&#39;s binary_logloss: 0.250913
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741741	valid&#39;s binary_logloss: 0.250929
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733652	valid&#39;s binary_logloss: 0.254516
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733652	valid&#39;s binary_logloss: 0.254516
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733334	valid&#39;s binary_logloss: 0.254446
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733334	valid&#39;s binary_logloss: 0.254446
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733474	valid&#39;s binary_logloss: 0.254495
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733474	valid&#39;s binary_logloss: 0.254495
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73374	valid&#39;s binary_logloss: 0.254526
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73374	valid&#39;s binary_logloss: 0.254526
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734687	valid&#39;s binary_logloss: 0.254301
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734687	valid&#39;s binary_logloss: 0.254301
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718515	valid&#39;s binary_logloss: 0.261341
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718515	valid&#39;s binary_logloss: 0.261341
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715944	valid&#39;s binary_logloss: 0.261589
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715944	valid&#39;s binary_logloss: 0.261589
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.7163	valid&#39;s binary_logloss: 0.261598
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.7163	valid&#39;s binary_logloss: 0.261598
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717469	valid&#39;s binary_logloss: 0.261401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717469	valid&#39;s binary_logloss: 0.261401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717291	valid&#39;s binary_logloss: 0.261466
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717291	valid&#39;s binary_logloss: 0.261466
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742915	valid&#39;s binary_logloss: 0.250011
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742915	valid&#39;s binary_logloss: 0.250011
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741863	valid&#39;s binary_logloss: 0.250459
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741875	valid&#39;s binary_logloss: 0.250469
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742259	valid&#39;s binary_logloss: 0.250401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742259	valid&#39;s binary_logloss: 0.250401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741931	valid&#39;s binary_logloss: 0.2504
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741931	valid&#39;s binary_logloss: 0.2504
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741422	valid&#39;s binary_logloss: 0.250545
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741422	valid&#39;s binary_logloss: 0.250545
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738554	valid&#39;s binary_logloss: 0.251986
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738554	valid&#39;s binary_logloss: 0.251986
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737512	valid&#39;s binary_logloss: 0.252118
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737512	valid&#39;s binary_logloss: 0.252118
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738817	valid&#39;s binary_logloss: 0.251928
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738817	valid&#39;s binary_logloss: 0.251928
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737889	valid&#39;s binary_logloss: 0.252098
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737889	valid&#39;s binary_logloss: 0.252098
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738395	valid&#39;s binary_logloss: 0.251918
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738395	valid&#39;s binary_logloss: 0.251918
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739193	valid&#39;s binary_logloss: 0.251348
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739193	valid&#39;s binary_logloss: 0.251348
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739455	valid&#39;s binary_logloss: 0.251356
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739455	valid&#39;s binary_logloss: 0.251356
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740417	valid&#39;s binary_logloss: 0.251168
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740417	valid&#39;s binary_logloss: 0.251168
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74231	valid&#39;s binary_logloss: 0.25076
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74231	valid&#39;s binary_logloss: 0.25076
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740341	valid&#39;s binary_logloss: 0.251238
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740341	valid&#39;s binary_logloss: 0.251238
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740764	valid&#39;s binary_logloss: 0.25091
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740764	valid&#39;s binary_logloss: 0.25091
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740202	valid&#39;s binary_logloss: 0.250957
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740202	valid&#39;s binary_logloss: 0.250957
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741959	valid&#39;s binary_logloss: 0.250578
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741959	valid&#39;s binary_logloss: 0.250578
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742236	valid&#39;s binary_logloss: 0.250595
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742236	valid&#39;s binary_logloss: 0.250595
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741635	valid&#39;s binary_logloss: 0.250533
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741655	valid&#39;s binary_logloss: 0.250537
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741978	valid&#39;s binary_logloss: 0.250567
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741978	valid&#39;s binary_logloss: 0.250567
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740931	valid&#39;s binary_logloss: 0.250848
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740931	valid&#39;s binary_logloss: 0.250848
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741424	valid&#39;s binary_logloss: 0.250841
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741424	valid&#39;s binary_logloss: 0.250841
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741101	valid&#39;s binary_logloss: 0.250895
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741101	valid&#39;s binary_logloss: 0.250895
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742539	valid&#39;s binary_logloss: 0.250515
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742539	valid&#39;s binary_logloss: 0.250515
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739941	valid&#39;s binary_logloss: 0.251582
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739941	valid&#39;s binary_logloss: 0.251582
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740617	valid&#39;s binary_logloss: 0.251435
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740617	valid&#39;s binary_logloss: 0.251435
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740697	valid&#39;s binary_logloss: 0.25146
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740697	valid&#39;s binary_logloss: 0.25146
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74081	valid&#39;s binary_logloss: 0.25139
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74081	valid&#39;s binary_logloss: 0.25139
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74024	valid&#39;s binary_logloss: 0.251543
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74024	valid&#39;s binary_logloss: 0.251543
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733173	valid&#39;s binary_logloss: 0.254441
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733173	valid&#39;s binary_logloss: 0.254441
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732676	valid&#39;s binary_logloss: 0.254649
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732676	valid&#39;s binary_logloss: 0.254649
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732133	valid&#39;s binary_logloss: 0.254696
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732133	valid&#39;s binary_logloss: 0.254696
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732764	valid&#39;s binary_logloss: 0.254496
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732764	valid&#39;s binary_logloss: 0.254496
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732818	valid&#39;s binary_logloss: 0.254597
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732818	valid&#39;s binary_logloss: 0.254597
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733492	valid&#39;s binary_logloss: 0.254259
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733492	valid&#39;s binary_logloss: 0.254259
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733141	valid&#39;s binary_logloss: 0.254396
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733141	valid&#39;s binary_logloss: 0.254396
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733149	valid&#39;s binary_logloss: 0.254383
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733149	valid&#39;s binary_logloss: 0.254383
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.7343	valid&#39;s binary_logloss: 0.25413
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.7343	valid&#39;s binary_logloss: 0.25413
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734037	valid&#39;s binary_logloss: 0.254187
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734037	valid&#39;s binary_logloss: 0.254187
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740046	valid&#39;s binary_logloss: 0.251582
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740046	valid&#39;s binary_logloss: 0.251582
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739035	valid&#39;s binary_logloss: 0.251823
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739035	valid&#39;s binary_logloss: 0.251823
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739828	valid&#39;s binary_logloss: 0.251607
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739828	valid&#39;s binary_logloss: 0.251607
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739901	valid&#39;s binary_logloss: 0.25168
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739901	valid&#39;s binary_logloss: 0.25168
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740246	valid&#39;s binary_logloss: 0.251538
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740246	valid&#39;s binary_logloss: 0.251538
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73961	valid&#39;s binary_logloss: 0.251229
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73961	valid&#39;s binary_logloss: 0.251229
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740659	valid&#39;s binary_logloss: 0.251267
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740659	valid&#39;s binary_logloss: 0.251267
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740971	valid&#39;s binary_logloss: 0.25121
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740971	valid&#39;s binary_logloss: 0.25121
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741452	valid&#39;s binary_logloss: 0.250889
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741452	valid&#39;s binary_logloss: 0.250889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74041	valid&#39;s binary_logloss: 0.251202
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74041	valid&#39;s binary_logloss: 0.251202
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731649	valid&#39;s binary_logloss: 0.257035
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731649	valid&#39;s binary_logloss: 0.257035
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731653	valid&#39;s binary_logloss: 0.25704
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731653	valid&#39;s binary_logloss: 0.25704
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732612	valid&#39;s binary_logloss: 0.256994
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732612	valid&#39;s binary_logloss: 0.256994
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732583	valid&#39;s binary_logloss: 0.257007
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732583	valid&#39;s binary_logloss: 0.257007
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732578	valid&#39;s binary_logloss: 0.256895
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732578	valid&#39;s binary_logloss: 0.256895
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732401	valid&#39;s binary_logloss: 0.254821
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732401	valid&#39;s binary_logloss: 0.254821
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731144	valid&#39;s binary_logloss: 0.254983
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731144	valid&#39;s binary_logloss: 0.254983
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731054	valid&#39;s binary_logloss: 0.255143
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731054	valid&#39;s binary_logloss: 0.255143
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732886	valid&#39;s binary_logloss: 0.254693
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732886	valid&#39;s binary_logloss: 0.254693
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732893	valid&#39;s binary_logloss: 0.254762
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732893	valid&#39;s binary_logloss: 0.254762
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74362	valid&#39;s binary_logloss: 0.249967
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.743757	valid&#39;s binary_logloss: 0.249926
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743382	valid&#39;s binary_logloss: 0.249889
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743422	valid&#39;s binary_logloss: 0.249877
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743461	valid&#39;s binary_logloss: 0.250101
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.743702	valid&#39;s binary_logloss: 0.250024
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745372	valid&#39;s binary_logloss: 0.249492
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745549	valid&#39;s binary_logloss: 0.249462
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743802	valid&#39;s binary_logloss: 0.249989
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743857	valid&#39;s binary_logloss: 0.249988
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743449	valid&#39;s binary_logloss: 0.250011
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743449	valid&#39;s binary_logloss: 0.250011
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742284	valid&#39;s binary_logloss: 0.25036
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.742302	valid&#39;s binary_logloss: 0.250373
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743163	valid&#39;s binary_logloss: 0.250247
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743213	valid&#39;s binary_logloss: 0.250243
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744498	valid&#39;s binary_logloss: 0.249904
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744498	valid&#39;s binary_logloss: 0.249904
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743954	valid&#39;s binary_logloss: 0.249939
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743964	valid&#39;s binary_logloss: 0.249939
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739317	valid&#39;s binary_logloss: 0.251626
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739317	valid&#39;s binary_logloss: 0.251626
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738113	valid&#39;s binary_logloss: 0.251888
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738113	valid&#39;s binary_logloss: 0.251888
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739029	valid&#39;s binary_logloss: 0.251628
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739029	valid&#39;s binary_logloss: 0.251628
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740185	valid&#39;s binary_logloss: 0.251375
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740185	valid&#39;s binary_logloss: 0.251375
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739556	valid&#39;s binary_logloss: 0.251583
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739556	valid&#39;s binary_logloss: 0.251583
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719748	valid&#39;s binary_logloss: 0.259852
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719748	valid&#39;s binary_logloss: 0.259852
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.71889	valid&#39;s binary_logloss: 0.259911
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.71889	valid&#39;s binary_logloss: 0.259911
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718522	valid&#39;s binary_logloss: 0.25998
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718522	valid&#39;s binary_logloss: 0.25998
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720158	valid&#39;s binary_logloss: 0.259837
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720158	valid&#39;s binary_logloss: 0.259837
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720249	valid&#39;s binary_logloss: 0.25981
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720249	valid&#39;s binary_logloss: 0.25981
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742215	valid&#39;s binary_logloss: 0.250325
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742215	valid&#39;s binary_logloss: 0.250325
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74221	valid&#39;s binary_logloss: 0.250386
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74221	valid&#39;s binary_logloss: 0.250397
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742575	valid&#39;s binary_logloss: 0.250359
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742575	valid&#39;s binary_logloss: 0.250359
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74184	valid&#39;s binary_logloss: 0.250524
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74184	valid&#39;s binary_logloss: 0.250524
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741893	valid&#39;s binary_logloss: 0.250447
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741911	valid&#39;s binary_logloss: 0.25045
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731902	valid&#39;s binary_logloss: 0.254589
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731902	valid&#39;s binary_logloss: 0.254589
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732246	valid&#39;s binary_logloss: 0.254644
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732246	valid&#39;s binary_logloss: 0.254644
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731595	valid&#39;s binary_logloss: 0.254724
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731595	valid&#39;s binary_logloss: 0.254724
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732963	valid&#39;s binary_logloss: 0.254468
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732963	valid&#39;s binary_logloss: 0.254468
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733176	valid&#39;s binary_logloss: 0.254458
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733176	valid&#39;s binary_logloss: 0.254458
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744528	valid&#39;s binary_logloss: 0.249709
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744575	valid&#39;s binary_logloss: 0.249699
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742884	valid&#39;s binary_logloss: 0.250037
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742884	valid&#39;s binary_logloss: 0.250037
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74563	valid&#39;s binary_logloss: 0.249556
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74563	valid&#39;s binary_logloss: 0.249556
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744855	valid&#39;s binary_logloss: 0.249635
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.745119	valid&#39;s binary_logloss: 0.249602
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[87]	valid&#39;s auc: 0.742898	valid&#39;s binary_logloss: 0.250099
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742377	valid&#39;s binary_logloss: 0.25034
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742377	valid&#39;s binary_logloss: 0.25034
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741313	valid&#39;s binary_logloss: 0.250649
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.741376	valid&#39;s binary_logloss: 0.250651
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74352	valid&#39;s binary_logloss: 0.250174
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74352	valid&#39;s binary_logloss: 0.250174
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743835	valid&#39;s binary_logloss: 0.249995
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743837	valid&#39;s binary_logloss: 0.25
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742239	valid&#39;s binary_logloss: 0.250328
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742239	valid&#39;s binary_logloss: 0.250328
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741158	valid&#39;s binary_logloss: 0.250644
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741158	valid&#39;s binary_logloss: 0.250644
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740954	valid&#39;s binary_logloss: 0.250926
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740954	valid&#39;s binary_logloss: 0.250926
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740299	valid&#39;s binary_logloss: 0.251131
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740299	valid&#39;s binary_logloss: 0.251131
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741772	valid&#39;s binary_logloss: 0.250649
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.741776	valid&#39;s binary_logloss: 0.250662
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741581	valid&#39;s binary_logloss: 0.25066
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741581	valid&#39;s binary_logloss: 0.25066
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740584	valid&#39;s binary_logloss: 0.250991
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740584	valid&#39;s binary_logloss: 0.250991
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740642	valid&#39;s binary_logloss: 0.251021
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740642	valid&#39;s binary_logloss: 0.251021
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741458	valid&#39;s binary_logloss: 0.250962
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741458	valid&#39;s binary_logloss: 0.250962
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741068	valid&#39;s binary_logloss: 0.250875
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741068	valid&#39;s binary_logloss: 0.250875
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74202	valid&#39;s binary_logloss: 0.250725
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.742062	valid&#39;s binary_logloss: 0.250725
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 51.2min finished
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745557	valid&#39;s binary_logloss: 0.249369
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745557	valid&#39;s binary_logloss: 0.249369
finishing pca n=50
Elapsed time: 3080.212977409363 seconds
starting pca n=100
Fitting 5 folds for each of 100 candidates, totalling 500 fits
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746993	valid&#39;s binary_logloss: 0.249043
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746993	valid&#39;s binary_logloss: 0.249043
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746147	valid&#39;s binary_logloss: 0.249449
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.746194	valid&#39;s binary_logloss: 0.249444
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746321	valid&#39;s binary_logloss: 0.249318
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s auc: 0.746405	valid&#39;s binary_logloss: 0.249349
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747138	valid&#39;s binary_logloss: 0.249107
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747138	valid&#39;s binary_logloss: 0.249107
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746903	valid&#39;s binary_logloss: 0.249177
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746903	valid&#39;s binary_logloss: 0.249177
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744885	valid&#39;s binary_logloss: 0.249589
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744885	valid&#39;s binary_logloss: 0.249589
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744071	valid&#39;s binary_logloss: 0.24975
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744071	valid&#39;s binary_logloss: 0.24975
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746455	valid&#39;s binary_logloss: 0.249499
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746455	valid&#39;s binary_logloss: 0.249499
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744933	valid&#39;s binary_logloss: 0.249805
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744937	valid&#39;s binary_logloss: 0.249801
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744311	valid&#39;s binary_logloss: 0.25006
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744311	valid&#39;s binary_logloss: 0.25006
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745664	valid&#39;s binary_logloss: 0.249563
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745685	valid&#39;s binary_logloss: 0.249572
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744889	valid&#39;s binary_logloss: 0.249761
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744889	valid&#39;s binary_logloss: 0.249761
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74703	valid&#39;s binary_logloss: 0.249391
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74703	valid&#39;s binary_logloss: 0.249391
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745695	valid&#39;s binary_logloss: 0.249519
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745717	valid&#39;s binary_logloss: 0.249528
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746697	valid&#39;s binary_logloss: 0.249396
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.746751	valid&#39;s binary_logloss: 0.249385
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742185	valid&#39;s binary_logloss: 0.250779
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742185	valid&#39;s binary_logloss: 0.250779
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742792	valid&#39;s binary_logloss: 0.250829
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742792	valid&#39;s binary_logloss: 0.250829
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743985	valid&#39;s binary_logloss: 0.250585
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743985	valid&#39;s binary_logloss: 0.250585
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743595	valid&#39;s binary_logloss: 0.250634
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743595	valid&#39;s binary_logloss: 0.250634
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743921	valid&#39;s binary_logloss: 0.250673
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743921	valid&#39;s binary_logloss: 0.250673
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743481	valid&#39;s binary_logloss: 0.250249
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743481	valid&#39;s binary_logloss: 0.250249
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745054	valid&#39;s binary_logloss: 0.250065
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745054	valid&#39;s binary_logloss: 0.250065
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743535	valid&#39;s binary_logloss: 0.25025
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743535	valid&#39;s binary_logloss: 0.25025
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744496	valid&#39;s binary_logloss: 0.250011
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744496	valid&#39;s binary_logloss: 0.250011
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744155	valid&#39;s binary_logloss: 0.250225
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744155	valid&#39;s binary_logloss: 0.250225
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730327	valid&#39;s binary_logloss: 0.25595
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730327	valid&#39;s binary_logloss: 0.25595
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730224	valid&#39;s binary_logloss: 0.256025
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730224	valid&#39;s binary_logloss: 0.256025
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729909	valid&#39;s binary_logloss: 0.255985
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729909	valid&#39;s binary_logloss: 0.255985
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731005	valid&#39;s binary_logloss: 0.255892
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731005	valid&#39;s binary_logloss: 0.255892
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730657	valid&#39;s binary_logloss: 0.255934
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730657	valid&#39;s binary_logloss: 0.255934
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715264	valid&#39;s binary_logloss: 0.262648
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715264	valid&#39;s binary_logloss: 0.262648
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712195	valid&#39;s binary_logloss: 0.262889
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712195	valid&#39;s binary_logloss: 0.262889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.713145	valid&#39;s binary_logloss: 0.262897
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.713145	valid&#39;s binary_logloss: 0.262897
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715167	valid&#39;s binary_logloss: 0.262682
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715167	valid&#39;s binary_logloss: 0.262682
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715155	valid&#39;s binary_logloss: 0.262648
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715155	valid&#39;s binary_logloss: 0.262648
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743837	valid&#39;s binary_logloss: 0.250277
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743837	valid&#39;s binary_logloss: 0.250277
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74321	valid&#39;s binary_logloss: 0.250471
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74321	valid&#39;s binary_logloss: 0.250471
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743031	valid&#39;s binary_logloss: 0.250485
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743031	valid&#39;s binary_logloss: 0.250485
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743226	valid&#39;s binary_logloss: 0.250554
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743226	valid&#39;s binary_logloss: 0.250554
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743104	valid&#39;s binary_logloss: 0.250558
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743104	valid&#39;s binary_logloss: 0.250558
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74501	valid&#39;s binary_logloss: 0.249816
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74501	valid&#39;s binary_logloss: 0.249816
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74342	valid&#39;s binary_logloss: 0.250216
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74342	valid&#39;s binary_logloss: 0.250216
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743908	valid&#39;s binary_logloss: 0.250216
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743908	valid&#39;s binary_logloss: 0.250216
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746054	valid&#39;s binary_logloss: 0.249627
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746054	valid&#39;s binary_logloss: 0.249627
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744468	valid&#39;s binary_logloss: 0.250062
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744468	valid&#39;s binary_logloss: 0.250062
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740826	valid&#39;s binary_logloss: 0.251583
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740826	valid&#39;s binary_logloss: 0.251583
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740565	valid&#39;s binary_logloss: 0.251664
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740565	valid&#39;s binary_logloss: 0.251664
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742518	valid&#39;s binary_logloss: 0.25134
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742518	valid&#39;s binary_logloss: 0.25134
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741839	valid&#39;s binary_logloss: 0.251477
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741839	valid&#39;s binary_logloss: 0.251477
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742429	valid&#39;s binary_logloss: 0.251401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742429	valid&#39;s binary_logloss: 0.251401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745442	valid&#39;s binary_logloss: 0.249698
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745442	valid&#39;s binary_logloss: 0.249698
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74544	valid&#39;s binary_logloss: 0.249859
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74544	valid&#39;s binary_logloss: 0.249859
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746075	valid&#39;s binary_logloss: 0.249762
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746075	valid&#39;s binary_logloss: 0.249762
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746392	valid&#39;s binary_logloss: 0.249421
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746392	valid&#39;s binary_logloss: 0.249421
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745937	valid&#39;s binary_logloss: 0.249644
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745937	valid&#39;s binary_logloss: 0.249644
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746441	valid&#39;s binary_logloss: 0.249167
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746441	valid&#39;s binary_logloss: 0.249167
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745732	valid&#39;s binary_logloss: 0.2494
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745732	valid&#39;s binary_logloss: 0.2494
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745748	valid&#39;s binary_logloss: 0.249566
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745748	valid&#39;s binary_logloss: 0.249566
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745482	valid&#39;s binary_logloss: 0.249535
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745505	valid&#39;s binary_logloss: 0.24955
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[89]	valid&#39;s auc: 0.746216	valid&#39;s binary_logloss: 0.24959
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746747	valid&#39;s binary_logloss: 0.249196
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746747	valid&#39;s binary_logloss: 0.249196
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746268	valid&#39;s binary_logloss: 0.249297
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746268	valid&#39;s binary_logloss: 0.249297
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746207	valid&#39;s binary_logloss: 0.249303
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.746257	valid&#39;s binary_logloss: 0.249296
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745783	valid&#39;s binary_logloss: 0.249318
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745783	valid&#39;s binary_logloss: 0.249318
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746711	valid&#39;s binary_logloss: 0.249299
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746711	valid&#39;s binary_logloss: 0.249299
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746669	valid&#39;s binary_logloss: 0.249285
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746669	valid&#39;s binary_logloss: 0.249285
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744736	valid&#39;s binary_logloss: 0.24965
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744736	valid&#39;s binary_logloss: 0.24965
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746709	valid&#39;s binary_logloss: 0.249108
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746709	valid&#39;s binary_logloss: 0.249108
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745946	valid&#39;s binary_logloss: 0.249358
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745951	valid&#39;s binary_logloss: 0.24936
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747478	valid&#39;s binary_logloss: 0.249105
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747478	valid&#39;s binary_logloss: 0.249105
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72189	valid&#39;s binary_logloss: 0.260146
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72189	valid&#39;s binary_logloss: 0.260146
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719179	valid&#39;s binary_logloss: 0.260432
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719179	valid&#39;s binary_logloss: 0.260432
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720441	valid&#39;s binary_logloss: 0.260322
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720441	valid&#39;s binary_logloss: 0.260322
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721022	valid&#39;s binary_logloss: 0.260199
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721022	valid&#39;s binary_logloss: 0.260199
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722061	valid&#39;s binary_logloss: 0.260103
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.722138	valid&#39;s binary_logloss: 0.260184
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735208	valid&#39;s binary_logloss: 0.253791
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735208	valid&#39;s binary_logloss: 0.253791
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734622	valid&#39;s binary_logloss: 0.253903
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734622	valid&#39;s binary_logloss: 0.253903
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735066	valid&#39;s binary_logloss: 0.253914
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735066	valid&#39;s binary_logloss: 0.253914
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735606	valid&#39;s binary_logloss: 0.253663
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735606	valid&#39;s binary_logloss: 0.253663
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735972	valid&#39;s binary_logloss: 0.253765
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735972	valid&#39;s binary_logloss: 0.253765
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743261	valid&#39;s binary_logloss: 0.250372
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743261	valid&#39;s binary_logloss: 0.250372
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742808	valid&#39;s binary_logloss: 0.250488
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742808	valid&#39;s binary_logloss: 0.250488
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745529	valid&#39;s binary_logloss: 0.250048
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745529	valid&#39;s binary_logloss: 0.250048
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743952	valid&#39;s binary_logloss: 0.250208
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743966	valid&#39;s binary_logloss: 0.25022
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745515	valid&#39;s binary_logloss: 0.249952
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745515	valid&#39;s binary_logloss: 0.249952
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[84]	valid&#39;s auc: 0.745634	valid&#39;s binary_logloss: 0.24974
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[89]	valid&#39;s auc: 0.744658	valid&#39;s binary_logloss: 0.249995
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[70]	valid&#39;s auc: 0.744009	valid&#39;s binary_logloss: 0.24984
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[74]	valid&#39;s auc: 0.745421	valid&#39;s binary_logloss: 0.249197
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[80]	valid&#39;s auc: 0.745816	valid&#39;s binary_logloss: 0.24946
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743719	valid&#39;s binary_logloss: 0.25045
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743719	valid&#39;s binary_logloss: 0.25045
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742226	valid&#39;s binary_logloss: 0.250716
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742226	valid&#39;s binary_logloss: 0.250716
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743496	valid&#39;s binary_logloss: 0.250547
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743496	valid&#39;s binary_logloss: 0.250547
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742671	valid&#39;s binary_logloss: 0.250816
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742671	valid&#39;s binary_logloss: 0.250816
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743918	valid&#39;s binary_logloss: 0.250456
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743918	valid&#39;s binary_logloss: 0.250456
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742475	valid&#39;s binary_logloss: 0.25104
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742475	valid&#39;s binary_logloss: 0.25104
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74128	valid&#39;s binary_logloss: 0.251289
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74128	valid&#39;s binary_logloss: 0.251289
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742548	valid&#39;s binary_logloss: 0.251155
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742548	valid&#39;s binary_logloss: 0.251155
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742161	valid&#39;s binary_logloss: 0.251104
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742161	valid&#39;s binary_logloss: 0.251104
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742133	valid&#39;s binary_logloss: 0.251213
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742133	valid&#39;s binary_logloss: 0.251213
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745277	valid&#39;s binary_logloss: 0.249848
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745277	valid&#39;s binary_logloss: 0.249848
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744543	valid&#39;s binary_logloss: 0.249798
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744543	valid&#39;s binary_logloss: 0.249798
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746623	valid&#39;s binary_logloss: 0.24944
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746623	valid&#39;s binary_logloss: 0.24944
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745668	valid&#39;s binary_logloss: 0.249574
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745668	valid&#39;s binary_logloss: 0.249574
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745243	valid&#39;s binary_logloss: 0.249745
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745243	valid&#39;s binary_logloss: 0.249745
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719631	valid&#39;s binary_logloss: 0.261987
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719631	valid&#39;s binary_logloss: 0.261987
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717161	valid&#39;s binary_logloss: 0.262228
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717161	valid&#39;s binary_logloss: 0.262228
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718768	valid&#39;s binary_logloss: 0.262107
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718768	valid&#39;s binary_logloss: 0.262107
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719879	valid&#39;s binary_logloss: 0.262039
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719879	valid&#39;s binary_logloss: 0.262039
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720788	valid&#39;s binary_logloss: 0.261913
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720788	valid&#39;s binary_logloss: 0.261913
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732939	valid&#39;s binary_logloss: 0.255263
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732939	valid&#39;s binary_logloss: 0.255263
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731665	valid&#39;s binary_logloss: 0.255355
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731665	valid&#39;s binary_logloss: 0.255355
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732595	valid&#39;s binary_logloss: 0.255316
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732595	valid&#39;s binary_logloss: 0.255316
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732053	valid&#39;s binary_logloss: 0.255364
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732053	valid&#39;s binary_logloss: 0.255364
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733489	valid&#39;s binary_logloss: 0.255219
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733489	valid&#39;s binary_logloss: 0.255219
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746125	valid&#39;s binary_logloss: 0.249367
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746125	valid&#39;s binary_logloss: 0.249367
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745538	valid&#39;s binary_logloss: 0.249575
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745538	valid&#39;s binary_logloss: 0.249575
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745751	valid&#39;s binary_logloss: 0.249573
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745827	valid&#39;s binary_logloss: 0.24956
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747188	valid&#39;s binary_logloss: 0.249363
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747191	valid&#39;s binary_logloss: 0.249364
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745352	valid&#39;s binary_logloss: 0.249665
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745352	valid&#39;s binary_logloss: 0.249665
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729671	valid&#39;s binary_logloss: 0.256195
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729671	valid&#39;s binary_logloss: 0.256195
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729006	valid&#39;s binary_logloss: 0.256298
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729006	valid&#39;s binary_logloss: 0.256298
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.729227	valid&#39;s binary_logloss: 0.256273
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.729227	valid&#39;s binary_logloss: 0.256273
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73009	valid&#39;s binary_logloss: 0.256133
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73009	valid&#39;s binary_logloss: 0.256133
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730625	valid&#39;s binary_logloss: 0.256048
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730625	valid&#39;s binary_logloss: 0.256048
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743885	valid&#39;s binary_logloss: 0.249767
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743885	valid&#39;s binary_logloss: 0.249767
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745928	valid&#39;s binary_logloss: 0.249284
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745928	valid&#39;s binary_logloss: 0.249284
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745698	valid&#39;s binary_logloss: 0.249256
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745698	valid&#39;s binary_logloss: 0.249256
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745404	valid&#39;s binary_logloss: 0.24947
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745404	valid&#39;s binary_logloss: 0.24947
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74689	valid&#39;s binary_logloss: 0.249405
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.746914	valid&#39;s binary_logloss: 0.249408
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734585	valid&#39;s binary_logloss: 0.254485
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734585	valid&#39;s binary_logloss: 0.254485
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732906	valid&#39;s binary_logloss: 0.254751
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732906	valid&#39;s binary_logloss: 0.254751
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733963	valid&#39;s binary_logloss: 0.254622
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733963	valid&#39;s binary_logloss: 0.254622
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733414	valid&#39;s binary_logloss: 0.254576
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733414	valid&#39;s binary_logloss: 0.254576
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734827	valid&#39;s binary_logloss: 0.254525
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734827	valid&#39;s binary_logloss: 0.254525
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741592	valid&#39;s binary_logloss: 0.251451
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741592	valid&#39;s binary_logloss: 0.251451
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740952	valid&#39;s binary_logloss: 0.251618
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740952	valid&#39;s binary_logloss: 0.251618
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742199	valid&#39;s binary_logloss: 0.251332
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742199	valid&#39;s binary_logloss: 0.251332
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741559	valid&#39;s binary_logloss: 0.251411
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741559	valid&#39;s binary_logloss: 0.251411
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742842	valid&#39;s binary_logloss: 0.251238
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742842	valid&#39;s binary_logloss: 0.251238
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747499	valid&#39;s binary_logloss: 0.24896
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747499	valid&#39;s binary_logloss: 0.24896
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747766	valid&#39;s binary_logloss: 0.248879
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747766	valid&#39;s binary_logloss: 0.248879
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745979	valid&#39;s binary_logloss: 0.249482
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.746025	valid&#39;s binary_logloss: 0.249481
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746803	valid&#39;s binary_logloss: 0.249097
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746803	valid&#39;s binary_logloss: 0.249097
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745672	valid&#39;s binary_logloss: 0.249392
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745672	valid&#39;s binary_logloss: 0.249392
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737482	valid&#39;s binary_logloss: 0.252928
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737482	valid&#39;s binary_logloss: 0.252928
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737746	valid&#39;s binary_logloss: 0.25285
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737746	valid&#39;s binary_logloss: 0.25285
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73871	valid&#39;s binary_logloss: 0.25284
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73871	valid&#39;s binary_logloss: 0.25284
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739395	valid&#39;s binary_logloss: 0.25258
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739395	valid&#39;s binary_logloss: 0.25258
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740311	valid&#39;s binary_logloss: 0.252506
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740311	valid&#39;s binary_logloss: 0.252506
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746467	valid&#39;s binary_logloss: 0.249167
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74648	valid&#39;s binary_logloss: 0.24917
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745097	valid&#39;s binary_logloss: 0.249492
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745097	valid&#39;s binary_logloss: 0.249492
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745356	valid&#39;s binary_logloss: 0.249456
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745356	valid&#39;s binary_logloss: 0.249456
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74701	valid&#39;s binary_logloss: 0.249111
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747023	valid&#39;s binary_logloss: 0.249099
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745588	valid&#39;s binary_logloss: 0.249621
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s auc: 0.745592	valid&#39;s binary_logloss: 0.249654
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741049	valid&#39;s binary_logloss: 0.251859
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741049	valid&#39;s binary_logloss: 0.251859
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740889	valid&#39;s binary_logloss: 0.251887
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740889	valid&#39;s binary_logloss: 0.251887
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741464	valid&#39;s binary_logloss: 0.251768
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741464	valid&#39;s binary_logloss: 0.251768
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742184	valid&#39;s binary_logloss: 0.251639
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742184	valid&#39;s binary_logloss: 0.251639
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742942	valid&#39;s binary_logloss: 0.251599
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742942	valid&#39;s binary_logloss: 0.251599
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736976	valid&#39;s binary_logloss: 0.253021
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736976	valid&#39;s binary_logloss: 0.253021
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736715	valid&#39;s binary_logloss: 0.253211
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736715	valid&#39;s binary_logloss: 0.253211
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737759	valid&#39;s binary_logloss: 0.25306
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737759	valid&#39;s binary_logloss: 0.25306
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737141	valid&#39;s binary_logloss: 0.252973
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737141	valid&#39;s binary_logloss: 0.252973
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736626	valid&#39;s binary_logloss: 0.25316
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736626	valid&#39;s binary_logloss: 0.25316
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74416	valid&#39;s binary_logloss: 0.250249
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74416	valid&#39;s binary_logloss: 0.250249
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743365	valid&#39;s binary_logloss: 0.250298
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743365	valid&#39;s binary_logloss: 0.250298
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74495	valid&#39;s binary_logloss: 0.250183
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74495	valid&#39;s binary_logloss: 0.250183
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74444	valid&#39;s binary_logloss: 0.25018
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74444	valid&#39;s binary_logloss: 0.25018
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745021	valid&#39;s binary_logloss: 0.250008
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745021	valid&#39;s binary_logloss: 0.250008
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734517	valid&#39;s binary_logloss: 0.254245
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734517	valid&#39;s binary_logloss: 0.254245
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734523	valid&#39;s binary_logloss: 0.254235
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734523	valid&#39;s binary_logloss: 0.254235
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735128	valid&#39;s binary_logloss: 0.254215
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735128	valid&#39;s binary_logloss: 0.254215
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734158	valid&#39;s binary_logloss: 0.254319
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734158	valid&#39;s binary_logloss: 0.254319
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734687	valid&#39;s binary_logloss: 0.254238
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734687	valid&#39;s binary_logloss: 0.254238
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712769	valid&#39;s binary_logloss: 0.263396
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712769	valid&#39;s binary_logloss: 0.263396
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.710444	valid&#39;s binary_logloss: 0.263575
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.710444	valid&#39;s binary_logloss: 0.263575
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.710087	valid&#39;s binary_logloss: 0.263702
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.710087	valid&#39;s binary_logloss: 0.263702
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712193	valid&#39;s binary_logloss: 0.263533
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712193	valid&#39;s binary_logloss: 0.263533
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712475	valid&#39;s binary_logloss: 0.263417
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712475	valid&#39;s binary_logloss: 0.263417
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723826	valid&#39;s binary_logloss: 0.258623
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723826	valid&#39;s binary_logloss: 0.258623
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722042	valid&#39;s binary_logloss: 0.258809
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722042	valid&#39;s binary_logloss: 0.258809
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723185	valid&#39;s binary_logloss: 0.258679
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723185	valid&#39;s binary_logloss: 0.258679
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724504	valid&#39;s binary_logloss: 0.258549
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724504	valid&#39;s binary_logloss: 0.258549
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724396	valid&#39;s binary_logloss: 0.258505
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724396	valid&#39;s binary_logloss: 0.258505
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747023	valid&#39;s binary_logloss: 0.248808
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747023	valid&#39;s binary_logloss: 0.248808
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745736	valid&#39;s binary_logloss: 0.249319
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745736	valid&#39;s binary_logloss: 0.249319
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747303	valid&#39;s binary_logloss: 0.248925
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.747323	valid&#39;s binary_logloss: 0.248936
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745291	valid&#39;s binary_logloss: 0.249426
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745344	valid&#39;s binary_logloss: 0.249407
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746289	valid&#39;s binary_logloss: 0.249336
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746289	valid&#39;s binary_logloss: 0.249336
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736697	valid&#39;s binary_logloss: 0.253374
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736697	valid&#39;s binary_logloss: 0.253374
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737403	valid&#39;s binary_logloss: 0.25327
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737403	valid&#39;s binary_logloss: 0.25327
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737503	valid&#39;s binary_logloss: 0.25322
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737503	valid&#39;s binary_logloss: 0.25322
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737744	valid&#39;s binary_logloss: 0.253168
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737744	valid&#39;s binary_logloss: 0.253168
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737526	valid&#39;s binary_logloss: 0.253139
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737526	valid&#39;s binary_logloss: 0.253139
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746309	valid&#39;s binary_logloss: 0.249222
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746309	valid&#39;s binary_logloss: 0.249222
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746454	valid&#39;s binary_logloss: 0.24932
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.746536	valid&#39;s binary_logloss: 0.249327
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748031	valid&#39;s binary_logloss: 0.248826
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.748112	valid&#39;s binary_logloss: 0.248822
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747694	valid&#39;s binary_logloss: 0.248979
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747694	valid&#39;s binary_logloss: 0.248979
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748072	valid&#39;s binary_logloss: 0.248809
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748072	valid&#39;s binary_logloss: 0.248809
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732423	valid&#39;s binary_logloss: 0.255063
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732423	valid&#39;s binary_logloss: 0.255063
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731484	valid&#39;s binary_logloss: 0.255226
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731484	valid&#39;s binary_logloss: 0.255226
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732775	valid&#39;s binary_logloss: 0.255086
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732775	valid&#39;s binary_logloss: 0.255086
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733461	valid&#39;s binary_logloss: 0.255012
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733461	valid&#39;s binary_logloss: 0.255012
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733745	valid&#39;s binary_logloss: 0.255022
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733745	valid&#39;s binary_logloss: 0.255022
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736386	valid&#39;s binary_logloss: 0.25364
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736386	valid&#39;s binary_logloss: 0.25364
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735562	valid&#39;s binary_logloss: 0.253676
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735562	valid&#39;s binary_logloss: 0.253676
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736069	valid&#39;s binary_logloss: 0.253729
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736069	valid&#39;s binary_logloss: 0.253729
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735607	valid&#39;s binary_logloss: 0.253731
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735607	valid&#39;s binary_logloss: 0.253731
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737046	valid&#39;s binary_logloss: 0.253585
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737046	valid&#39;s binary_logloss: 0.253585
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745947	valid&#39;s binary_logloss: 0.249486
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745947	valid&#39;s binary_logloss: 0.249486
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[77]	valid&#39;s auc: 0.745619	valid&#39;s binary_logloss: 0.249472
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745209	valid&#39;s binary_logloss: 0.249344
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.745308	valid&#39;s binary_logloss: 0.249315
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743876	valid&#39;s binary_logloss: 0.249742
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743912	valid&#39;s binary_logloss: 0.249734
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74663	valid&#39;s binary_logloss: 0.249256
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74663	valid&#39;s binary_logloss: 0.249256
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725825	valid&#39;s binary_logloss: 0.257579
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725825	valid&#39;s binary_logloss: 0.257579
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724799	valid&#39;s binary_logloss: 0.257682
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724799	valid&#39;s binary_logloss: 0.257682
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725586	valid&#39;s binary_logloss: 0.257674
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725586	valid&#39;s binary_logloss: 0.257674
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726036	valid&#39;s binary_logloss: 0.257578
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726036	valid&#39;s binary_logloss: 0.257578
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726356	valid&#39;s binary_logloss: 0.257586
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726356	valid&#39;s binary_logloss: 0.257586
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745434	valid&#39;s binary_logloss: 0.24985
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745434	valid&#39;s binary_logloss: 0.24985
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743356	valid&#39;s binary_logloss: 0.250221
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743356	valid&#39;s binary_logloss: 0.250221
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746524	valid&#39;s binary_logloss: 0.249694
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746524	valid&#39;s binary_logloss: 0.249694
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745612	valid&#39;s binary_logloss: 0.24977
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745612	valid&#39;s binary_logloss: 0.24977
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74549	valid&#39;s binary_logloss: 0.249852
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74549	valid&#39;s binary_logloss: 0.249852
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741567	valid&#39;s binary_logloss: 0.251704
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741567	valid&#39;s binary_logloss: 0.251704
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740449	valid&#39;s binary_logloss: 0.25184
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740449	valid&#39;s binary_logloss: 0.25184
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742641	valid&#39;s binary_logloss: 0.251458
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742641	valid&#39;s binary_logloss: 0.251458
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741132	valid&#39;s binary_logloss: 0.251727
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741132	valid&#39;s binary_logloss: 0.251727
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743886	valid&#39;s binary_logloss: 0.251213
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743886	valid&#39;s binary_logloss: 0.251213
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739492	valid&#39;s binary_logloss: 0.252096
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739492	valid&#39;s binary_logloss: 0.252096
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738816	valid&#39;s binary_logloss: 0.252257
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738816	valid&#39;s binary_logloss: 0.252257
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740052	valid&#39;s binary_logloss: 0.252027
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740052	valid&#39;s binary_logloss: 0.252027
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739636	valid&#39;s binary_logloss: 0.252104
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739636	valid&#39;s binary_logloss: 0.252104
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739541	valid&#39;s binary_logloss: 0.252135
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739541	valid&#39;s binary_logloss: 0.252135
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742685	valid&#39;s binary_logloss: 0.250655
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742685	valid&#39;s binary_logloss: 0.250655
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742512	valid&#39;s binary_logloss: 0.250764
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742512	valid&#39;s binary_logloss: 0.250764
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742611	valid&#39;s binary_logloss: 0.250706
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742611	valid&#39;s binary_logloss: 0.250706
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743181	valid&#39;s binary_logloss: 0.250568
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.743235	valid&#39;s binary_logloss: 0.250604
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744107	valid&#39;s binary_logloss: 0.250375
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744107	valid&#39;s binary_logloss: 0.250375
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747514	valid&#39;s binary_logloss: 0.248838
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747514	valid&#39;s binary_logloss: 0.248838
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746693	valid&#39;s binary_logloss: 0.24915
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746693	valid&#39;s binary_logloss: 0.24915
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747602	valid&#39;s binary_logloss: 0.249122
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747626	valid&#39;s binary_logloss: 0.249112
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747139	valid&#39;s binary_logloss: 0.249259
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747139	valid&#39;s binary_logloss: 0.249259
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745407	valid&#39;s binary_logloss: 0.249644
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745407	valid&#39;s binary_logloss: 0.249644
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73856	valid&#39;s binary_logloss: 0.252328
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73856	valid&#39;s binary_logloss: 0.252328
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738349	valid&#39;s binary_logloss: 0.252298
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738349	valid&#39;s binary_logloss: 0.252298
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740137	valid&#39;s binary_logloss: 0.252093
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740137	valid&#39;s binary_logloss: 0.252093
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739517	valid&#39;s binary_logloss: 0.252082
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739517	valid&#39;s binary_logloss: 0.252082
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738368	valid&#39;s binary_logloss: 0.252328
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738368	valid&#39;s binary_logloss: 0.252328
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742162	valid&#39;s binary_logloss: 0.251476
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742162	valid&#39;s binary_logloss: 0.251476
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740914	valid&#39;s binary_logloss: 0.251592
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740914	valid&#39;s binary_logloss: 0.251592
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742688	valid&#39;s binary_logloss: 0.251287
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742688	valid&#39;s binary_logloss: 0.251287
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742653	valid&#39;s binary_logloss: 0.251305
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742653	valid&#39;s binary_logloss: 0.251305
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743037	valid&#39;s binary_logloss: 0.25121
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743037	valid&#39;s binary_logloss: 0.25121
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[81]	valid&#39;s auc: 0.745882	valid&#39;s binary_logloss: 0.249339
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746428	valid&#39;s binary_logloss: 0.249049
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74646	valid&#39;s binary_logloss: 0.249049
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746907	valid&#39;s binary_logloss: 0.248962
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746907	valid&#39;s binary_logloss: 0.248962
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74631	valid&#39;s binary_logloss: 0.249252
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74631	valid&#39;s binary_logloss: 0.249252
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[87]	valid&#39;s auc: 0.746439	valid&#39;s binary_logloss: 0.249385
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743876	valid&#39;s binary_logloss: 0.250068
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743876	valid&#39;s binary_logloss: 0.250068
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74342	valid&#39;s binary_logloss: 0.250268
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743442	valid&#39;s binary_logloss: 0.250283
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744084	valid&#39;s binary_logloss: 0.250241
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744084	valid&#39;s binary_logloss: 0.250241
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74359	valid&#39;s binary_logloss: 0.250192
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.743647	valid&#39;s binary_logloss: 0.250204
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743598	valid&#39;s binary_logloss: 0.250273
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743598	valid&#39;s binary_logloss: 0.250273
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718546	valid&#39;s binary_logloss: 0.26068
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718546	valid&#39;s binary_logloss: 0.26068
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.716452	valid&#39;s binary_logloss: 0.260912
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.716452	valid&#39;s binary_logloss: 0.260912
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.716614	valid&#39;s binary_logloss: 0.260923
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.716614	valid&#39;s binary_logloss: 0.260923
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718078	valid&#39;s binary_logloss: 0.260791
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718078	valid&#39;s binary_logloss: 0.260791
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718062	valid&#39;s binary_logloss: 0.260777
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718062	valid&#39;s binary_logloss: 0.260777
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73952	valid&#39;s binary_logloss: 0.252126
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73952	valid&#39;s binary_logloss: 0.252126
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738093	valid&#39;s binary_logloss: 0.252421
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738093	valid&#39;s binary_logloss: 0.252421
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740331	valid&#39;s binary_logloss: 0.252052
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740331	valid&#39;s binary_logloss: 0.252052
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739929	valid&#39;s binary_logloss: 0.251993
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739929	valid&#39;s binary_logloss: 0.251993
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740215	valid&#39;s binary_logloss: 0.251999
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740215	valid&#39;s binary_logloss: 0.251999
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744867	valid&#39;s binary_logloss: 0.249667
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744867	valid&#39;s binary_logloss: 0.249667
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743847	valid&#39;s binary_logloss: 0.249913
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743847	valid&#39;s binary_logloss: 0.249913
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745414	valid&#39;s binary_logloss: 0.249682
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745414	valid&#39;s binary_logloss: 0.249682
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744144	valid&#39;s binary_logloss: 0.249868
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744162	valid&#39;s binary_logloss: 0.249871
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745406	valid&#39;s binary_logloss: 0.249716
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745406	valid&#39;s binary_logloss: 0.249716
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739639	valid&#39;s binary_logloss: 0.25205
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739639	valid&#39;s binary_logloss: 0.25205
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739038	valid&#39;s binary_logloss: 0.252143
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739038	valid&#39;s binary_logloss: 0.252143
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74138	valid&#39;s binary_logloss: 0.25167
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74138	valid&#39;s binary_logloss: 0.25167
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739038	valid&#39;s binary_logloss: 0.252098
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739038	valid&#39;s binary_logloss: 0.252098
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741752	valid&#39;s binary_logloss: 0.251638
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741752	valid&#39;s binary_logloss: 0.251638
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738327	valid&#39;s binary_logloss: 0.252532
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738327	valid&#39;s binary_logloss: 0.252532
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738181	valid&#39;s binary_logloss: 0.252562
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738181	valid&#39;s binary_logloss: 0.252562
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738224	valid&#39;s binary_logloss: 0.252657
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738224	valid&#39;s binary_logloss: 0.252657
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739456	valid&#39;s binary_logloss: 0.252323
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739456	valid&#39;s binary_logloss: 0.252323
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739406	valid&#39;s binary_logloss: 0.252442
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739406	valid&#39;s binary_logloss: 0.252442
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724374	valid&#39;s binary_logloss: 0.260446
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724374	valid&#39;s binary_logloss: 0.260446
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723527	valid&#39;s binary_logloss: 0.260425
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723527	valid&#39;s binary_logloss: 0.260425
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724422	valid&#39;s binary_logloss: 0.260424
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724422	valid&#39;s binary_logloss: 0.260424
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725306	valid&#39;s binary_logloss: 0.260306
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725306	valid&#39;s binary_logloss: 0.260306
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725597	valid&#39;s binary_logloss: 0.260306
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725597	valid&#39;s binary_logloss: 0.260306
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731967	valid&#39;s binary_logloss: 0.255378
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731967	valid&#39;s binary_logloss: 0.255378
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73062	valid&#39;s binary_logloss: 0.255565
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73062	valid&#39;s binary_logloss: 0.255565
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732665	valid&#39;s binary_logloss: 0.255291
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732665	valid&#39;s binary_logloss: 0.255291
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731513	valid&#39;s binary_logloss: 0.255336
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731513	valid&#39;s binary_logloss: 0.255336
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732948	valid&#39;s binary_logloss: 0.255234
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732948	valid&#39;s binary_logloss: 0.255234
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745145	valid&#39;s binary_logloss: 0.249548
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745145	valid&#39;s binary_logloss: 0.249548
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745718	valid&#39;s binary_logloss: 0.249541
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.745761	valid&#39;s binary_logloss: 0.249553
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745032	valid&#39;s binary_logloss: 0.249729
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745032	valid&#39;s binary_logloss: 0.249729
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745245	valid&#39;s binary_logloss: 0.249595
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745245	valid&#39;s binary_logloss: 0.249595
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74639	valid&#39;s binary_logloss: 0.249429
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74639	valid&#39;s binary_logloss: 0.249429
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719831	valid&#39;s binary_logloss: 0.260246
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719831	valid&#39;s binary_logloss: 0.260246
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718193	valid&#39;s binary_logloss: 0.260468
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718193	valid&#39;s binary_logloss: 0.260468
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718296	valid&#39;s binary_logloss: 0.260448
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718296	valid&#39;s binary_logloss: 0.260448
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719929	valid&#39;s binary_logloss: 0.260352
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719929	valid&#39;s binary_logloss: 0.260352
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720089	valid&#39;s binary_logloss: 0.260296
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720089	valid&#39;s binary_logloss: 0.260296
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725805	valid&#39;s binary_logloss: 0.257951
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725805	valid&#39;s binary_logloss: 0.257951
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724447	valid&#39;s binary_logloss: 0.258122
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724447	valid&#39;s binary_logloss: 0.258122
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725207	valid&#39;s binary_logloss: 0.258075
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725207	valid&#39;s binary_logloss: 0.258075
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72547	valid&#39;s binary_logloss: 0.258061
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72547	valid&#39;s binary_logloss: 0.258061
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72718	valid&#39;s binary_logloss: 0.257808
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72718	valid&#39;s binary_logloss: 0.257808
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712717	valid&#39;s binary_logloss: 0.262979
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712717	valid&#39;s binary_logloss: 0.262979
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.710474	valid&#39;s binary_logloss: 0.263126
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.710474	valid&#39;s binary_logloss: 0.263126
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.709113	valid&#39;s binary_logloss: 0.263235
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.709113	valid&#39;s binary_logloss: 0.263235
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.710838	valid&#39;s binary_logloss: 0.263068
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.710838	valid&#39;s binary_logloss: 0.263068
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711607	valid&#39;s binary_logloss: 0.263066
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711607	valid&#39;s binary_logloss: 0.263066
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741477	valid&#39;s binary_logloss: 0.251377
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741477	valid&#39;s binary_logloss: 0.251377
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741032	valid&#39;s binary_logloss: 0.251465
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741032	valid&#39;s binary_logloss: 0.251465
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741742	valid&#39;s binary_logloss: 0.25136
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741742	valid&#39;s binary_logloss: 0.25136
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741531	valid&#39;s binary_logloss: 0.251384
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741531	valid&#39;s binary_logloss: 0.251384
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742048	valid&#39;s binary_logloss: 0.251348
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742048	valid&#39;s binary_logloss: 0.251348
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721057	valid&#39;s binary_logloss: 0.261097
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721057	valid&#39;s binary_logloss: 0.261097
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720987	valid&#39;s binary_logloss: 0.261176
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720987	valid&#39;s binary_logloss: 0.261176
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723087	valid&#39;s binary_logloss: 0.260991
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723087	valid&#39;s binary_logloss: 0.260991
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.7233	valid&#39;s binary_logloss: 0.260968
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.7233	valid&#39;s binary_logloss: 0.260968
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723005	valid&#39;s binary_logloss: 0.261045
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723005	valid&#39;s binary_logloss: 0.261045
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742134	valid&#39;s binary_logloss: 0.25073
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742134	valid&#39;s binary_logloss: 0.25073
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742806	valid&#39;s binary_logloss: 0.250659
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742806	valid&#39;s binary_logloss: 0.250659
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742282	valid&#39;s binary_logloss: 0.250763
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.742291	valid&#39;s binary_logloss: 0.25078
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742453	valid&#39;s binary_logloss: 0.250647
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742453	valid&#39;s binary_logloss: 0.250647
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742555	valid&#39;s binary_logloss: 0.250825
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742555	valid&#39;s binary_logloss: 0.250825
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723141	valid&#39;s binary_logloss: 0.259646
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723141	valid&#39;s binary_logloss: 0.259646
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72043	valid&#39;s binary_logloss: 0.259897
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72043	valid&#39;s binary_logloss: 0.259897
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722383	valid&#39;s binary_logloss: 0.259743
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722383	valid&#39;s binary_logloss: 0.259743
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722977	valid&#39;s binary_logloss: 0.25964
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722977	valid&#39;s binary_logloss: 0.25964
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723588	valid&#39;s binary_logloss: 0.259606
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723588	valid&#39;s binary_logloss: 0.259606
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745873	valid&#39;s binary_logloss: 0.249246
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74594	valid&#39;s binary_logloss: 0.249244
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745878	valid&#39;s binary_logloss: 0.249531
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745891	valid&#39;s binary_logloss: 0.249533
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745656	valid&#39;s binary_logloss: 0.24956
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745656	valid&#39;s binary_logloss: 0.24956
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747166	valid&#39;s binary_logloss: 0.249261
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747166	valid&#39;s binary_logloss: 0.249261
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746129	valid&#39;s binary_logloss: 0.249534
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746129	valid&#39;s binary_logloss: 0.249534
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735705	valid&#39;s binary_logloss: 0.25485
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735705	valid&#39;s binary_logloss: 0.25485
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73449	valid&#39;s binary_logloss: 0.255019
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73449	valid&#39;s binary_logloss: 0.255019
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734848	valid&#39;s binary_logloss: 0.254935
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734848	valid&#39;s binary_logloss: 0.254935
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735268	valid&#39;s binary_logloss: 0.254929
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735268	valid&#39;s binary_logloss: 0.254929
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73663	valid&#39;s binary_logloss: 0.2547
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73663	valid&#39;s binary_logloss: 0.2547
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74107	valid&#39;s binary_logloss: 0.251452
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74107	valid&#39;s binary_logloss: 0.251452
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739413	valid&#39;s binary_logloss: 0.251864
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739413	valid&#39;s binary_logloss: 0.251864
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740679	valid&#39;s binary_logloss: 0.251618
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740679	valid&#39;s binary_logloss: 0.251618
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74064	valid&#39;s binary_logloss: 0.251474
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74064	valid&#39;s binary_logloss: 0.251474
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741341	valid&#39;s binary_logloss: 0.25142
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741341	valid&#39;s binary_logloss: 0.25142
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744538	valid&#39;s binary_logloss: 0.250311
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744538	valid&#39;s binary_logloss: 0.250311
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744924	valid&#39;s binary_logloss: 0.250314
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744964	valid&#39;s binary_logloss: 0.250333
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74518	valid&#39;s binary_logloss: 0.250238
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74518	valid&#39;s binary_logloss: 0.250238
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74469	valid&#39;s binary_logloss: 0.25015
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74469	valid&#39;s binary_logloss: 0.25015
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745682	valid&#39;s binary_logloss: 0.250155
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745682	valid&#39;s binary_logloss: 0.250155
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745142	valid&#39;s binary_logloss: 0.24977
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745142	valid&#39;s binary_logloss: 0.24977
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74384	valid&#39;s binary_logloss: 0.250172
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74384	valid&#39;s binary_logloss: 0.250172
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745448	valid&#39;s binary_logloss: 0.249776
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745448	valid&#39;s binary_logloss: 0.249776
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745151	valid&#39;s binary_logloss: 0.249888
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745151	valid&#39;s binary_logloss: 0.249888
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745556	valid&#39;s binary_logloss: 0.249811
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745556	valid&#39;s binary_logloss: 0.249811
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746667	valid&#39;s binary_logloss: 0.249016
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746667	valid&#39;s binary_logloss: 0.249016
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746786	valid&#39;s binary_logloss: 0.249204
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.746902	valid&#39;s binary_logloss: 0.249167
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746849	valid&#39;s binary_logloss: 0.24905
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746849	valid&#39;s binary_logloss: 0.24905
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747608	valid&#39;s binary_logloss: 0.248697
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747608	valid&#39;s binary_logloss: 0.248697
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744362	valid&#39;s binary_logloss: 0.24979
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.744397	valid&#39;s binary_logloss: 0.249813
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744538	valid&#39;s binary_logloss: 0.250145
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744538	valid&#39;s binary_logloss: 0.250145
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744463	valid&#39;s binary_logloss: 0.250107
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744463	valid&#39;s binary_logloss: 0.250107
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744648	valid&#39;s binary_logloss: 0.250092
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744648	valid&#39;s binary_logloss: 0.250092
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743754	valid&#39;s binary_logloss: 0.250194
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743754	valid&#39;s binary_logloss: 0.250194
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745469	valid&#39;s binary_logloss: 0.249885
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745469	valid&#39;s binary_logloss: 0.249885
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744032	valid&#39;s binary_logloss: 0.250428
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744032	valid&#39;s binary_logloss: 0.250428
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742203	valid&#39;s binary_logloss: 0.250757
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742203	valid&#39;s binary_logloss: 0.250757
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745081	valid&#39;s binary_logloss: 0.250186
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745081	valid&#39;s binary_logloss: 0.250186
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744221	valid&#39;s binary_logloss: 0.250429
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744221	valid&#39;s binary_logloss: 0.250429
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744425	valid&#39;s binary_logloss: 0.250326
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744425	valid&#39;s binary_logloss: 0.250326
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735636	valid&#39;s binary_logloss: 0.254108
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735636	valid&#39;s binary_logloss: 0.254108
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734223	valid&#39;s binary_logloss: 0.254303
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734223	valid&#39;s binary_logloss: 0.254303
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735882	valid&#39;s binary_logloss: 0.254034
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735882	valid&#39;s binary_logloss: 0.254034
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735974	valid&#39;s binary_logloss: 0.254005
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735974	valid&#39;s binary_logloss: 0.254005
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737295	valid&#39;s binary_logloss: 0.253809
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737295	valid&#39;s binary_logloss: 0.253809
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719526	valid&#39;s binary_logloss: 0.261279
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719526	valid&#39;s binary_logloss: 0.261279
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.716645	valid&#39;s binary_logloss: 0.261556
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.716645	valid&#39;s binary_logloss: 0.261556
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717619	valid&#39;s binary_logloss: 0.261505
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717619	valid&#39;s binary_logloss: 0.261505
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718556	valid&#39;s binary_logloss: 0.261384
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718556	valid&#39;s binary_logloss: 0.261384
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718953	valid&#39;s binary_logloss: 0.261433
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718953	valid&#39;s binary_logloss: 0.261433
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745363	valid&#39;s binary_logloss: 0.249483
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745363	valid&#39;s binary_logloss: 0.249483
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74485	valid&#39;s binary_logloss: 0.24978
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744907	valid&#39;s binary_logloss: 0.249774
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745815	valid&#39;s binary_logloss: 0.249406
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745815	valid&#39;s binary_logloss: 0.249406
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746112	valid&#39;s binary_logloss: 0.249444
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746112	valid&#39;s binary_logloss: 0.249444
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745355	valid&#39;s binary_logloss: 0.249639
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745355	valid&#39;s binary_logloss: 0.249639
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741133	valid&#39;s binary_logloss: 0.251467
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741133	valid&#39;s binary_logloss: 0.251467
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740824	valid&#39;s binary_logloss: 0.251655
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740824	valid&#39;s binary_logloss: 0.251655
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741941	valid&#39;s binary_logloss: 0.251447
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741941	valid&#39;s binary_logloss: 0.251447
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741464	valid&#39;s binary_logloss: 0.251417
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741464	valid&#39;s binary_logloss: 0.251417
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74261	valid&#39;s binary_logloss: 0.251268
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74261	valid&#39;s binary_logloss: 0.251268
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742802	valid&#39;s binary_logloss: 0.250645
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742802	valid&#39;s binary_logloss: 0.250645
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742526	valid&#39;s binary_logloss: 0.250699
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742526	valid&#39;s binary_logloss: 0.250699
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743918	valid&#39;s binary_logloss: 0.250488
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743918	valid&#39;s binary_logloss: 0.250488
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74199	valid&#39;s binary_logloss: 0.250913
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74199	valid&#39;s binary_logloss: 0.250913
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742045	valid&#39;s binary_logloss: 0.250831
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742045	valid&#39;s binary_logloss: 0.250831
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744257	valid&#39;s binary_logloss: 0.249757
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.744312	valid&#39;s binary_logloss: 0.249783
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742401	valid&#39;s binary_logloss: 0.250445
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742401	valid&#39;s binary_logloss: 0.250445
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745427	valid&#39;s binary_logloss: 0.249745
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745427	valid&#39;s binary_logloss: 0.249745
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745868	valid&#39;s binary_logloss: 0.249543
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745868	valid&#39;s binary_logloss: 0.249543
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745273	valid&#39;s binary_logloss: 0.249767
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745273	valid&#39;s binary_logloss: 0.249767
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743985	valid&#39;s binary_logloss: 0.249977
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743985	valid&#39;s binary_logloss: 0.249977
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743694	valid&#39;s binary_logloss: 0.250089
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743694	valid&#39;s binary_logloss: 0.250089
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745564	valid&#39;s binary_logloss: 0.24983
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745564	valid&#39;s binary_logloss: 0.24983
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745558	valid&#39;s binary_logloss: 0.24972
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745558	valid&#39;s binary_logloss: 0.24972
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745053	valid&#39;s binary_logloss: 0.249909
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745053	valid&#39;s binary_logloss: 0.249909
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741872	valid&#39;s binary_logloss: 0.251175
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741872	valid&#39;s binary_logloss: 0.251175
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741886	valid&#39;s binary_logloss: 0.251211
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741886	valid&#39;s binary_logloss: 0.251211
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742728	valid&#39;s binary_logloss: 0.251112
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742728	valid&#39;s binary_logloss: 0.251112
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742843	valid&#39;s binary_logloss: 0.251025
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742843	valid&#39;s binary_logloss: 0.251025
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742991	valid&#39;s binary_logloss: 0.250944
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742991	valid&#39;s binary_logloss: 0.250944
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733595	valid&#39;s binary_logloss: 0.254432
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733595	valid&#39;s binary_logloss: 0.254432
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733621	valid&#39;s binary_logloss: 0.254499
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733621	valid&#39;s binary_logloss: 0.254499
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734364	valid&#39;s binary_logloss: 0.254376
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734364	valid&#39;s binary_logloss: 0.254376
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735061	valid&#39;s binary_logloss: 0.254146
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735061	valid&#39;s binary_logloss: 0.254146
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734978	valid&#39;s binary_logloss: 0.254249
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734978	valid&#39;s binary_logloss: 0.254249
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735576	valid&#39;s binary_logloss: 0.253904
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735576	valid&#39;s binary_logloss: 0.253904
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734943	valid&#39;s binary_logloss: 0.254037
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734943	valid&#39;s binary_logloss: 0.254037
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735608	valid&#39;s binary_logloss: 0.254098
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735608	valid&#39;s binary_logloss: 0.254098
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736482	valid&#39;s binary_logloss: 0.253818
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736482	valid&#39;s binary_logloss: 0.253818
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736553	valid&#39;s binary_logloss: 0.253871
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736553	valid&#39;s binary_logloss: 0.253871
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741887	valid&#39;s binary_logloss: 0.251182
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741887	valid&#39;s binary_logloss: 0.251182
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741393	valid&#39;s binary_logloss: 0.251346
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741393	valid&#39;s binary_logloss: 0.251346
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74265	valid&#39;s binary_logloss: 0.251212
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74265	valid&#39;s binary_logloss: 0.251212
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742282	valid&#39;s binary_logloss: 0.251211
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742282	valid&#39;s binary_logloss: 0.251211
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741472	valid&#39;s binary_logloss: 0.251337
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741472	valid&#39;s binary_logloss: 0.251337
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743236	valid&#39;s binary_logloss: 0.250583
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743236	valid&#39;s binary_logloss: 0.250583
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742581	valid&#39;s binary_logloss: 0.25083
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742581	valid&#39;s binary_logloss: 0.25083
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74334	valid&#39;s binary_logloss: 0.250537
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74334	valid&#39;s binary_logloss: 0.250537
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742885	valid&#39;s binary_logloss: 0.250662
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742885	valid&#39;s binary_logloss: 0.250662
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744138	valid&#39;s binary_logloss: 0.250545
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744138	valid&#39;s binary_logloss: 0.250545
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733275	valid&#39;s binary_logloss: 0.256635
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733275	valid&#39;s binary_logloss: 0.256635
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732859	valid&#39;s binary_logloss: 0.256706
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732859	valid&#39;s binary_logloss: 0.256706
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733861	valid&#39;s binary_logloss: 0.256467
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733861	valid&#39;s binary_logloss: 0.256467
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733592	valid&#39;s binary_logloss: 0.256631
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733592	valid&#39;s binary_logloss: 0.256631
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735525	valid&#39;s binary_logloss: 0.256348
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735525	valid&#39;s binary_logloss: 0.256348
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73476	valid&#39;s binary_logloss: 0.254534
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73476	valid&#39;s binary_logloss: 0.254534
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733536	valid&#39;s binary_logloss: 0.254719
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733536	valid&#39;s binary_logloss: 0.254719
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732917	valid&#39;s binary_logloss: 0.254819
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732917	valid&#39;s binary_logloss: 0.254819
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735093	valid&#39;s binary_logloss: 0.254401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735093	valid&#39;s binary_logloss: 0.254401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735252	valid&#39;s binary_logloss: 0.254475
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735252	valid&#39;s binary_logloss: 0.254475
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747508	valid&#39;s binary_logloss: 0.248732
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.747589	valid&#39;s binary_logloss: 0.248718
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746388	valid&#39;s binary_logloss: 0.249307
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74653	valid&#39;s binary_logloss: 0.249273
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[76]	valid&#39;s auc: 0.74538	valid&#39;s binary_logloss: 0.249412
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745948	valid&#39;s binary_logloss: 0.249452
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745948	valid&#39;s binary_logloss: 0.249452
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[83]	valid&#39;s auc: 0.746593	valid&#39;s binary_logloss: 0.249205
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745684	valid&#39;s binary_logloss: 0.249417
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745684	valid&#39;s binary_logloss: 0.249417
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745948	valid&#39;s binary_logloss: 0.249421
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745948	valid&#39;s binary_logloss: 0.249421
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747871	valid&#39;s binary_logloss: 0.248993
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.747915	valid&#39;s binary_logloss: 0.249011
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746656	valid&#39;s binary_logloss: 0.249326
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746656	valid&#39;s binary_logloss: 0.249326
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745402	valid&#39;s binary_logloss: 0.249615
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745402	valid&#39;s binary_logloss: 0.249615
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74231	valid&#39;s binary_logloss: 0.250887
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74231	valid&#39;s binary_logloss: 0.250887
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741575	valid&#39;s binary_logloss: 0.251128
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741575	valid&#39;s binary_logloss: 0.251128
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742431	valid&#39;s binary_logloss: 0.250973
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742431	valid&#39;s binary_logloss: 0.250973
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742534	valid&#39;s binary_logloss: 0.250934
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742534	valid&#39;s binary_logloss: 0.250934
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741918	valid&#39;s binary_logloss: 0.251065
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741918	valid&#39;s binary_logloss: 0.251065
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721498	valid&#39;s binary_logloss: 0.259651
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721498	valid&#39;s binary_logloss: 0.259651
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720259	valid&#39;s binary_logloss: 0.259841
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720259	valid&#39;s binary_logloss: 0.259841
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719953	valid&#39;s binary_logloss: 0.259782
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719953	valid&#39;s binary_logloss: 0.259782
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720987	valid&#39;s binary_logloss: 0.259687
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720987	valid&#39;s binary_logloss: 0.259687
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722023	valid&#39;s binary_logloss: 0.25961
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722023	valid&#39;s binary_logloss: 0.25961
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744956	valid&#39;s binary_logloss: 0.249508
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.744966	valid&#39;s binary_logloss: 0.249523
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744857	valid&#39;s binary_logloss: 0.249775
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.744893	valid&#39;s binary_logloss: 0.249774
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747429	valid&#39;s binary_logloss: 0.249254
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747429	valid&#39;s binary_logloss: 0.249254
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745001	valid&#39;s binary_logloss: 0.249459
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745001	valid&#39;s binary_logloss: 0.249459
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.7462	valid&#39;s binary_logloss: 0.249387
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.746341	valid&#39;s binary_logloss: 0.249397
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73374	valid&#39;s binary_logloss: 0.254382
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73374	valid&#39;s binary_logloss: 0.254382
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733373	valid&#39;s binary_logloss: 0.254433
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733373	valid&#39;s binary_logloss: 0.254433
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734471	valid&#39;s binary_logloss: 0.254295
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734471	valid&#39;s binary_logloss: 0.254295
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734736	valid&#39;s binary_logloss: 0.254139
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734736	valid&#39;s binary_logloss: 0.254139
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734918	valid&#39;s binary_logloss: 0.254168
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734918	valid&#39;s binary_logloss: 0.254168
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748012	valid&#39;s binary_logloss: 0.24853
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748012	valid&#39;s binary_logloss: 0.24853
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747029	valid&#39;s binary_logloss: 0.249193
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.747093	valid&#39;s binary_logloss: 0.249157
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74731	valid&#39;s binary_logloss: 0.248858
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747351	valid&#39;s binary_logloss: 0.24886
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747735	valid&#39;s binary_logloss: 0.249002
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.747907	valid&#39;s binary_logloss: 0.248974
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746438	valid&#39;s binary_logloss: 0.249346
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746438	valid&#39;s binary_logloss: 0.249346
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746518	valid&#39;s binary_logloss: 0.249316
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746518	valid&#39;s binary_logloss: 0.249316
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746359	valid&#39;s binary_logloss: 0.249322
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746359	valid&#39;s binary_logloss: 0.249322
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747254	valid&#39;s binary_logloss: 0.249265
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747254	valid&#39;s binary_logloss: 0.249265
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746838	valid&#39;s binary_logloss: 0.249282
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746838	valid&#39;s binary_logloss: 0.249282
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745258	valid&#39;s binary_logloss: 0.249546
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.745286	valid&#39;s binary_logloss: 0.249569
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744317	valid&#39;s binary_logloss: 0.249991
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744317	valid&#39;s binary_logloss: 0.249991
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743319	valid&#39;s binary_logloss: 0.250225
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743319	valid&#39;s binary_logloss: 0.250225
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743462	valid&#39;s binary_logloss: 0.250361
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.743469	valid&#39;s binary_logloss: 0.250372
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744197	valid&#39;s binary_logloss: 0.250206
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744197	valid&#39;s binary_logloss: 0.250206
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746271	valid&#39;s binary_logloss: 0.249719
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746271	valid&#39;s binary_logloss: 0.249719
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743248	valid&#39;s binary_logloss: 0.250355
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743248	valid&#39;s binary_logloss: 0.250355
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743898	valid&#39;s binary_logloss: 0.250268
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743898	valid&#39;s binary_logloss: 0.250268
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744236	valid&#39;s binary_logloss: 0.250368
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744236	valid&#39;s binary_logloss: 0.250368
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744	valid&#39;s binary_logloss: 0.250174
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744	valid&#39;s binary_logloss: 0.250174
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743516	valid&#39;s binary_logloss: 0.250233
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743516	valid&#39;s binary_logloss: 0.250233
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 80.4min finished
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747298	valid&#39;s binary_logloss: 0.249016
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747298	valid&#39;s binary_logloss: 0.249016
finishing pca n=100
Elapsed time: 4834.717962503433 seconds
starting pca n=150
Fitting 5 folds for each of 100 candidates, totalling 500 fits
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748679	valid&#39;s binary_logloss: 0.248457
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748679	valid&#39;s binary_logloss: 0.248457
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747539	valid&#39;s binary_logloss: 0.248907
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747539	valid&#39;s binary_logloss: 0.248907
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749257	valid&#39;s binary_logloss: 0.24852
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749257	valid&#39;s binary_logloss: 0.24852
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749704	valid&#39;s binary_logloss: 0.248404
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749704	valid&#39;s binary_logloss: 0.248404
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748513	valid&#39;s binary_logloss: 0.24877
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74855	valid&#39;s binary_logloss: 0.248773
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747602	valid&#39;s binary_logloss: 0.249107
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747634	valid&#39;s binary_logloss: 0.249102
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74815	valid&#39;s binary_logloss: 0.248889
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74815	valid&#39;s binary_logloss: 0.248889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748836	valid&#39;s binary_logloss: 0.248596
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748836	valid&#39;s binary_logloss: 0.248596
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747103	valid&#39;s binary_logloss: 0.24905
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747143	valid&#39;s binary_logloss: 0.249054
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746776	valid&#39;s binary_logloss: 0.249516
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746776	valid&#39;s binary_logloss: 0.249516
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748219	valid&#39;s binary_logloss: 0.248838
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.748234	valid&#39;s binary_logloss: 0.248866
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746299	valid&#39;s binary_logloss: 0.249386
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.746309	valid&#39;s binary_logloss: 0.249408
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749649	valid&#39;s binary_logloss: 0.248632
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749649	valid&#39;s binary_logloss: 0.248632
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748994	valid&#39;s binary_logloss: 0.24879
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748994	valid&#39;s binary_logloss: 0.24879
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749859	valid&#39;s binary_logloss: 0.248604
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749859	valid&#39;s binary_logloss: 0.248604
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74607	valid&#39;s binary_logloss: 0.249938
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74607	valid&#39;s binary_logloss: 0.249938
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744378	valid&#39;s binary_logloss: 0.25031
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744378	valid&#39;s binary_logloss: 0.25031
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746368	valid&#39;s binary_logloss: 0.249983
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746368	valid&#39;s binary_logloss: 0.249983
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746886	valid&#39;s binary_logloss: 0.249768
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746886	valid&#39;s binary_logloss: 0.249768
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746948	valid&#39;s binary_logloss: 0.249929
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746948	valid&#39;s binary_logloss: 0.249929
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746528	valid&#39;s binary_logloss: 0.249461
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746528	valid&#39;s binary_logloss: 0.249461
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746556	valid&#39;s binary_logloss: 0.249526
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746556	valid&#39;s binary_logloss: 0.249526
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747281	valid&#39;s binary_logloss: 0.249386
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747281	valid&#39;s binary_logloss: 0.249386
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74778	valid&#39;s binary_logloss: 0.249236
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74778	valid&#39;s binary_logloss: 0.249236
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746553	valid&#39;s binary_logloss: 0.249439
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746553	valid&#39;s binary_logloss: 0.249439
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731908	valid&#39;s binary_logloss: 0.255718
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731908	valid&#39;s binary_logloss: 0.255718
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73111	valid&#39;s binary_logloss: 0.255871
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73111	valid&#39;s binary_logloss: 0.255871
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731295	valid&#39;s binary_logloss: 0.255822
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731295	valid&#39;s binary_logloss: 0.255822
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733194	valid&#39;s binary_logloss: 0.255546
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733194	valid&#39;s binary_logloss: 0.255546
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733219	valid&#39;s binary_logloss: 0.255501
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733219	valid&#39;s binary_logloss: 0.255501
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715618	valid&#39;s binary_logloss: 0.262658
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715618	valid&#39;s binary_logloss: 0.262658
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.713134	valid&#39;s binary_logloss: 0.262892
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.713134	valid&#39;s binary_logloss: 0.262892
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.714468	valid&#39;s binary_logloss: 0.262846
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.714468	valid&#39;s binary_logloss: 0.262846
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715363	valid&#39;s binary_logloss: 0.26272
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715363	valid&#39;s binary_logloss: 0.26272
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.715918	valid&#39;s binary_logloss: 0.26259
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.715918	valid&#39;s binary_logloss: 0.26259
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744536	valid&#39;s binary_logloss: 0.250157
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744536	valid&#39;s binary_logloss: 0.250157
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744328	valid&#39;s binary_logloss: 0.250222
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744328	valid&#39;s binary_logloss: 0.250222
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746	valid&#39;s binary_logloss: 0.249897
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746	valid&#39;s binary_logloss: 0.249897
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745794	valid&#39;s binary_logloss: 0.249876
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745794	valid&#39;s binary_logloss: 0.249876
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745737	valid&#39;s binary_logloss: 0.24975
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745737	valid&#39;s binary_logloss: 0.24975
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74672	valid&#39;s binary_logloss: 0.249535
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74672	valid&#39;s binary_logloss: 0.249535
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745299	valid&#39;s binary_logloss: 0.249805
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.745307	valid&#39;s binary_logloss: 0.24983
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747848	valid&#39;s binary_logloss: 0.249246
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747848	valid&#39;s binary_logloss: 0.249246
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746798	valid&#39;s binary_logloss: 0.249298
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746798	valid&#39;s binary_logloss: 0.249298
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748035	valid&#39;s binary_logloss: 0.249103
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748035	valid&#39;s binary_logloss: 0.249103
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743985	valid&#39;s binary_logloss: 0.250966
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743985	valid&#39;s binary_logloss: 0.250966
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74304	valid&#39;s binary_logloss: 0.251252
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74304	valid&#39;s binary_logloss: 0.251252
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744085	valid&#39;s binary_logloss: 0.251025
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744085	valid&#39;s binary_logloss: 0.251025
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743724	valid&#39;s binary_logloss: 0.251123
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743724	valid&#39;s binary_logloss: 0.251123
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743358	valid&#39;s binary_logloss: 0.251318
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743358	valid&#39;s binary_logloss: 0.251318
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748592	valid&#39;s binary_logloss: 0.248821
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748592	valid&#39;s binary_logloss: 0.248821
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747236	valid&#39;s binary_logloss: 0.249199
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747236	valid&#39;s binary_logloss: 0.249199
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749338	valid&#39;s binary_logloss: 0.248771
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749338	valid&#39;s binary_logloss: 0.248771
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748826	valid&#39;s binary_logloss: 0.24876
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748826	valid&#39;s binary_logloss: 0.24876
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747451	valid&#39;s binary_logloss: 0.249194
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747451	valid&#39;s binary_logloss: 0.249194
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748313	valid&#39;s binary_logloss: 0.2487
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748313	valid&#39;s binary_logloss: 0.2487
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746703	valid&#39;s binary_logloss: 0.248963
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.746712	valid&#39;s binary_logloss: 0.248975
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749569	valid&#39;s binary_logloss: 0.248387
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749569	valid&#39;s binary_logloss: 0.248387
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74778	valid&#39;s binary_logloss: 0.248877
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74778	valid&#39;s binary_logloss: 0.248877
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74832	valid&#39;s binary_logloss: 0.248891
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74832	valid&#39;s binary_logloss: 0.248891
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748064	valid&#39;s binary_logloss: 0.248657
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748064	valid&#39;s binary_logloss: 0.248657
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747664	valid&#39;s binary_logloss: 0.248719
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747664	valid&#39;s binary_logloss: 0.248719
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749119	valid&#39;s binary_logloss: 0.248453
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749119	valid&#39;s binary_logloss: 0.248453
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749594	valid&#39;s binary_logloss: 0.248475
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749594	valid&#39;s binary_logloss: 0.248475
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.750391	valid&#39;s binary_logloss: 0.248337
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.750391	valid&#39;s binary_logloss: 0.248337
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749157	valid&#39;s binary_logloss: 0.248615
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749157	valid&#39;s binary_logloss: 0.248615
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74778	valid&#39;s binary_logloss: 0.24884
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74778	valid&#39;s binary_logloss: 0.24884
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748382	valid&#39;s binary_logloss: 0.248777
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748382	valid&#39;s binary_logloss: 0.248777
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747883	valid&#39;s binary_logloss: 0.249025
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747883	valid&#39;s binary_logloss: 0.249025
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749012	valid&#39;s binary_logloss: 0.248909
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749012	valid&#39;s binary_logloss: 0.248909
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722629	valid&#39;s binary_logloss: 0.260059
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722629	valid&#39;s binary_logloss: 0.260059
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720913	valid&#39;s binary_logloss: 0.260279
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720913	valid&#39;s binary_logloss: 0.260279
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[13]	valid&#39;s auc: 0.703658	valid&#39;s binary_logloss: 0.27517
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722334	valid&#39;s binary_logloss: 0.260118
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722334	valid&#39;s binary_logloss: 0.260118
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722937	valid&#39;s binary_logloss: 0.260085
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722937	valid&#39;s binary_logloss: 0.260085
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737166	valid&#39;s binary_logloss: 0.253485
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737166	valid&#39;s binary_logloss: 0.253485
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736317	valid&#39;s binary_logloss: 0.25368
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736317	valid&#39;s binary_logloss: 0.25368
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73708	valid&#39;s binary_logloss: 0.253647
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73708	valid&#39;s binary_logloss: 0.253647
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737739	valid&#39;s binary_logloss: 0.253363
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737739	valid&#39;s binary_logloss: 0.253363
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73782	valid&#39;s binary_logloss: 0.253481
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73782	valid&#39;s binary_logloss: 0.253481
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746306	valid&#39;s binary_logloss: 0.249635
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746306	valid&#39;s binary_logloss: 0.249635
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746144	valid&#39;s binary_logloss: 0.249657
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746144	valid&#39;s binary_logloss: 0.249657
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747125	valid&#39;s binary_logloss: 0.249413
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747125	valid&#39;s binary_logloss: 0.249413
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74748	valid&#39;s binary_logloss: 0.249471
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74748	valid&#39;s binary_logloss: 0.249471
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746979	valid&#39;s binary_logloss: 0.249565
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746979	valid&#39;s binary_logloss: 0.249565
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[79]	valid&#39;s auc: 0.747716	valid&#39;s binary_logloss: 0.248844
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[64]	valid&#39;s auc: 0.744557	valid&#39;s binary_logloss: 0.249602
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[82]	valid&#39;s auc: 0.746636	valid&#39;s binary_logloss: 0.248865
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[80]	valid&#39;s auc: 0.746797	valid&#39;s binary_logloss: 0.248856
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[82]	valid&#39;s auc: 0.746549	valid&#39;s binary_logloss: 0.249273
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745461	valid&#39;s binary_logloss: 0.249959
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745461	valid&#39;s binary_logloss: 0.249959
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744404	valid&#39;s binary_logloss: 0.250064
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744404	valid&#39;s binary_logloss: 0.250064
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746249	valid&#39;s binary_logloss: 0.249845
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746249	valid&#39;s binary_logloss: 0.249845
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74636	valid&#39;s binary_logloss: 0.249828
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74636	valid&#39;s binary_logloss: 0.249828
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746624	valid&#39;s binary_logloss: 0.249824
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746624	valid&#39;s binary_logloss: 0.249824
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743577	valid&#39;s binary_logloss: 0.250766
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743577	valid&#39;s binary_logloss: 0.250766
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743582	valid&#39;s binary_logloss: 0.250803
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743582	valid&#39;s binary_logloss: 0.250803
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743759	valid&#39;s binary_logloss: 0.250811
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743759	valid&#39;s binary_logloss: 0.250811
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743885	valid&#39;s binary_logloss: 0.250656
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743885	valid&#39;s binary_logloss: 0.250656
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744536	valid&#39;s binary_logloss: 0.250599
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744536	valid&#39;s binary_logloss: 0.250599
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748939	valid&#39;s binary_logloss: 0.2486
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748939	valid&#39;s binary_logloss: 0.2486
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747106	valid&#39;s binary_logloss: 0.249181
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747106	valid&#39;s binary_logloss: 0.249181
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749955	valid&#39;s binary_logloss: 0.248735
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749955	valid&#39;s binary_logloss: 0.248735
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748826	valid&#39;s binary_logloss: 0.248775
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748826	valid&#39;s binary_logloss: 0.248775
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.7487	valid&#39;s binary_logloss: 0.249043
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.7487	valid&#39;s binary_logloss: 0.249043
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720616	valid&#39;s binary_logloss: 0.261914
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720616	valid&#39;s binary_logloss: 0.261914
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[4]	valid&#39;s auc: 0.702168	valid&#39;s binary_logloss: 0.278775
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719911	valid&#39;s binary_logloss: 0.262011
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719911	valid&#39;s binary_logloss: 0.262011
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721314	valid&#39;s binary_logloss: 0.261925
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721314	valid&#39;s binary_logloss: 0.261925
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720655	valid&#39;s binary_logloss: 0.261882
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720655	valid&#39;s binary_logloss: 0.261882
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734248	valid&#39;s binary_logloss: 0.254991
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734248	valid&#39;s binary_logloss: 0.254991
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732876	valid&#39;s binary_logloss: 0.255274
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732876	valid&#39;s binary_logloss: 0.255274
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733954	valid&#39;s binary_logloss: 0.255143
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733954	valid&#39;s binary_logloss: 0.255143
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734163	valid&#39;s binary_logloss: 0.255004
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734163	valid&#39;s binary_logloss: 0.255004
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734946	valid&#39;s binary_logloss: 0.254953
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734946	valid&#39;s binary_logloss: 0.254953
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749331	valid&#39;s binary_logloss: 0.248446
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749331	valid&#39;s binary_logloss: 0.248446
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748379	valid&#39;s binary_logloss: 0.24891
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748379	valid&#39;s binary_logloss: 0.24891
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749441	valid&#39;s binary_logloss: 0.248695
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749441	valid&#39;s binary_logloss: 0.248695
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749922	valid&#39;s binary_logloss: 0.248461
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749922	valid&#39;s binary_logloss: 0.248461
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748767	valid&#39;s binary_logloss: 0.248924
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748767	valid&#39;s binary_logloss: 0.248924
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731203	valid&#39;s binary_logloss: 0.256004
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731203	valid&#39;s binary_logloss: 0.256004
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.731148	valid&#39;s binary_logloss: 0.256009
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.731148	valid&#39;s binary_logloss: 0.256009
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.730789	valid&#39;s binary_logloss: 0.256085
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.730789	valid&#39;s binary_logloss: 0.256085
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732194	valid&#39;s binary_logloss: 0.25586
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732194	valid&#39;s binary_logloss: 0.25586
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.732186	valid&#39;s binary_logloss: 0.255775
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.732186	valid&#39;s binary_logloss: 0.255775
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747564	valid&#39;s binary_logloss: 0.248678
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747564	valid&#39;s binary_logloss: 0.248678
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746759	valid&#39;s binary_logloss: 0.248983
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746759	valid&#39;s binary_logloss: 0.248983
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748122	valid&#39;s binary_logloss: 0.248588
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748122	valid&#39;s binary_logloss: 0.248588
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747207	valid&#39;s binary_logloss: 0.248956
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747207	valid&#39;s binary_logloss: 0.248956
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746848	valid&#39;s binary_logloss: 0.249116
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746848	valid&#39;s binary_logloss: 0.249116
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73606	valid&#39;s binary_logloss: 0.254231
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73606	valid&#39;s binary_logloss: 0.254231
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73395	valid&#39;s binary_logloss: 0.254551
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73395	valid&#39;s binary_logloss: 0.254551
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735681	valid&#39;s binary_logloss: 0.254457
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735681	valid&#39;s binary_logloss: 0.254457
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735985	valid&#39;s binary_logloss: 0.254131
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735985	valid&#39;s binary_logloss: 0.254131
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736914	valid&#39;s binary_logloss: 0.254095
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736914	valid&#39;s binary_logloss: 0.254095
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743613	valid&#39;s binary_logloss: 0.251018
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743613	valid&#39;s binary_logloss: 0.251018
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742463	valid&#39;s binary_logloss: 0.251239
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742463	valid&#39;s binary_logloss: 0.251239
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.7433	valid&#39;s binary_logloss: 0.251045
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.7433	valid&#39;s binary_logloss: 0.251045
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743552	valid&#39;s binary_logloss: 0.251088
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743552	valid&#39;s binary_logloss: 0.251088
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743943	valid&#39;s binary_logloss: 0.251016
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743943	valid&#39;s binary_logloss: 0.251016
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748576	valid&#39;s binary_logloss: 0.24865
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.748694	valid&#39;s binary_logloss: 0.248617
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748684	valid&#39;s binary_logloss: 0.24846
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.748743	valid&#39;s binary_logloss: 0.248471
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749305	valid&#39;s binary_logloss: 0.248406
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.74934	valid&#39;s binary_logloss: 0.248441
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74931	valid&#39;s binary_logloss: 0.248416
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74931	valid&#39;s binary_logloss: 0.248416
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749193	valid&#39;s binary_logloss: 0.248598
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.74924	valid&#39;s binary_logloss: 0.248586
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739919	valid&#39;s binary_logloss: 0.252437
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739919	valid&#39;s binary_logloss: 0.252437
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739396	valid&#39;s binary_logloss: 0.252525
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739396	valid&#39;s binary_logloss: 0.252525
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740273	valid&#39;s binary_logloss: 0.252437
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740273	valid&#39;s binary_logloss: 0.252437
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740364	valid&#39;s binary_logloss: 0.252486
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740364	valid&#39;s binary_logloss: 0.252486
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74145	valid&#39;s binary_logloss: 0.252201
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74145	valid&#39;s binary_logloss: 0.252201
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.750013	valid&#39;s binary_logloss: 0.248329
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.750013	valid&#39;s binary_logloss: 0.248329
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747442	valid&#39;s binary_logloss: 0.248994
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747442	valid&#39;s binary_logloss: 0.248994
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748943	valid&#39;s binary_logloss: 0.248742
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748943	valid&#39;s binary_logloss: 0.248742
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749004	valid&#39;s binary_logloss: 0.248541
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.749008	valid&#39;s binary_logloss: 0.248555
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748951	valid&#39;s binary_logloss: 0.24864
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748951	valid&#39;s binary_logloss: 0.24864
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74337	valid&#39;s binary_logloss: 0.251318
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74337	valid&#39;s binary_logloss: 0.251318
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743387	valid&#39;s binary_logloss: 0.251356
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743387	valid&#39;s binary_logloss: 0.251356
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744822	valid&#39;s binary_logloss: 0.251179
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744822	valid&#39;s binary_logloss: 0.251179
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743757	valid&#39;s binary_logloss: 0.251268
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743757	valid&#39;s binary_logloss: 0.251268
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744552	valid&#39;s binary_logloss: 0.251151
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744552	valid&#39;s binary_logloss: 0.251151
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739674	valid&#39;s binary_logloss: 0.25259
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739674	valid&#39;s binary_logloss: 0.25259
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738519	valid&#39;s binary_logloss: 0.252867
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738519	valid&#39;s binary_logloss: 0.252867
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740367	valid&#39;s binary_logloss: 0.252547
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740367	valid&#39;s binary_logloss: 0.252547
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740232	valid&#39;s binary_logloss: 0.252469
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740232	valid&#39;s binary_logloss: 0.252469
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740634	valid&#39;s binary_logloss: 0.252509
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740634	valid&#39;s binary_logloss: 0.252509
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746508	valid&#39;s binary_logloss: 0.24961
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746508	valid&#39;s binary_logloss: 0.24961
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746125	valid&#39;s binary_logloss: 0.249578
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746125	valid&#39;s binary_logloss: 0.249578
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746711	valid&#39;s binary_logloss: 0.249566
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746711	valid&#39;s binary_logloss: 0.249566
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747475	valid&#39;s binary_logloss: 0.249351
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747475	valid&#39;s binary_logloss: 0.249351
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747282	valid&#39;s binary_logloss: 0.249432
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747282	valid&#39;s binary_logloss: 0.249432
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737199	valid&#39;s binary_logloss: 0.253821
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737199	valid&#39;s binary_logloss: 0.253821
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735812	valid&#39;s binary_logloss: 0.254075
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735812	valid&#39;s binary_logloss: 0.254075
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735744	valid&#39;s binary_logloss: 0.254073
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735744	valid&#39;s binary_logloss: 0.254073
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736558	valid&#39;s binary_logloss: 0.253958
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736558	valid&#39;s binary_logloss: 0.253958
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736628	valid&#39;s binary_logloss: 0.253909
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736628	valid&#39;s binary_logloss: 0.253909
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.714151	valid&#39;s binary_logloss: 0.263355
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.714151	valid&#39;s binary_logloss: 0.263355
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711695	valid&#39;s binary_logloss: 0.263472
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711695	valid&#39;s binary_logloss: 0.263472
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712132	valid&#39;s binary_logloss: 0.263522
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712132	valid&#39;s binary_logloss: 0.263522
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712913	valid&#39;s binary_logloss: 0.263481
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712913	valid&#39;s binary_logloss: 0.263481
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.713282	valid&#39;s binary_logloss: 0.263371
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.713282	valid&#39;s binary_logloss: 0.263371
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725415	valid&#39;s binary_logloss: 0.258453
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725415	valid&#39;s binary_logloss: 0.258453
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724478	valid&#39;s binary_logloss: 0.258593
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724478	valid&#39;s binary_logloss: 0.258593
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724385	valid&#39;s binary_logloss: 0.258678
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724385	valid&#39;s binary_logloss: 0.258678
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725436	valid&#39;s binary_logloss: 0.258613
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725436	valid&#39;s binary_logloss: 0.258613
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[10]	valid&#39;s auc: 0.700463	valid&#39;s binary_logloss: 0.275079
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74965	valid&#39;s binary_logloss: 0.248276
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.749776	valid&#39;s binary_logloss: 0.248293
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748412	valid&#39;s binary_logloss: 0.248701
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748412	valid&#39;s binary_logloss: 0.248701
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.750382	valid&#39;s binary_logloss: 0.247954
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.750382	valid&#39;s binary_logloss: 0.247954
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748443	valid&#39;s binary_logloss: 0.248527
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748443	valid&#39;s binary_logloss: 0.248527
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.750493	valid&#39;s binary_logloss: 0.248182
Did not meet early stopping. Best iteration is:
[95]	valid&#39;s auc: 0.750624	valid&#39;s binary_logloss: 0.248202
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739484	valid&#39;s binary_logloss: 0.252852
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739484	valid&#39;s binary_logloss: 0.252852
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738013	valid&#39;s binary_logloss: 0.253112
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738013	valid&#39;s binary_logloss: 0.253112
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739448	valid&#39;s binary_logloss: 0.252918
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739448	valid&#39;s binary_logloss: 0.252918
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739224	valid&#39;s binary_logloss: 0.252856
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739224	valid&#39;s binary_logloss: 0.252856
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740529	valid&#39;s binary_logloss: 0.252611
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740529	valid&#39;s binary_logloss: 0.252611
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748144	valid&#39;s binary_logloss: 0.248652
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.748201	valid&#39;s binary_logloss: 0.248635
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748429	valid&#39;s binary_logloss: 0.248581
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748429	valid&#39;s binary_logloss: 0.248581
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749739	valid&#39;s binary_logloss: 0.248347
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749739	valid&#39;s binary_logloss: 0.248347
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749811	valid&#39;s binary_logloss: 0.24801
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749811	valid&#39;s binary_logloss: 0.24801
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.750636	valid&#39;s binary_logloss: 0.248277
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.750648	valid&#39;s binary_logloss: 0.248273
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734423	valid&#39;s binary_logloss: 0.25482
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734423	valid&#39;s binary_logloss: 0.25482
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733509	valid&#39;s binary_logloss: 0.254916
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733509	valid&#39;s binary_logloss: 0.254916
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734683	valid&#39;s binary_logloss: 0.254805
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734683	valid&#39;s binary_logloss: 0.254805
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735063	valid&#39;s binary_logloss: 0.254741
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735063	valid&#39;s binary_logloss: 0.254741
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735818	valid&#39;s binary_logloss: 0.254615
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735818	valid&#39;s binary_logloss: 0.254615
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738642	valid&#39;s binary_logloss: 0.253322
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738642	valid&#39;s binary_logloss: 0.253322
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737356	valid&#39;s binary_logloss: 0.253338
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737356	valid&#39;s binary_logloss: 0.253338
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737967	valid&#39;s binary_logloss: 0.253492
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737967	valid&#39;s binary_logloss: 0.253492
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738184	valid&#39;s binary_logloss: 0.253281
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738184	valid&#39;s binary_logloss: 0.253281
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739721	valid&#39;s binary_logloss: 0.253103
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739721	valid&#39;s binary_logloss: 0.253103
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749367	valid&#39;s binary_logloss: 0.248362
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749367	valid&#39;s binary_logloss: 0.248362
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748967	valid&#39;s binary_logloss: 0.248354
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.749046	valid&#39;s binary_logloss: 0.248337
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748921	valid&#39;s binary_logloss: 0.248306
Did not meet early stopping. Best iteration is:
[93]	valid&#39;s auc: 0.749429	valid&#39;s binary_logloss: 0.248197
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748569	valid&#39;s binary_logloss: 0.248436
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748569	valid&#39;s binary_logloss: 0.248436
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74971	valid&#39;s binary_logloss: 0.248595
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74971	valid&#39;s binary_logloss: 0.248595
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.727399	valid&#39;s binary_logloss: 0.257432
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.727399	valid&#39;s binary_logloss: 0.257432
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725879	valid&#39;s binary_logloss: 0.257619
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725879	valid&#39;s binary_logloss: 0.257619
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726226	valid&#39;s binary_logloss: 0.257569
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726226	valid&#39;s binary_logloss: 0.257569
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726947	valid&#39;s binary_logloss: 0.257396
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726947	valid&#39;s binary_logloss: 0.257396
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72755	valid&#39;s binary_logloss: 0.25739
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72755	valid&#39;s binary_logloss: 0.25739
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747168	valid&#39;s binary_logloss: 0.249225
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747168	valid&#39;s binary_logloss: 0.249225
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745444	valid&#39;s binary_logloss: 0.249639
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745444	valid&#39;s binary_logloss: 0.249639
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748972	valid&#39;s binary_logloss: 0.248888
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.748975	valid&#39;s binary_logloss: 0.248919
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748373	valid&#39;s binary_logloss: 0.24916
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748373	valid&#39;s binary_logloss: 0.24916
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748776	valid&#39;s binary_logloss: 0.248919
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748776	valid&#39;s binary_logloss: 0.248919
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743497	valid&#39;s binary_logloss: 0.251286
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743497	valid&#39;s binary_logloss: 0.251286
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744	valid&#39;s binary_logloss: 0.251164
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744	valid&#39;s binary_logloss: 0.251164
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743514	valid&#39;s binary_logloss: 0.251315
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743514	valid&#39;s binary_logloss: 0.251315
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743505	valid&#39;s binary_logloss: 0.251282
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743505	valid&#39;s binary_logloss: 0.251282
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743841	valid&#39;s binary_logloss: 0.251241
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743841	valid&#39;s binary_logloss: 0.251241
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742257	valid&#39;s binary_logloss: 0.251551
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742257	valid&#39;s binary_logloss: 0.251551
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741549	valid&#39;s binary_logloss: 0.251792
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741549	valid&#39;s binary_logloss: 0.251792
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741646	valid&#39;s binary_logloss: 0.251753
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741646	valid&#39;s binary_logloss: 0.251753
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743089	valid&#39;s binary_logloss: 0.251478
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743089	valid&#39;s binary_logloss: 0.251478
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743085	valid&#39;s binary_logloss: 0.251421
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743085	valid&#39;s binary_logloss: 0.251421
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746297	valid&#39;s binary_logloss: 0.249819
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746297	valid&#39;s binary_logloss: 0.249819
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744176	valid&#39;s binary_logloss: 0.250407
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744176	valid&#39;s binary_logloss: 0.250407
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745332	valid&#39;s binary_logloss: 0.2501
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.745333	valid&#39;s binary_logloss: 0.250133
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744218	valid&#39;s binary_logloss: 0.250373
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744218	valid&#39;s binary_logloss: 0.250373
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745427	valid&#39;s binary_logloss: 0.250228
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745427	valid&#39;s binary_logloss: 0.250228
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748741	valid&#39;s binary_logloss: 0.248315
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748741	valid&#39;s binary_logloss: 0.248315
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747785	valid&#39;s binary_logloss: 0.248733
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747785	valid&#39;s binary_logloss: 0.248733
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749756	valid&#39;s binary_logloss: 0.248284
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749756	valid&#39;s binary_logloss: 0.248284
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74853	valid&#39;s binary_logloss: 0.248704
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.748703	valid&#39;s binary_logloss: 0.248684
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746534	valid&#39;s binary_logloss: 0.248984
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.746634	valid&#39;s binary_logloss: 0.248978
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.740971	valid&#39;s binary_logloss: 0.251822
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.740971	valid&#39;s binary_logloss: 0.251822
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.739801	valid&#39;s binary_logloss: 0.252052
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.739801	valid&#39;s binary_logloss: 0.252052
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742511	valid&#39;s binary_logloss: 0.251551
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742511	valid&#39;s binary_logloss: 0.251551
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74188	valid&#39;s binary_logloss: 0.251619
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74189	valid&#39;s binary_logloss: 0.251654
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742483	valid&#39;s binary_logloss: 0.251428
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742483	valid&#39;s binary_logloss: 0.251428
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744565	valid&#39;s binary_logloss: 0.250812
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744565	valid&#39;s binary_logloss: 0.250812
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743956	valid&#39;s binary_logloss: 0.251037
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743956	valid&#39;s binary_logloss: 0.251037
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74421	valid&#39;s binary_logloss: 0.250991
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74421	valid&#39;s binary_logloss: 0.250991
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744203	valid&#39;s binary_logloss: 0.250788
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744203	valid&#39;s binary_logloss: 0.250788
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745848	valid&#39;s binary_logloss: 0.250771
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745848	valid&#39;s binary_logloss: 0.250771
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749546	valid&#39;s binary_logloss: 0.248248
Did not meet early stopping. Best iteration is:
[91]	valid&#39;s auc: 0.7496	valid&#39;s binary_logloss: 0.248214
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748598	valid&#39;s binary_logloss: 0.248456
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748598	valid&#39;s binary_logloss: 0.248456
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[81]	valid&#39;s auc: 0.748021	valid&#39;s binary_logloss: 0.248673
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[80]	valid&#39;s auc: 0.747142	valid&#39;s binary_logloss: 0.248929
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748771	valid&#39;s binary_logloss: 0.248543
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748771	valid&#39;s binary_logloss: 0.248543
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746828	valid&#39;s binary_logloss: 0.249302
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746828	valid&#39;s binary_logloss: 0.249302
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743694	valid&#39;s binary_logloss: 0.250114
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743694	valid&#39;s binary_logloss: 0.250114
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746193	valid&#39;s binary_logloss: 0.249638
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746193	valid&#39;s binary_logloss: 0.249638
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746858	valid&#39;s binary_logloss: 0.249378
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746858	valid&#39;s binary_logloss: 0.249378
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745697	valid&#39;s binary_logloss: 0.24959
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745697	valid&#39;s binary_logloss: 0.24959
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718868	valid&#39;s binary_logloss: 0.260676
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718868	valid&#39;s binary_logloss: 0.260676
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717764	valid&#39;s binary_logloss: 0.260796
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717764	valid&#39;s binary_logloss: 0.260796
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717486	valid&#39;s binary_logloss: 0.260827
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717486	valid&#39;s binary_logloss: 0.260827
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717731	valid&#39;s binary_logloss: 0.260762
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717731	valid&#39;s binary_logloss: 0.260762
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718901	valid&#39;s binary_logloss: 0.260708
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718901	valid&#39;s binary_logloss: 0.260708
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742549	valid&#39;s binary_logloss: 0.251481
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742549	valid&#39;s binary_logloss: 0.251481
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741305	valid&#39;s binary_logloss: 0.251826
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741305	valid&#39;s binary_logloss: 0.251826
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742362	valid&#39;s binary_logloss: 0.251692
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742362	valid&#39;s binary_logloss: 0.251692
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74282	valid&#39;s binary_logloss: 0.251503
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74282	valid&#39;s binary_logloss: 0.251503
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742651	valid&#39;s binary_logloss: 0.251525
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742651	valid&#39;s binary_logloss: 0.251525
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747409	valid&#39;s binary_logloss: 0.249024
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747409	valid&#39;s binary_logloss: 0.249024
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747069	valid&#39;s binary_logloss: 0.249144
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747069	valid&#39;s binary_logloss: 0.249144
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748793	valid&#39;s binary_logloss: 0.248787
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748793	valid&#39;s binary_logloss: 0.248787
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749236	valid&#39;s binary_logloss: 0.248694
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749236	valid&#39;s binary_logloss: 0.248694
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748492	valid&#39;s binary_logloss: 0.248968
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.748561	valid&#39;s binary_logloss: 0.248997
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743139	valid&#39;s binary_logloss: 0.251241
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743139	valid&#39;s binary_logloss: 0.251241
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742084	valid&#39;s binary_logloss: 0.251506
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742084	valid&#39;s binary_logloss: 0.251506
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743318	valid&#39;s binary_logloss: 0.251176
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743318	valid&#39;s binary_logloss: 0.251176
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743092	valid&#39;s binary_logloss: 0.251297
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743092	valid&#39;s binary_logloss: 0.251297
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744291	valid&#39;s binary_logloss: 0.251096
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744291	valid&#39;s binary_logloss: 0.251096
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741721	valid&#39;s binary_logloss: 0.251911
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741721	valid&#39;s binary_logloss: 0.251911
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74169	valid&#39;s binary_logloss: 0.251917
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74169	valid&#39;s binary_logloss: 0.251917
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741826	valid&#39;s binary_logloss: 0.251982
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741826	valid&#39;s binary_logloss: 0.251982
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742263	valid&#39;s binary_logloss: 0.25184
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742263	valid&#39;s binary_logloss: 0.25184
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.741949	valid&#39;s binary_logloss: 0.251945
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.741949	valid&#39;s binary_logloss: 0.251945
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726791	valid&#39;s binary_logloss: 0.260204
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726791	valid&#39;s binary_logloss: 0.260204
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724002	valid&#39;s binary_logloss: 0.260547
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724002	valid&#39;s binary_logloss: 0.260547
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725791	valid&#39;s binary_logloss: 0.260476
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725791	valid&#39;s binary_logloss: 0.260476
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[10]	valid&#39;s auc: 0.712765	valid&#39;s binary_logloss: 0.276511
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726484	valid&#39;s binary_logloss: 0.260266
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726484	valid&#39;s binary_logloss: 0.260266
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733923	valid&#39;s binary_logloss: 0.255083
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733923	valid&#39;s binary_logloss: 0.255083
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733028	valid&#39;s binary_logloss: 0.255248
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733028	valid&#39;s binary_logloss: 0.255248
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.733968	valid&#39;s binary_logloss: 0.255136
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.733968	valid&#39;s binary_logloss: 0.255136
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734974	valid&#39;s binary_logloss: 0.254939
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734974	valid&#39;s binary_logloss: 0.254939
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734531	valid&#39;s binary_logloss: 0.25499
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734531	valid&#39;s binary_logloss: 0.25499
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748026	valid&#39;s binary_logloss: 0.248651
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748026	valid&#39;s binary_logloss: 0.248651
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747555	valid&#39;s binary_logloss: 0.2489
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747616	valid&#39;s binary_logloss: 0.248889
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749251	valid&#39;s binary_logloss: 0.248722
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749251	valid&#39;s binary_logloss: 0.248722
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748794	valid&#39;s binary_logloss: 0.248586
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748794	valid&#39;s binary_logloss: 0.248586
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748665	valid&#39;s binary_logloss: 0.248842
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748665	valid&#39;s binary_logloss: 0.248842
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720796	valid&#39;s binary_logloss: 0.260177
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720796	valid&#39;s binary_logloss: 0.260177
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719662	valid&#39;s binary_logloss: 0.260334
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719662	valid&#39;s binary_logloss: 0.260334
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720277	valid&#39;s binary_logloss: 0.260324
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720277	valid&#39;s binary_logloss: 0.260324
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72114	valid&#39;s binary_logloss: 0.260212
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72114	valid&#39;s binary_logloss: 0.260212
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72132	valid&#39;s binary_logloss: 0.260176
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72132	valid&#39;s binary_logloss: 0.260176
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726786	valid&#39;s binary_logloss: 0.257883
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726786	valid&#39;s binary_logloss: 0.257883
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.725803	valid&#39;s binary_logloss: 0.258058
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.725803	valid&#39;s binary_logloss: 0.258058
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726702	valid&#39;s binary_logloss: 0.258028
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726702	valid&#39;s binary_logloss: 0.258028
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.726662	valid&#39;s binary_logloss: 0.257928
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.726662	valid&#39;s binary_logloss: 0.257928
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.727415	valid&#39;s binary_logloss: 0.257842
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.727415	valid&#39;s binary_logloss: 0.257842
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.712771	valid&#39;s binary_logloss: 0.263011
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.712771	valid&#39;s binary_logloss: 0.263011
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.710719	valid&#39;s binary_logloss: 0.263132
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.710719	valid&#39;s binary_logloss: 0.263132
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.710118	valid&#39;s binary_logloss: 0.263133
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.710118	valid&#39;s binary_logloss: 0.263133
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711625	valid&#39;s binary_logloss: 0.263014
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711625	valid&#39;s binary_logloss: 0.263014
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.711515	valid&#39;s binary_logloss: 0.263048
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.711515	valid&#39;s binary_logloss: 0.263048
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74389	valid&#39;s binary_logloss: 0.250863
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74389	valid&#39;s binary_logloss: 0.250863
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742634	valid&#39;s binary_logloss: 0.251023
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742634	valid&#39;s binary_logloss: 0.251023
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743199	valid&#39;s binary_logloss: 0.251081
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743199	valid&#39;s binary_logloss: 0.251081
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743743	valid&#39;s binary_logloss: 0.250833
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743743	valid&#39;s binary_logloss: 0.250833
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744042	valid&#39;s binary_logloss: 0.250862
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744042	valid&#39;s binary_logloss: 0.250862
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722702	valid&#39;s binary_logloss: 0.260954
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722702	valid&#39;s binary_logloss: 0.260954
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721604	valid&#39;s binary_logloss: 0.261074
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721604	valid&#39;s binary_logloss: 0.261074
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723177	valid&#39;s binary_logloss: 0.261057
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723177	valid&#39;s binary_logloss: 0.261057
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722904	valid&#39;s binary_logloss: 0.261038
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722904	valid&#39;s binary_logloss: 0.261038
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723976	valid&#39;s binary_logloss: 0.260936
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723976	valid&#39;s binary_logloss: 0.260936
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745532	valid&#39;s binary_logloss: 0.249866
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745532	valid&#39;s binary_logloss: 0.249866
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74329	valid&#39;s binary_logloss: 0.250323
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74329	valid&#39;s binary_logloss: 0.250323
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746	valid&#39;s binary_logloss: 0.249789
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746	valid&#39;s binary_logloss: 0.249789
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745234	valid&#39;s binary_logloss: 0.249872
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745234	valid&#39;s binary_logloss: 0.249872
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745754	valid&#39;s binary_logloss: 0.249857
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745754	valid&#39;s binary_logloss: 0.249857
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724506	valid&#39;s binary_logloss: 0.259461
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724506	valid&#39;s binary_logloss: 0.259461
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721185	valid&#39;s binary_logloss: 0.259852
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721185	valid&#39;s binary_logloss: 0.259852
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[11]	valid&#39;s auc: 0.703575	valid&#39;s binary_logloss: 0.275456
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.72505	valid&#39;s binary_logloss: 0.259401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.72505	valid&#39;s binary_logloss: 0.259401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.724902	valid&#39;s binary_logloss: 0.259493
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.724902	valid&#39;s binary_logloss: 0.259493
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748446	valid&#39;s binary_logloss: 0.248833
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748446	valid&#39;s binary_logloss: 0.248833
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747855	valid&#39;s binary_logloss: 0.248848
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747855	valid&#39;s binary_logloss: 0.248848
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748871	valid&#39;s binary_logloss: 0.248801
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748871	valid&#39;s binary_logloss: 0.248801
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748739	valid&#39;s binary_logloss: 0.248777
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.748745	valid&#39;s binary_logloss: 0.248784
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749127	valid&#39;s binary_logloss: 0.248786
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749127	valid&#39;s binary_logloss: 0.248786
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737675	valid&#39;s binary_logloss: 0.254525
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737675	valid&#39;s binary_logloss: 0.254525
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73506	valid&#39;s binary_logloss: 0.254898
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73506	valid&#39;s binary_logloss: 0.254898
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737131	valid&#39;s binary_logloss: 0.254642
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737131	valid&#39;s binary_logloss: 0.254642
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737609	valid&#39;s binary_logloss: 0.254607
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737609	valid&#39;s binary_logloss: 0.254607
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738246	valid&#39;s binary_logloss: 0.254554
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738246	valid&#39;s binary_logloss: 0.254554
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743753	valid&#39;s binary_logloss: 0.25087
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743753	valid&#39;s binary_logloss: 0.25087
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743039	valid&#39;s binary_logloss: 0.251059
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743039	valid&#39;s binary_logloss: 0.251059
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742955	valid&#39;s binary_logloss: 0.251127
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742955	valid&#39;s binary_logloss: 0.251127
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744189	valid&#39;s binary_logloss: 0.25081
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744189	valid&#39;s binary_logloss: 0.25081
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.742698	valid&#39;s binary_logloss: 0.251065
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.742698	valid&#39;s binary_logloss: 0.251065
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746003	valid&#39;s binary_logloss: 0.249796
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746003	valid&#39;s binary_logloss: 0.249796
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746304	valid&#39;s binary_logloss: 0.249811
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746304	valid&#39;s binary_logloss: 0.249811
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746737	valid&#39;s binary_logloss: 0.249748
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746737	valid&#39;s binary_logloss: 0.249748
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747354	valid&#39;s binary_logloss: 0.249449
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747354	valid&#39;s binary_logloss: 0.249449
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747317	valid&#39;s binary_logloss: 0.249646
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747317	valid&#39;s binary_logloss: 0.249646
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747014	valid&#39;s binary_logloss: 0.249351
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747014	valid&#39;s binary_logloss: 0.249351
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746878	valid&#39;s binary_logloss: 0.249499
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746878	valid&#39;s binary_logloss: 0.249499
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746993	valid&#39;s binary_logloss: 0.249553
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746993	valid&#39;s binary_logloss: 0.249553
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74771	valid&#39;s binary_logloss: 0.249269
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74771	valid&#39;s binary_logloss: 0.249269
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748057	valid&#39;s binary_logloss: 0.249267
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748057	valid&#39;s binary_logloss: 0.249267
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748904	valid&#39;s binary_logloss: 0.248337
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.748911	valid&#39;s binary_logloss: 0.248325
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747874	valid&#39;s binary_logloss: 0.248777
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.748222	valid&#39;s binary_logloss: 0.248693
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749936	valid&#39;s binary_logloss: 0.248107
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.74999	valid&#39;s binary_logloss: 0.248087
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748965	valid&#39;s binary_logloss: 0.248484
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748965	valid&#39;s binary_logloss: 0.248484
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749692	valid&#39;s binary_logloss: 0.248381
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.749808	valid&#39;s binary_logloss: 0.248358
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746926	valid&#39;s binary_logloss: 0.249488
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746926	valid&#39;s binary_logloss: 0.249488
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747764	valid&#39;s binary_logloss: 0.249222
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747764	valid&#39;s binary_logloss: 0.249222
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746625	valid&#39;s binary_logloss: 0.249511
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746625	valid&#39;s binary_logloss: 0.249511
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745603	valid&#39;s binary_logloss: 0.249683
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745603	valid&#39;s binary_logloss: 0.249683
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748296	valid&#39;s binary_logloss: 0.249286
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.748365	valid&#39;s binary_logloss: 0.24933
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745794	valid&#39;s binary_logloss: 0.249938
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745794	valid&#39;s binary_logloss: 0.249938
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744508	valid&#39;s binary_logloss: 0.250237
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744508	valid&#39;s binary_logloss: 0.250237
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746609	valid&#39;s binary_logloss: 0.249917
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746609	valid&#39;s binary_logloss: 0.249917
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746456	valid&#39;s binary_logloss: 0.249898
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746456	valid&#39;s binary_logloss: 0.249898
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747158	valid&#39;s binary_logloss: 0.249839
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747158	valid&#39;s binary_logloss: 0.249839
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737816	valid&#39;s binary_logloss: 0.253774
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737816	valid&#39;s binary_logloss: 0.253774
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737246	valid&#39;s binary_logloss: 0.25386
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737246	valid&#39;s binary_logloss: 0.25386
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738136	valid&#39;s binary_logloss: 0.253733
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738136	valid&#39;s binary_logloss: 0.253733
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738652	valid&#39;s binary_logloss: 0.253597
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738652	valid&#39;s binary_logloss: 0.253597
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738485	valid&#39;s binary_logloss: 0.253769
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738485	valid&#39;s binary_logloss: 0.253769
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.720392	valid&#39;s binary_logloss: 0.261253
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.720392	valid&#39;s binary_logloss: 0.261253
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.717192	valid&#39;s binary_logloss: 0.261531
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.717192	valid&#39;s binary_logloss: 0.261531
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718791	valid&#39;s binary_logloss: 0.261498
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718791	valid&#39;s binary_logloss: 0.261498
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.718523	valid&#39;s binary_logloss: 0.261418
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.718523	valid&#39;s binary_logloss: 0.261418
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.719218	valid&#39;s binary_logloss: 0.261354
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.719218	valid&#39;s binary_logloss: 0.261354
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748587	valid&#39;s binary_logloss: 0.2488
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748587	valid&#39;s binary_logloss: 0.2488
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746847	valid&#39;s binary_logloss: 0.249342
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746847	valid&#39;s binary_logloss: 0.249342
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748611	valid&#39;s binary_logloss: 0.248908
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748611	valid&#39;s binary_logloss: 0.248908
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747888	valid&#39;s binary_logloss: 0.249029
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747888	valid&#39;s binary_logloss: 0.249029
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748251	valid&#39;s binary_logloss: 0.249074
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.748262	valid&#39;s binary_logloss: 0.249081
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74452	valid&#39;s binary_logloss: 0.250752
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74452	valid&#39;s binary_logloss: 0.250752
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743669	valid&#39;s binary_logloss: 0.250761
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743669	valid&#39;s binary_logloss: 0.250761
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744748	valid&#39;s binary_logloss: 0.250665
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744748	valid&#39;s binary_logloss: 0.250665
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744849	valid&#39;s binary_logloss: 0.250718
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744849	valid&#39;s binary_logloss: 0.250718
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744489	valid&#39;s binary_logloss: 0.250778
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744489	valid&#39;s binary_logloss: 0.250778
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74519	valid&#39;s binary_logloss: 0.250153
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74519	valid&#39;s binary_logloss: 0.250153
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744554	valid&#39;s binary_logloss: 0.250188
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744554	valid&#39;s binary_logloss: 0.250188
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745382	valid&#39;s binary_logloss: 0.250188
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745382	valid&#39;s binary_logloss: 0.250188
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745414	valid&#39;s binary_logloss: 0.250058
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745414	valid&#39;s binary_logloss: 0.250058
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745506	valid&#39;s binary_logloss: 0.249955
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745506	valid&#39;s binary_logloss: 0.249955
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746842	valid&#39;s binary_logloss: 0.24927
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746842	valid&#39;s binary_logloss: 0.24927
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74575	valid&#39;s binary_logloss: 0.249421
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74575	valid&#39;s binary_logloss: 0.249421
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747998	valid&#39;s binary_logloss: 0.248994
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747998	valid&#39;s binary_logloss: 0.248994
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748179	valid&#39;s binary_logloss: 0.248915
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748179	valid&#39;s binary_logloss: 0.248915
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747649	valid&#39;s binary_logloss: 0.249139
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747649	valid&#39;s binary_logloss: 0.249139
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747413	valid&#39;s binary_logloss: 0.249189
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747413	valid&#39;s binary_logloss: 0.249189
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745948	valid&#39;s binary_logloss: 0.2497
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.746018	valid&#39;s binary_logloss: 0.249716
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746958	valid&#39;s binary_logloss: 0.249295
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746958	valid&#39;s binary_logloss: 0.249295
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747286	valid&#39;s binary_logloss: 0.249204
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747286	valid&#39;s binary_logloss: 0.249204
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747284	valid&#39;s binary_logloss: 0.249492
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747284	valid&#39;s binary_logloss: 0.249492
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744959	valid&#39;s binary_logloss: 0.250478
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744959	valid&#39;s binary_logloss: 0.250478
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744264	valid&#39;s binary_logloss: 0.250708
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744264	valid&#39;s binary_logloss: 0.250708
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744584	valid&#39;s binary_logloss: 0.250608
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744584	valid&#39;s binary_logloss: 0.250608
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744628	valid&#39;s binary_logloss: 0.250504
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744628	valid&#39;s binary_logloss: 0.250504
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745125	valid&#39;s binary_logloss: 0.250518
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745125	valid&#39;s binary_logloss: 0.250518
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734662	valid&#39;s binary_logloss: 0.254262
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734662	valid&#39;s binary_logloss: 0.254262
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734416	valid&#39;s binary_logloss: 0.254299
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734416	valid&#39;s binary_logloss: 0.254299
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735729	valid&#39;s binary_logloss: 0.254236
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735729	valid&#39;s binary_logloss: 0.254236
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73661	valid&#39;s binary_logloss: 0.253896
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73661	valid&#39;s binary_logloss: 0.253896
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736404	valid&#39;s binary_logloss: 0.253925
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736404	valid&#39;s binary_logloss: 0.253925
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737597	valid&#39;s binary_logloss: 0.2537
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737597	valid&#39;s binary_logloss: 0.2537
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735402	valid&#39;s binary_logloss: 0.253929
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735402	valid&#39;s binary_logloss: 0.253929
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737033	valid&#39;s binary_logloss: 0.253786
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737033	valid&#39;s binary_logloss: 0.253786
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.737885	valid&#39;s binary_logloss: 0.253577
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.737885	valid&#39;s binary_logloss: 0.253577
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.738606	valid&#39;s binary_logloss: 0.25353
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.738606	valid&#39;s binary_logloss: 0.25353
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744523	valid&#39;s binary_logloss: 0.250595
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744523	valid&#39;s binary_logloss: 0.250595
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74316	valid&#39;s binary_logloss: 0.250814
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74316	valid&#39;s binary_logloss: 0.250814
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74288	valid&#39;s binary_logloss: 0.250966
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74288	valid&#39;s binary_logloss: 0.250966
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744829	valid&#39;s binary_logloss: 0.250524
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744829	valid&#39;s binary_logloss: 0.250524
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744401	valid&#39;s binary_logloss: 0.250696
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744401	valid&#39;s binary_logloss: 0.250696
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746237	valid&#39;s binary_logloss: 0.249853
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746237	valid&#39;s binary_logloss: 0.249853
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745847	valid&#39;s binary_logloss: 0.24994
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745847	valid&#39;s binary_logloss: 0.24994
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746258	valid&#39;s binary_logloss: 0.249979
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746258	valid&#39;s binary_logloss: 0.249979
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745928	valid&#39;s binary_logloss: 0.249928
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745928	valid&#39;s binary_logloss: 0.249928
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746466	valid&#39;s binary_logloss: 0.249856
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746466	valid&#39;s binary_logloss: 0.249856
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735412	valid&#39;s binary_logloss: 0.25637
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735412	valid&#39;s binary_logloss: 0.25637
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734582	valid&#39;s binary_logloss: 0.256516
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734582	valid&#39;s binary_logloss: 0.256516
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735185	valid&#39;s binary_logloss: 0.256409
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735185	valid&#39;s binary_logloss: 0.256409
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.734567	valid&#39;s binary_logloss: 0.256538
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.734567	valid&#39;s binary_logloss: 0.256538
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.73667	valid&#39;s binary_logloss: 0.256256
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.73667	valid&#39;s binary_logloss: 0.256256
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736463	valid&#39;s binary_logloss: 0.254202
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736463	valid&#39;s binary_logloss: 0.254202
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735289	valid&#39;s binary_logloss: 0.254362
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735289	valid&#39;s binary_logloss: 0.254362
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735548	valid&#39;s binary_logloss: 0.254452
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735548	valid&#39;s binary_logloss: 0.254452
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736745	valid&#39;s binary_logloss: 0.254285
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736745	valid&#39;s binary_logloss: 0.254285
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736394	valid&#39;s binary_logloss: 0.254247
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736394	valid&#39;s binary_logloss: 0.254247
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749211	valid&#39;s binary_logloss: 0.248288
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749211	valid&#39;s binary_logloss: 0.248288
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[80]	valid&#39;s auc: 0.748145	valid&#39;s binary_logloss: 0.248721
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[84]	valid&#39;s auc: 0.746425	valid&#39;s binary_logloss: 0.249218
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748043	valid&#39;s binary_logloss: 0.248725
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.748151	valid&#39;s binary_logloss: 0.248686
Training until validation scores don&#39;t improve for 10 rounds.
Early stopping, best iteration is:
[83]	valid&#39;s auc: 0.7472	valid&#39;s binary_logloss: 0.249007
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747801	valid&#39;s binary_logloss: 0.248657
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747801	valid&#39;s binary_logloss: 0.248657
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747871	valid&#39;s binary_logloss: 0.24876
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747877	valid&#39;s binary_logloss: 0.248766
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749722	valid&#39;s binary_logloss: 0.248335
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749722	valid&#39;s binary_logloss: 0.248335
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748431	valid&#39;s binary_logloss: 0.248674
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748431	valid&#39;s binary_logloss: 0.248674
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749517	valid&#39;s binary_logloss: 0.248626
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749517	valid&#39;s binary_logloss: 0.248626
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74521	valid&#39;s binary_logloss: 0.250381
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.74521	valid&#39;s binary_logloss: 0.250381
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.744992	valid&#39;s binary_logloss: 0.250294
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.744992	valid&#39;s binary_logloss: 0.250294
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.743834	valid&#39;s binary_logloss: 0.250612
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.743834	valid&#39;s binary_logloss: 0.250612
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745991	valid&#39;s binary_logloss: 0.249981
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745991	valid&#39;s binary_logloss: 0.249981
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745074	valid&#39;s binary_logloss: 0.25046
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745074	valid&#39;s binary_logloss: 0.25046
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722014	valid&#39;s binary_logloss: 0.259621
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722014	valid&#39;s binary_logloss: 0.259621
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721121	valid&#39;s binary_logloss: 0.259818
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721121	valid&#39;s binary_logloss: 0.259818
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.721381	valid&#39;s binary_logloss: 0.25975
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.721381	valid&#39;s binary_logloss: 0.25975
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.722346	valid&#39;s binary_logloss: 0.259652
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.722346	valid&#39;s binary_logloss: 0.259652
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.723872	valid&#39;s binary_logloss: 0.259512
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.723872	valid&#39;s binary_logloss: 0.259512
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747771	valid&#39;s binary_logloss: 0.248777
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747771	valid&#39;s binary_logloss: 0.248777
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.74796	valid&#39;s binary_logloss: 0.248862
Did not meet early stopping. Best iteration is:
[97]	valid&#39;s auc: 0.748198	valid&#39;s binary_logloss: 0.248836
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748317	valid&#39;s binary_logloss: 0.248633
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748317	valid&#39;s binary_logloss: 0.248633
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748098	valid&#39;s binary_logloss: 0.24875
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748098	valid&#39;s binary_logloss: 0.24875
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748117	valid&#39;s binary_logloss: 0.249008
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.748122	valid&#39;s binary_logloss: 0.249016
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736544	valid&#39;s binary_logloss: 0.253939
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736544	valid&#39;s binary_logloss: 0.253939
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.735469	valid&#39;s binary_logloss: 0.254216
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.735469	valid&#39;s binary_logloss: 0.254216
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736043	valid&#39;s binary_logloss: 0.254092
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736043	valid&#39;s binary_logloss: 0.254092
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736786	valid&#39;s binary_logloss: 0.253923
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736786	valid&#39;s binary_logloss: 0.253923
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.736698	valid&#39;s binary_logloss: 0.253964
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.736698	valid&#39;s binary_logloss: 0.253964
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749606	valid&#39;s binary_logloss: 0.248155
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.749623	valid&#39;s binary_logloss: 0.248131
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747472	valid&#39;s binary_logloss: 0.248832
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747497	valid&#39;s binary_logloss: 0.248815
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.751144	valid&#39;s binary_logloss: 0.247943
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.751144	valid&#39;s binary_logloss: 0.247943
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.750172	valid&#39;s binary_logloss: 0.24832
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.750248	valid&#39;s binary_logloss: 0.248319
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.750323	valid&#39;s binary_logloss: 0.248335
Did not meet early stopping. Best iteration is:
[98]	valid&#39;s auc: 0.75045	valid&#39;s binary_logloss: 0.248306
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747761	valid&#39;s binary_logloss: 0.248803
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747761	valid&#39;s binary_logloss: 0.248803
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747798	valid&#39;s binary_logloss: 0.248846
Did not meet early stopping. Best iteration is:
[99]	valid&#39;s auc: 0.747831	valid&#39;s binary_logloss: 0.248841
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748683	valid&#39;s binary_logloss: 0.248732
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748683	valid&#39;s binary_logloss: 0.248732
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.749579	valid&#39;s binary_logloss: 0.248401
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.749579	valid&#39;s binary_logloss: 0.248401
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.748683	valid&#39;s binary_logloss: 0.248711
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.748683	valid&#39;s binary_logloss: 0.248711
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747023	valid&#39;s binary_logloss: 0.249176
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747023	valid&#39;s binary_logloss: 0.249176
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745228	valid&#39;s binary_logloss: 0.249734
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745228	valid&#39;s binary_logloss: 0.249734
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746684	valid&#39;s binary_logloss: 0.249403
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746684	valid&#39;s binary_logloss: 0.249403
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747984	valid&#39;s binary_logloss: 0.249102
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747984	valid&#39;s binary_logloss: 0.249102
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.747735	valid&#39;s binary_logloss: 0.249183
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.747735	valid&#39;s binary_logloss: 0.249183
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746329	valid&#39;s binary_logloss: 0.24958
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746329	valid&#39;s binary_logloss: 0.24958
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.745555	valid&#39;s binary_logloss: 0.24979
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.745555	valid&#39;s binary_logloss: 0.24979
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746191	valid&#39;s binary_logloss: 0.249899
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746191	valid&#39;s binary_logloss: 0.249899
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746526	valid&#39;s binary_logloss: 0.249595
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746526	valid&#39;s binary_logloss: 0.249595
Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.746088	valid&#39;s binary_logloss: 0.24983
Did not meet early stopping. Best iteration is:
[100]	valid&#39;s auc: 0.746088	valid&#39;s binary_logloss: 0.24983
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 111.8min finished
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 10 rounds.
[100]	valid&#39;s auc: 0.751782	valid&#39;s binary_logloss: 0.247689
Did not meet early stopping. Best iteration is:
[96]	valid&#39;s auc: 0.751789	valid&#39;s binary_logloss: 0.247751
finishing pca n=150
Elapsed time: 6722.860311508179 seconds
Wall time: 4h 4min 32s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Clear the cache directory after job is done</span>
<span class="n">rmtree</span><span class="p">(</span><span class="n">cachedir</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>unfortunately, the pac() doesn't have any better result</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="use-more-features-from-Naimesh-and-Nishad">use more features from Naimesh and Nishad<a class="anchor-link" href="#use-more-features-from-Naimesh-and-Nishad">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>added the new features from Naimesh and Nishad</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># select numerica and categorical features</span>

<span class="n">NUMERIC_COLS_lgbm</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_REGISTRATION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_ID_PUBLISH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;TOTALAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_LAST_PHONE_CHANGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span>
 <span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;income_credit_percen&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;fam_member_income&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;ann_incom_percen&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;new_employ_to_birth_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;new_credit_to_annuity&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;new_credit_to_goods_ratio&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;new_car_to_birth_ratio&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;new_car_to_emp_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;new_inc_per_child&#39;</span><span class="p">,</span>                    
 <span class="s1">&#39;income_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;credit_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;annuity_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;fam_member_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;child_population_percen&#39;</span><span class="p">,</span>
<span class="s1">&#39;goods_prices_population_percen&#39;</span><span class="p">,</span>                  
<span class="s1">&#39;car_age_population_percen&#39;</span><span class="p">,</span>
<span class="c1"># &#39;no_prev_app_income_percen&#39;,</span>
<span class="c1"># &#39;no_prev_app_annuity_percen&#39;,  </span>
<span class="c1"># &#39;no_prev_app_credit_percen&#39;,</span>
<span class="c1"># &#39;no_prev_app_days_birth_percen&#39;,</span>
<span class="c1"># &#39;no_prev_app_days_employed_percen&#39;,         </span>
<span class="c1"># &#39;no_approved_prev_appl_income_percen&#39;,</span>
<span class="c1"># &#39;no_approved_prev_appl_annuity_percen&#39;,</span>
<span class="c1"># &#39;no_approved_prev_appl_credit_percen&#39;,</span>
<span class="c1"># &#39;no_approved_prev_appl_days_birth_percen&#39;,</span>
<span class="c1"># &#39;no_approved_prev_appl_days_employed_percen&#39;,</span>
<span class="c1"># &#39;total_creditLimit_income_percen&#39;,</span>
<span class="c1"># &#39;total_creditLimit_annuity_percen&#39;,</span>
<span class="c1"># &#39;total_creditLimit_credit_percen&#39;,</span>
<span class="c1"># &#39;total_creditLimit_days_birth_percen&#39;,</span>
<span class="c1"># &#39;total_creditLimit_days_employed_percen&#39;,</span>
<span class="c1"># &#39;no_of_loans_income_percen&#39;,</span>
<span class="c1"># &#39;no_of_loans_annuity_percen&#39;,</span>
<span class="c1"># &#39;no_of_loans_credit_percen&#39;,</span>
<span class="c1"># &#39;no_of_loans_days_birth_percen&#39;,</span>
<span class="c1"># &#39;no_of_loans_days_employed_percen&#39;,   </span>
<span class="c1"># &#39;utilization_CC_income_percen&#39;,</span>
<span class="c1"># &#39;utilization_CC_annuity_percen&#39;,</span>
<span class="c1"># &#39;utilization_CC_credit_percen&#39;, </span>
<span class="c1"># &#39;utilization_CC_days_birth_percen&#39;,</span>
<span class="c1"># &#39;utilization_CC_days_employed_percen&#39;,</span>
<span class="c1"># &#39;payment_ratio_CC_income_percen&#39;,</span>
<span class="c1"># &#39;payment_ratio_CC_annuity_percen&#39;,</span>
<span class="c1"># &#39;payment_ratio_CC_credit_percen&#39;,</span>
<span class="c1"># &#39;payment_ratio_CC_days_birth_percen&#39;,</span>
<span class="c1"># &#39;payment_ratio_CC_days_employed_percen&#39;,</span>
<span class="c1"># &#39;past_due_times_income_percen&#39;,</span>
<span class="c1"># &#39;past_due_timesC_annuity_percen&#39;,  </span>
<span class="c1"># &#39;past_due_times_credit_percen&#39;,</span>
<span class="c1"># &#39;past_due_times_days_birth_percen&#39;,</span>
<span class="c1"># &#39;past_due_times_days_employed_percen&#39;</span>
                    <span class="p">]</span>

<span class="n">CATEGORY_COLS_lgbm</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_TYPE_SUITE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_FAMILY_STATUS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_HOUSING_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_MOBIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_CONT_MOBILE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMAIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WEEKDAY_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_LIVE_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_LIVE_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUSETYPE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EMERGENCYSTATE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_4&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_5&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_6&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_7&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_8&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_9&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_10&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_11&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_12&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_13&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_14&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_15&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_16&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_17&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_18&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_19&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_20&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_21&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

lgbm_pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_lgbm, num_attribs=NUMERIC_COLS_lgbm)

X, Y, pipe = pre_process(phase = &quot;train&quot;, preproc_pipeline = lgbm_pipeline)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>loaded 307511 records
features from previous application
features from bureau
features from credit card balance
features from installments
features from application
start pipeline
Wall time: 1min 15s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="from-Nishad-and-Naimesh-using-Bayesian-search">from Nishad and Naimesh using Bayesian search<a class="anchor-link" href="#from-Nishad-and-Naimesh-using-Bayesian-search">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">hyperopt</span> <span class="k">import</span> <span class="n">STATUS_OK</span><span class="p">,</span> <span class="n">Trials</span><span class="p">,</span> <span class="n">fmin</span><span class="p">,</span> <span class="n">hp</span><span class="p">,</span> <span class="n">tpe</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="k">import</span> <span class="n">LGBMClassifier</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;max_depth&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;reg_alpha&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;reg_lambda&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;feature_fraction&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;feature_fraction&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;min_child_weight&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;min_child_samples&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;min_child_samples&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;subsample&#39;</span><span class="p">]),</span>
        <span class="s1">&#39;bagging_fraction&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;bagging_fraction&#39;</span><span class="p">]),</span>

        
    <span class="p">}</span>

    <span class="n">clf</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span>
        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="o">**</span><span class="n">params</span>
    <span class="p">)</span>

    <span class="n">gbm_model</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)],</span> <span class="n">eval_metric</span><span class="o">=</span><span class="p">[</span>
                        <span class="s1">&#39;logloss&#39;</span><span class="p">,</span> <span class="s1">&#39;auc&#39;</span><span class="p">],</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="n">gbm_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="o">-</span><span class="n">score</span><span class="p">,</span> <span class="s1">&#39;status&#39;</span><span class="p">:</span> <span class="n">STATUS_OK</span><span class="p">}</span>


<span class="n">space</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;max_depth&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s1">&#39;feature_fraction&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;feature_fraction&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">),</span>
    <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;min_child_weight&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="s1">&#39;min_child_samples&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;min_child_samples&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;subsample&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="s1">&#39;bagging_fraction&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;bagging_fraction&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;reg_alpha&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;reg_lambda&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>

<span class="p">}</span>

<span class="n">best</span> <span class="o">=</span> <span class="n">fmin</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">space</span><span class="o">=</span><span class="n">space</span><span class="p">,</span>
            <span class="n">algo</span><span class="o">=</span><span class="n">tpe</span><span class="o">.</span><span class="n">suggest</span><span class="p">,</span>
            <span class="n">max_evals</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>100%|██████████| 30/30 [24:51&lt;00:00, 60.45s/it, best loss: 0.2204405004707939]
{&#39;bagging_fraction&#39;: 0.9, &#39;feature_fraction&#39;: 0.2, &#39;learning_rate&#39;: 0.07500000000000001, &#39;max_depth&#39;: 9.0, &#39;min_child_samples&#39;: 20.0, &#39;min_child_weight&#39;: 7.0, &#39;num_leaves&#39;: 49.0, &#39;reg_alpha&#39;: 0.9, &#39;reg_lambda&#39;: 0.0, &#39;subsample&#39;: 0.30000000000000004}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="RandomizedSearch-Based-on-results-from-Bayesian-search">RandomizedSearch Based on results from Bayesian search<a class="anchor-link" href="#RandomizedSearch-Based-on-results-from-Bayesian-search">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">randint</span> <span class="k">as</span> <span class="n">sp_randint</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">uniform</span> <span class="k">as</span> <span class="n">sp_uniform</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">grid_params</span> <span class="o">=</span><span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
             <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">),</span> 
             <span class="s1">&#39;min_child_samples&#39;</span><span class="p">:</span> <span class="n">sp_randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> 
             <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
             <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.075</span><span class="p">),</span>
             <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
             <span class="s1">&#39;bagging_fraction&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
             <span class="s1">&#39;feature_fraction&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.15</span><span class="p">),</span>
             <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
             <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">sp_uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)}</span>

<span class="n">fit_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;early_stopping_rounds&quot;</span><span class="p">:</span><span class="mi">500</span><span class="p">,</span> 
            <span class="s2">&quot;eval_metric&quot;</span> <span class="p">:</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span> 
            <span class="s2">&quot;eval_set&quot;</span> <span class="p">:</span> <span class="p">[(</span><span class="n">X_valid</span><span class="p">,</span><span class="n">y_valid</span><span class="p">)],</span>
            <span class="s1">&#39;eval_names&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">],</span>
            <span class="c1">#&#39;callbacks&#39;: [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],</span>
            <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s1">&#39;categorical_feature&#39;</span><span class="p">:</span> <span class="s1">&#39;auto&#39;</span><span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

from lightgbm import LGBMClassifier
import time


clf = LGBMClassifier(num_iterations=5000)
search = RandomizedSearchCV(
    estimator=clf, 
    param_distributions=grid_params, 
    scoring={&#39;AUC&#39;: &#39;roc_auc&#39;, &#39;LogLoss&#39;: &#39;neg_log_loss&#39;},
    cv=5,
    refit=&#39;AUC&#39;,
    random_state=42,
    verbose=True)

# log arguments
pipe_steps = repr(pipe.transformers_)
description = &quot;LGBM with new features from nishad poly degree = 1 bayesian 2_metrics&quot;
experiment = &quot;Lgbm_new_features_nishad_poly1_2nd_2_metrics&quot;

start_time = time.time()
run_test(X_train, y_train, search, description, experiment, pipe_steps, cat_attribs=CATEGORY_COLS_lgbm,
        num_attribs=NUMERIC_COLS_lgbm, **fit_params)
end_time = time.time()
elapsed_time = end_time - start_time
print(f&quot;Elapsed time: {elapsed_time} seconds&quot;)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 5 folds for each of 10 candidates, totalling 50 fits
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.241767	valid&#39;s auc: 0.772757
[200]	valid&#39;s binary_logloss: 0.24016	valid&#39;s auc: 0.776134
[300]	valid&#39;s binary_logloss: 0.240171	valid&#39;s auc: 0.776315
[400]	valid&#39;s binary_logloss: 0.240409	valid&#39;s auc: 0.77508
[500]	valid&#39;s binary_logloss: 0.240909	valid&#39;s auc: 0.773538
[600]	valid&#39;s binary_logloss: 0.241511	valid&#39;s auc: 0.772136
[700]	valid&#39;s binary_logloss: 0.241914	valid&#39;s auc: 0.771346
Early stopping, best iteration is:
[235]	valid&#39;s binary_logloss: 0.240088	valid&#39;s auc: 0.776494
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.241469	valid&#39;s auc: 0.773905
[200]	valid&#39;s binary_logloss: 0.239852	valid&#39;s auc: 0.777479
[300]	valid&#39;s binary_logloss: 0.239727	valid&#39;s auc: 0.777764
[400]	valid&#39;s binary_logloss: 0.240071	valid&#39;s auc: 0.776405
[500]	valid&#39;s binary_logloss: 0.240472	valid&#39;s auc: 0.775569
[600]	valid&#39;s binary_logloss: 0.240956	valid&#39;s auc: 0.774307
[700]	valid&#39;s binary_logloss: 0.241416	valid&#39;s auc: 0.773496
Early stopping, best iteration is:
[285]	valid&#39;s binary_logloss: 0.239678	valid&#39;s auc: 0.778063
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.241829	valid&#39;s auc: 0.772226
[200]	valid&#39;s binary_logloss: 0.24061	valid&#39;s auc: 0.77418
[300]	valid&#39;s binary_logloss: 0.240694	valid&#39;s auc: 0.773758
[400]	valid&#39;s binary_logloss: 0.241004	valid&#39;s auc: 0.772425
[500]	valid&#39;s binary_logloss: 0.241434	valid&#39;s auc: 0.771347
[600]	valid&#39;s binary_logloss: 0.241988	valid&#39;s auc: 0.769967
Early stopping, best iteration is:
[181]	valid&#39;s binary_logloss: 0.24056	valid&#39;s auc: 0.774602
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.242117	valid&#39;s auc: 0.772009
[200]	valid&#39;s binary_logloss: 0.240499	valid&#39;s auc: 0.77581
[300]	valid&#39;s binary_logloss: 0.240699	valid&#39;s auc: 0.775271
[400]	valid&#39;s binary_logloss: 0.241019	valid&#39;s auc: 0.774545
[500]	valid&#39;s binary_logloss: 0.241394	valid&#39;s auc: 0.77353
[600]	valid&#39;s binary_logloss: 0.241839	valid&#39;s auc: 0.772416
[700]	valid&#39;s binary_logloss: 0.242354	valid&#39;s auc: 0.771124
Early stopping, best iteration is:
[200]	valid&#39;s binary_logloss: 0.240499	valid&#39;s auc: 0.77581
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.241605	valid&#39;s auc: 0.773732
[200]	valid&#39;s binary_logloss: 0.240201	valid&#39;s auc: 0.777033
[300]	valid&#39;s binary_logloss: 0.240289	valid&#39;s auc: 0.776542
[400]	valid&#39;s binary_logloss: 0.24054	valid&#39;s auc: 0.77608
[500]	valid&#39;s binary_logloss: 0.240992	valid&#39;s auc: 0.774679
[600]	valid&#39;s binary_logloss: 0.241389	valid&#39;s auc: 0.773582
[700]	valid&#39;s binary_logloss: 0.241774	valid&#39;s auc: 0.772351
Early stopping, best iteration is:
[210]	valid&#39;s binary_logloss: 0.240116	valid&#39;s auc: 0.77736
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.24828	valid&#39;s auc: 0.75723
[200]	valid&#39;s binary_logloss: 0.242724	valid&#39;s auc: 0.769723
[300]	valid&#39;s binary_logloss: 0.241558	valid&#39;s auc: 0.772307
[400]	valid&#39;s binary_logloss: 0.240946	valid&#39;s auc: 0.773707
[500]	valid&#39;s binary_logloss: 0.24079	valid&#39;s auc: 0.774041
[600]	valid&#39;s binary_logloss: 0.240908	valid&#39;s auc: 0.773283
[700]	valid&#39;s binary_logloss: 0.241071	valid&#39;s auc: 0.773082
[800]	valid&#39;s binary_logloss: 0.241388	valid&#39;s auc: 0.772085
[900]	valid&#39;s binary_logloss: 0.241826	valid&#39;s auc: 0.771133
[1000]	valid&#39;s binary_logloss: 0.242123	valid&#39;s auc: 0.770406
Early stopping, best iteration is:
[502]	valid&#39;s binary_logloss: 0.240773	valid&#39;s auc: 0.774096
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248631	valid&#39;s auc: 0.756501
[200]	valid&#39;s binary_logloss: 0.243016	valid&#39;s auc: 0.769565
[300]	valid&#39;s binary_logloss: 0.241855	valid&#39;s auc: 0.772166
[400]	valid&#39;s binary_logloss: 0.241158	valid&#39;s auc: 0.773536
[500]	valid&#39;s binary_logloss: 0.24115	valid&#39;s auc: 0.773405
[600]	valid&#39;s binary_logloss: 0.241103	valid&#39;s auc: 0.77375
[700]	valid&#39;s binary_logloss: 0.241235	valid&#39;s auc: 0.773455
[800]	valid&#39;s binary_logloss: 0.241299	valid&#39;s auc: 0.773384
[900]	valid&#39;s binary_logloss: 0.241557	valid&#39;s auc: 0.772942
Early stopping, best iteration is:
[481]	valid&#39;s binary_logloss: 0.240986	valid&#39;s auc: 0.773999
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248711	valid&#39;s auc: 0.756017
[200]	valid&#39;s binary_logloss: 0.242905	valid&#39;s auc: 0.769849
[300]	valid&#39;s binary_logloss: 0.241761	valid&#39;s auc: 0.772147
[400]	valid&#39;s binary_logloss: 0.241072	valid&#39;s auc: 0.773853
[500]	valid&#39;s binary_logloss: 0.240991	valid&#39;s auc: 0.773968
[600]	valid&#39;s binary_logloss: 0.241089	valid&#39;s auc: 0.773447
[700]	valid&#39;s binary_logloss: 0.241317	valid&#39;s auc: 0.77312
[800]	valid&#39;s binary_logloss: 0.241472	valid&#39;s auc: 0.772712
[900]	valid&#39;s binary_logloss: 0.241446	valid&#39;s auc: 0.772887
Early stopping, best iteration is:
[470]	valid&#39;s binary_logloss: 0.240866	valid&#39;s auc: 0.774312
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.249274	valid&#39;s auc: 0.755103
[200]	valid&#39;s binary_logloss: 0.243609	valid&#39;s auc: 0.768783
[300]	valid&#39;s binary_logloss: 0.242035	valid&#39;s auc: 0.77182
[400]	valid&#39;s binary_logloss: 0.241648	valid&#39;s auc: 0.772412
[500]	valid&#39;s binary_logloss: 0.241199	valid&#39;s auc: 0.773536
[600]	valid&#39;s binary_logloss: 0.241231	valid&#39;s auc: 0.773278
[700]	valid&#39;s binary_logloss: 0.24123	valid&#39;s auc: 0.773237
[800]	valid&#39;s binary_logloss: 0.241434	valid&#39;s auc: 0.772643
[900]	valid&#39;s binary_logloss: 0.241699	valid&#39;s auc: 0.771836
[1000]	valid&#39;s binary_logloss: 0.241803	valid&#39;s auc: 0.771469
Early stopping, best iteration is:
[539]	valid&#39;s binary_logloss: 0.241167	valid&#39;s auc: 0.773638
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.249169	valid&#39;s auc: 0.755549
[200]	valid&#39;s binary_logloss: 0.243381	valid&#39;s auc: 0.769612
[300]	valid&#39;s binary_logloss: 0.241842	valid&#39;s auc: 0.77261
[400]	valid&#39;s binary_logloss: 0.241371	valid&#39;s auc: 0.773261
[500]	valid&#39;s binary_logloss: 0.241166	valid&#39;s auc: 0.773759
[600]	valid&#39;s binary_logloss: 0.240967	valid&#39;s auc: 0.774285
[700]	valid&#39;s binary_logloss: 0.24104	valid&#39;s auc: 0.773834
[800]	valid&#39;s binary_logloss: 0.241229	valid&#39;s auc: 0.773364
[900]	valid&#39;s binary_logloss: 0.241462	valid&#39;s auc: 0.772936
[1000]	valid&#39;s binary_logloss: 0.241756	valid&#39;s auc: 0.772139
[1100]	valid&#39;s binary_logloss: 0.241958	valid&#39;s auc: 0.771998
Early stopping, best iteration is:
[608]	valid&#39;s binary_logloss: 0.240909	valid&#39;s auc: 0.774497
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248419	valid&#39;s auc: 0.763585
[200]	valid&#39;s binary_logloss: 0.242521	valid&#39;s auc: 0.772484
[300]	valid&#39;s binary_logloss: 0.240662	valid&#39;s auc: 0.775984
[400]	valid&#39;s binary_logloss: 0.239938	valid&#39;s auc: 0.777234
[500]	valid&#39;s binary_logloss: 0.239516	valid&#39;s auc: 0.778271
[600]	valid&#39;s binary_logloss: 0.23942	valid&#39;s auc: 0.778351
[700]	valid&#39;s binary_logloss: 0.239346	valid&#39;s auc: 0.778585
[800]	valid&#39;s binary_logloss: 0.239343	valid&#39;s auc: 0.778405
[900]	valid&#39;s binary_logloss: 0.239506	valid&#39;s auc: 0.777875
[1000]	valid&#39;s binary_logloss: 0.239531	valid&#39;s auc: 0.777779
[1100]	valid&#39;s binary_logloss: 0.239644	valid&#39;s auc: 0.777415
[1200]	valid&#39;s binary_logloss: 0.239794	valid&#39;s auc: 0.776924
Early stopping, best iteration is:
[750]	valid&#39;s binary_logloss: 0.239287	valid&#39;s auc: 0.778637
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248516	valid&#39;s auc: 0.763811
[200]	valid&#39;s binary_logloss: 0.242782	valid&#39;s auc: 0.772671
[300]	valid&#39;s binary_logloss: 0.240959	valid&#39;s auc: 0.77595
[400]	valid&#39;s binary_logloss: 0.240221	valid&#39;s auc: 0.777251
[500]	valid&#39;s binary_logloss: 0.239995	valid&#39;s auc: 0.777553
[600]	valid&#39;s binary_logloss: 0.23986	valid&#39;s auc: 0.777752
[700]	valid&#39;s binary_logloss: 0.239718	valid&#39;s auc: 0.778292
[800]	valid&#39;s binary_logloss: 0.239803	valid&#39;s auc: 0.778066
[900]	valid&#39;s binary_logloss: 0.239852	valid&#39;s auc: 0.777976
[1000]	valid&#39;s binary_logloss: 0.239912	valid&#39;s auc: 0.778024
[1100]	valid&#39;s binary_logloss: 0.240019	valid&#39;s auc: 0.777689
[1200]	valid&#39;s binary_logloss: 0.24019	valid&#39;s auc: 0.777251
Early stopping, best iteration is:
[719]	valid&#39;s binary_logloss: 0.239685	valid&#39;s auc: 0.778443
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248448	valid&#39;s auc: 0.764047
[200]	valid&#39;s binary_logloss: 0.242706	valid&#39;s auc: 0.771992
[300]	valid&#39;s binary_logloss: 0.240897	valid&#39;s auc: 0.775385
[400]	valid&#39;s binary_logloss: 0.240165	valid&#39;s auc: 0.77649
[500]	valid&#39;s binary_logloss: 0.239744	valid&#39;s auc: 0.777448
[600]	valid&#39;s binary_logloss: 0.239613	valid&#39;s auc: 0.777794
[700]	valid&#39;s binary_logloss: 0.239475	valid&#39;s auc: 0.778053
[800]	valid&#39;s binary_logloss: 0.239534	valid&#39;s auc: 0.777774
[900]	valid&#39;s binary_logloss: 0.23966	valid&#39;s auc: 0.777233
[1000]	valid&#39;s binary_logloss: 0.239753	valid&#39;s auc: 0.776961
[1100]	valid&#39;s binary_logloss: 0.239792	valid&#39;s auc: 0.776952
[1200]	valid&#39;s binary_logloss: 0.239908	valid&#39;s auc: 0.776716
Early stopping, best iteration is:
[721]	valid&#39;s binary_logloss: 0.239448	valid&#39;s auc: 0.77809
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248568	valid&#39;s auc: 0.763711
[200]	valid&#39;s binary_logloss: 0.242846	valid&#39;s auc: 0.772192
[300]	valid&#39;s binary_logloss: 0.241011	valid&#39;s auc: 0.775604
[400]	valid&#39;s binary_logloss: 0.240338	valid&#39;s auc: 0.776732
[500]	valid&#39;s binary_logloss: 0.240134	valid&#39;s auc: 0.776963
[600]	valid&#39;s binary_logloss: 0.240135	valid&#39;s auc: 0.77674
[700]	valid&#39;s binary_logloss: 0.240054	valid&#39;s auc: 0.776906
[800]	valid&#39;s binary_logloss: 0.240042	valid&#39;s auc: 0.776825
[900]	valid&#39;s binary_logloss: 0.240059	valid&#39;s auc: 0.776939
Early stopping, best iteration is:
[448]	valid&#39;s binary_logloss: 0.240174	valid&#39;s auc: 0.777126
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248233	valid&#39;s auc: 0.764525
[200]	valid&#39;s binary_logloss: 0.242486	valid&#39;s auc: 0.773124
[300]	valid&#39;s binary_logloss: 0.24068	valid&#39;s auc: 0.77651
[400]	valid&#39;s binary_logloss: 0.239997	valid&#39;s auc: 0.777563
[500]	valid&#39;s binary_logloss: 0.239691	valid&#39;s auc: 0.778209
[600]	valid&#39;s binary_logloss: 0.239642	valid&#39;s auc: 0.778234
[700]	valid&#39;s binary_logloss: 0.239675	valid&#39;s auc: 0.778043
[800]	valid&#39;s binary_logloss: 0.239766	valid&#39;s auc: 0.777776
[900]	valid&#39;s binary_logloss: 0.239915	valid&#39;s auc: 0.77724
[1000]	valid&#39;s binary_logloss: 0.240052	valid&#39;s auc: 0.776734
[1100]	valid&#39;s binary_logloss: 0.240148	valid&#39;s auc: 0.776412
Early stopping, best iteration is:
[627]	valid&#39;s binary_logloss: 0.239555	valid&#39;s auc: 0.778486
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.242109	valid&#39;s auc: 0.772137
[200]	valid&#39;s binary_logloss: 0.240245	valid&#39;s auc: 0.776383
[300]	valid&#39;s binary_logloss: 0.24035	valid&#39;s auc: 0.775857
[400]	valid&#39;s binary_logloss: 0.240802	valid&#39;s auc: 0.774643
[500]	valid&#39;s binary_logloss: 0.241315	valid&#39;s auc: 0.772814
[600]	valid&#39;s binary_logloss: 0.241705	valid&#39;s auc: 0.772167
Early stopping, best iteration is:
[181]	valid&#39;s binary_logloss: 0.240249	valid&#39;s auc: 0.776572
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.241629	valid&#39;s auc: 0.773589
[200]	valid&#39;s binary_logloss: 0.239802	valid&#39;s auc: 0.777077
[300]	valid&#39;s binary_logloss: 0.239696	valid&#39;s auc: 0.777066
[400]	valid&#39;s binary_logloss: 0.239998	valid&#39;s auc: 0.776241
[500]	valid&#39;s binary_logloss: 0.240339	valid&#39;s auc: 0.77511
[600]	valid&#39;s binary_logloss: 0.240782	valid&#39;s auc: 0.773864
[700]	valid&#39;s binary_logloss: 0.241243	valid&#39;s auc: 0.772928
Early stopping, best iteration is:
[245]	valid&#39;s binary_logloss: 0.239597	valid&#39;s auc: 0.777502
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.242077	valid&#39;s auc: 0.771804
[200]	valid&#39;s binary_logloss: 0.240793	valid&#39;s auc: 0.773464
[300]	valid&#39;s binary_logloss: 0.24051	valid&#39;s auc: 0.77413
[400]	valid&#39;s binary_logloss: 0.240818	valid&#39;s auc: 0.773141
[500]	valid&#39;s binary_logloss: 0.24104	valid&#39;s auc: 0.772394
[600]	valid&#39;s binary_logloss: 0.241353	valid&#39;s auc: 0.771958
[700]	valid&#39;s binary_logloss: 0.241597	valid&#39;s auc: 0.771383
Early stopping, best iteration is:
[265]	valid&#39;s binary_logloss: 0.24044	valid&#39;s auc: 0.774476
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.242385	valid&#39;s auc: 0.771956
[200]	valid&#39;s binary_logloss: 0.240629	valid&#39;s auc: 0.775466
[300]	valid&#39;s binary_logloss: 0.240427	valid&#39;s auc: 0.775811
[400]	valid&#39;s binary_logloss: 0.240803	valid&#39;s auc: 0.774666
[500]	valid&#39;s binary_logloss: 0.240973	valid&#39;s auc: 0.774303
[600]	valid&#39;s binary_logloss: 0.241455	valid&#39;s auc: 0.773141
[700]	valid&#39;s binary_logloss: 0.241886	valid&#39;s auc: 0.772036
Early stopping, best iteration is:
[266]	valid&#39;s binary_logloss: 0.240358	valid&#39;s auc: 0.775968
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.242064	valid&#39;s auc: 0.772412
[200]	valid&#39;s binary_logloss: 0.240345	valid&#39;s auc: 0.776422
[300]	valid&#39;s binary_logloss: 0.240304	valid&#39;s auc: 0.776246
[400]	valid&#39;s binary_logloss: 0.240602	valid&#39;s auc: 0.775283
[500]	valid&#39;s binary_logloss: 0.241142	valid&#39;s auc: 0.773815
[600]	valid&#39;s binary_logloss: 0.241375	valid&#39;s auc: 0.77332
[700]	valid&#39;s binary_logloss: 0.241661	valid&#39;s auc: 0.77277
Early stopping, best iteration is:
[236]	valid&#39;s binary_logloss: 0.240279	valid&#39;s auc: 0.776522
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.249884	valid&#39;s auc: 0.760713
[200]	valid&#39;s binary_logloss: 0.244014	valid&#39;s auc: 0.769723
[300]	valid&#39;s binary_logloss: 0.24138	valid&#39;s auc: 0.774365
[400]	valid&#39;s binary_logloss: 0.240317	valid&#39;s auc: 0.776434
[500]	valid&#39;s binary_logloss: 0.239827	valid&#39;s auc: 0.777246
[600]	valid&#39;s binary_logloss: 0.239578	valid&#39;s auc: 0.777831
[700]	valid&#39;s binary_logloss: 0.239402	valid&#39;s auc: 0.7781
[800]	valid&#39;s binary_logloss: 0.239313	valid&#39;s auc: 0.778289
[900]	valid&#39;s binary_logloss: 0.239356	valid&#39;s auc: 0.778172
[1000]	valid&#39;s binary_logloss: 0.239395	valid&#39;s auc: 0.777979
[1100]	valid&#39;s binary_logloss: 0.239423	valid&#39;s auc: 0.777926
[1200]	valid&#39;s binary_logloss: 0.239522	valid&#39;s auc: 0.777603
Early stopping, best iteration is:
[776]	valid&#39;s binary_logloss: 0.239291	valid&#39;s auc: 0.778423
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.249786	valid&#39;s auc: 0.761493
[200]	valid&#39;s binary_logloss: 0.24403	valid&#39;s auc: 0.770271
[300]	valid&#39;s binary_logloss: 0.241526	valid&#39;s auc: 0.774882
[400]	valid&#39;s binary_logloss: 0.240591	valid&#39;s auc: 0.776536
[500]	valid&#39;s binary_logloss: 0.240124	valid&#39;s auc: 0.777353
[600]	valid&#39;s binary_logloss: 0.239809	valid&#39;s auc: 0.778039
[700]	valid&#39;s binary_logloss: 0.239796	valid&#39;s auc: 0.777783
[800]	valid&#39;s binary_logloss: 0.239681	valid&#39;s auc: 0.777986
[900]	valid&#39;s binary_logloss: 0.239706	valid&#39;s auc: 0.777859
[1000]	valid&#39;s binary_logloss: 0.239756	valid&#39;s auc: 0.777729
[1100]	valid&#39;s binary_logloss: 0.239822	valid&#39;s auc: 0.777538
[1200]	valid&#39;s binary_logloss: 0.239972	valid&#39;s auc: 0.777198
[1300]	valid&#39;s binary_logloss: 0.240057	valid&#39;s auc: 0.776989
Early stopping, best iteration is:
[822]	valid&#39;s binary_logloss: 0.239655	valid&#39;s auc: 0.778033
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.249745	valid&#39;s auc: 0.762679
[200]	valid&#39;s binary_logloss: 0.243925	valid&#39;s auc: 0.770934
[300]	valid&#39;s binary_logloss: 0.241408	valid&#39;s auc: 0.775113
[400]	valid&#39;s binary_logloss: 0.240422	valid&#39;s auc: 0.776918
[500]	valid&#39;s binary_logloss: 0.240007	valid&#39;s auc: 0.777593
[600]	valid&#39;s binary_logloss: 0.239739	valid&#39;s auc: 0.77796
[700]	valid&#39;s binary_logloss: 0.239709	valid&#39;s auc: 0.777847
[800]	valid&#39;s binary_logloss: 0.239637	valid&#39;s auc: 0.777955
[900]	valid&#39;s binary_logloss: 0.239581	valid&#39;s auc: 0.778159
[1000]	valid&#39;s binary_logloss: 0.239604	valid&#39;s auc: 0.778188
[1100]	valid&#39;s binary_logloss: 0.239656	valid&#39;s auc: 0.777907
[1200]	valid&#39;s binary_logloss: 0.239804	valid&#39;s auc: 0.777546
[1300]	valid&#39;s binary_logloss: 0.239819	valid&#39;s auc: 0.777559
Early stopping, best iteration is:
[874]	valid&#39;s binary_logloss: 0.239524	valid&#39;s auc: 0.778266
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.249965	valid&#39;s auc: 0.761261
[200]	valid&#39;s binary_logloss: 0.244175	valid&#39;s auc: 0.770348
[300]	valid&#39;s binary_logloss: 0.241782	valid&#39;s auc: 0.774295
[400]	valid&#39;s binary_logloss: 0.240804	valid&#39;s auc: 0.776213
[500]	valid&#39;s binary_logloss: 0.240445	valid&#39;s auc: 0.776528
[600]	valid&#39;s binary_logloss: 0.240239	valid&#39;s auc: 0.776968
[700]	valid&#39;s binary_logloss: 0.240185	valid&#39;s auc: 0.776887
[800]	valid&#39;s binary_logloss: 0.240078	valid&#39;s auc: 0.777173
[900]	valid&#39;s binary_logloss: 0.240054	valid&#39;s auc: 0.77751
[1000]	valid&#39;s binary_logloss: 0.240075	valid&#39;s auc: 0.777367
[1100]	valid&#39;s binary_logloss: 0.24016	valid&#39;s auc: 0.77696
[1200]	valid&#39;s binary_logloss: 0.24037	valid&#39;s auc: 0.776322
[1300]	valid&#39;s binary_logloss: 0.240498	valid&#39;s auc: 0.776026
[1400]	valid&#39;s binary_logloss: 0.240568	valid&#39;s auc: 0.77593
Early stopping, best iteration is:
[907]	valid&#39;s binary_logloss: 0.240017	valid&#39;s auc: 0.777605
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.251383	valid&#39;s auc: 0.757403
[200]	valid&#39;s binary_logloss: 0.244906	valid&#39;s auc: 0.768125
[300]	valid&#39;s binary_logloss: 0.242037	valid&#39;s auc: 0.773861
[400]	valid&#39;s binary_logloss: 0.24078	valid&#39;s auc: 0.77609
[500]	valid&#39;s binary_logloss: 0.240072	valid&#39;s auc: 0.777538
[600]	valid&#39;s binary_logloss: 0.239704	valid&#39;s auc: 0.778281
[700]	valid&#39;s binary_logloss: 0.239565	valid&#39;s auc: 0.778532
[800]	valid&#39;s binary_logloss: 0.239673	valid&#39;s auc: 0.778014
[900]	valid&#39;s binary_logloss: 0.23966	valid&#39;s auc: 0.778013
[1000]	valid&#39;s binary_logloss: 0.239738	valid&#39;s auc: 0.7778
[1100]	valid&#39;s binary_logloss: 0.239843	valid&#39;s auc: 0.777572
Early stopping, best iteration is:
[644]	valid&#39;s binary_logloss: 0.239623	valid&#39;s auc: 0.778569
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.245588	valid&#39;s auc: 0.766641
[200]	valid&#39;s binary_logloss: 0.242049	valid&#39;s auc: 0.772576
[300]	valid&#39;s binary_logloss: 0.240968	valid&#39;s auc: 0.774388
[400]	valid&#39;s binary_logloss: 0.240544	valid&#39;s auc: 0.775158
[500]	valid&#39;s binary_logloss: 0.240504	valid&#39;s auc: 0.775098
[600]	valid&#39;s binary_logloss: 0.24048	valid&#39;s auc: 0.775171
[700]	valid&#39;s binary_logloss: 0.240546	valid&#39;s auc: 0.775108
[800]	valid&#39;s binary_logloss: 0.24073	valid&#39;s auc: 0.774605
[900]	valid&#39;s binary_logloss: 0.241056	valid&#39;s auc: 0.773687
[1000]	valid&#39;s binary_logloss: 0.241277	valid&#39;s auc: 0.773139
Early stopping, best iteration is:
[527]	valid&#39;s binary_logloss: 0.240315	valid&#39;s auc: 0.775637
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.246967	valid&#39;s auc: 0.761762
[200]	valid&#39;s binary_logloss: 0.242216	valid&#39;s auc: 0.772997
[300]	valid&#39;s binary_logloss: 0.24088	valid&#39;s auc: 0.775446
[400]	valid&#39;s binary_logloss: 0.240424	valid&#39;s auc: 0.776075
[500]	valid&#39;s binary_logloss: 0.240376	valid&#39;s auc: 0.776187
[600]	valid&#39;s binary_logloss: 0.240535	valid&#39;s auc: 0.775989
[700]	valid&#39;s binary_logloss: 0.240651	valid&#39;s auc: 0.775705
[800]	valid&#39;s binary_logloss: 0.240854	valid&#39;s auc: 0.774842
[900]	valid&#39;s binary_logloss: 0.240798	valid&#39;s auc: 0.775088
Early stopping, best iteration is:
[438]	valid&#39;s binary_logloss: 0.240288	valid&#39;s auc: 0.776523
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.246744	valid&#39;s auc: 0.761816
[200]	valid&#39;s binary_logloss: 0.242092	valid&#39;s auc: 0.772315
[300]	valid&#39;s binary_logloss: 0.240579	valid&#39;s auc: 0.775563
[400]	valid&#39;s binary_logloss: 0.240099	valid&#39;s auc: 0.776607
[500]	valid&#39;s binary_logloss: 0.240074	valid&#39;s auc: 0.776464
[600]	valid&#39;s binary_logloss: 0.240218	valid&#39;s auc: 0.776091
[700]	valid&#39;s binary_logloss: 0.240433	valid&#39;s auc: 0.775289
[800]	valid&#39;s binary_logloss: 0.240635	valid&#39;s auc: 0.774744
Early stopping, best iteration is:
[391]	valid&#39;s binary_logloss: 0.240071	valid&#39;s auc: 0.77672
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.247039	valid&#39;s auc: 0.760821
[200]	valid&#39;s binary_logloss: 0.242328	valid&#39;s auc: 0.771964
[300]	valid&#39;s binary_logloss: 0.241024	valid&#39;s auc: 0.774168
[400]	valid&#39;s binary_logloss: 0.240708	valid&#39;s auc: 0.774731
[500]	valid&#39;s binary_logloss: 0.240623	valid&#39;s auc: 0.774704
[600]	valid&#39;s binary_logloss: 0.240748	valid&#39;s auc: 0.774461
[700]	valid&#39;s binary_logloss: 0.240991	valid&#39;s auc: 0.773951
[800]	valid&#39;s binary_logloss: 0.241195	valid&#39;s auc: 0.773502
Early stopping, best iteration is:
[379]	valid&#39;s binary_logloss: 0.240651	valid&#39;s auc: 0.775056
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.246765	valid&#39;s auc: 0.762001
[200]	valid&#39;s binary_logloss: 0.241931	valid&#39;s auc: 0.772908
[300]	valid&#39;s binary_logloss: 0.240694	valid&#39;s auc: 0.775354
[400]	valid&#39;s binary_logloss: 0.240268	valid&#39;s auc: 0.776112
[500]	valid&#39;s binary_logloss: 0.240227	valid&#39;s auc: 0.776146
[600]	valid&#39;s binary_logloss: 0.240216	valid&#39;s auc: 0.776178
[700]	valid&#39;s binary_logloss: 0.240284	valid&#39;s auc: 0.776115
[800]	valid&#39;s binary_logloss: 0.240434	valid&#39;s auc: 0.775708
[900]	valid&#39;s binary_logloss: 0.240669	valid&#39;s auc: 0.775011
[1000]	valid&#39;s binary_logloss: 0.240917	valid&#39;s auc: 0.774367
Early stopping, best iteration is:
[565]	valid&#39;s binary_logloss: 0.240118	valid&#39;s auc: 0.776513
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.243572	valid&#39;s auc: 0.770257
[200]	valid&#39;s binary_logloss: 0.240789	valid&#39;s auc: 0.774895
[300]	valid&#39;s binary_logloss: 0.240157	valid&#39;s auc: 0.776277
[400]	valid&#39;s binary_logloss: 0.240176	valid&#39;s auc: 0.775543
[500]	valid&#39;s binary_logloss: 0.240235	valid&#39;s auc: 0.775245
[600]	valid&#39;s binary_logloss: 0.240696	valid&#39;s auc: 0.774152
[700]	valid&#39;s binary_logloss: 0.24082	valid&#39;s auc: 0.773634
Early stopping, best iteration is:
[282]	valid&#39;s binary_logloss: 0.240104	valid&#39;s auc: 0.77642
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.243579	valid&#39;s auc: 0.77107
[200]	valid&#39;s binary_logloss: 0.24096	valid&#39;s auc: 0.77565
[300]	valid&#39;s binary_logloss: 0.240414	valid&#39;s auc: 0.776701
[400]	valid&#39;s binary_logloss: 0.240334	valid&#39;s auc: 0.776652
[500]	valid&#39;s binary_logloss: 0.240435	valid&#39;s auc: 0.776456
[600]	valid&#39;s binary_logloss: 0.240652	valid&#39;s auc: 0.775954
[700]	valid&#39;s binary_logloss: 0.241045	valid&#39;s auc: 0.774937
[800]	valid&#39;s binary_logloss: 0.241316	valid&#39;s auc: 0.774181
Early stopping, best iteration is:
[307]	valid&#39;s binary_logloss: 0.24033	valid&#39;s auc: 0.77694
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.243727	valid&#39;s auc: 0.769293
[200]	valid&#39;s binary_logloss: 0.240764	valid&#39;s auc: 0.774682
[300]	valid&#39;s binary_logloss: 0.240177	valid&#39;s auc: 0.775785
[400]	valid&#39;s binary_logloss: 0.24015	valid&#39;s auc: 0.775811
[500]	valid&#39;s binary_logloss: 0.240197	valid&#39;s auc: 0.775871
[600]	valid&#39;s binary_logloss: 0.240454	valid&#39;s auc: 0.774978
[700]	valid&#39;s binary_logloss: 0.240693	valid&#39;s auc: 0.774478
[800]	valid&#39;s binary_logloss: 0.241039	valid&#39;s auc: 0.773716
Early stopping, best iteration is:
[360]	valid&#39;s binary_logloss: 0.24003	valid&#39;s auc: 0.776185
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.243773	valid&#39;s auc: 0.770013
[200]	valid&#39;s binary_logloss: 0.240889	valid&#39;s auc: 0.774673
[300]	valid&#39;s binary_logloss: 0.240404	valid&#39;s auc: 0.775449
[400]	valid&#39;s binary_logloss: 0.24049	valid&#39;s auc: 0.774834
[500]	valid&#39;s binary_logloss: 0.240579	valid&#39;s auc: 0.774508
[600]	valid&#39;s binary_logloss: 0.240757	valid&#39;s auc: 0.774137
[700]	valid&#39;s binary_logloss: 0.241228	valid&#39;s auc: 0.772896
Early stopping, best iteration is:
[267]	valid&#39;s binary_logloss: 0.240417	valid&#39;s auc: 0.775589
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.244433	valid&#39;s auc: 0.768767
[200]	valid&#39;s binary_logloss: 0.240581	valid&#39;s auc: 0.776669
[300]	valid&#39;s binary_logloss: 0.240055	valid&#39;s auc: 0.777333
[400]	valid&#39;s binary_logloss: 0.240072	valid&#39;s auc: 0.776806
[500]	valid&#39;s binary_logloss: 0.240083	valid&#39;s auc: 0.776694
[600]	valid&#39;s binary_logloss: 0.240503	valid&#39;s auc: 0.775481
[700]	valid&#39;s binary_logloss: 0.24071	valid&#39;s auc: 0.774994
Early stopping, best iteration is:
[273]	valid&#39;s binary_logloss: 0.240054	valid&#39;s auc: 0.777717
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248599	valid&#39;s auc: 0.76361
[200]	valid&#39;s binary_logloss: 0.243123	valid&#39;s auc: 0.771425
[300]	valid&#39;s binary_logloss: 0.240964	valid&#39;s auc: 0.77522
[400]	valid&#39;s binary_logloss: 0.240004	valid&#39;s auc: 0.777136
[500]	valid&#39;s binary_logloss: 0.23974	valid&#39;s auc: 0.777422
[600]	valid&#39;s binary_logloss: 0.239598	valid&#39;s auc: 0.777571
[700]	valid&#39;s binary_logloss: 0.239465	valid&#39;s auc: 0.777764
[800]	valid&#39;s binary_logloss: 0.239479	valid&#39;s auc: 0.777574
[900]	valid&#39;s binary_logloss: 0.239561	valid&#39;s auc: 0.777184
[1000]	valid&#39;s binary_logloss: 0.239615	valid&#39;s auc: 0.777169
[1100]	valid&#39;s binary_logloss: 0.239624	valid&#39;s auc: 0.777194
[1200]	valid&#39;s binary_logloss: 0.239684	valid&#39;s auc: 0.777093
Early stopping, best iteration is:
[708]	valid&#39;s binary_logloss: 0.239455	valid&#39;s auc: 0.777789
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248719	valid&#39;s auc: 0.763368
[200]	valid&#39;s binary_logloss: 0.243339	valid&#39;s auc: 0.771571
[300]	valid&#39;s binary_logloss: 0.241054	valid&#39;s auc: 0.775682
[400]	valid&#39;s binary_logloss: 0.240178	valid&#39;s auc: 0.77747
[500]	valid&#39;s binary_logloss: 0.239743	valid&#39;s auc: 0.778412
[600]	valid&#39;s binary_logloss: 0.239603	valid&#39;s auc: 0.778687
[700]	valid&#39;s binary_logloss: 0.239487	valid&#39;s auc: 0.778876
[800]	valid&#39;s binary_logloss: 0.239456	valid&#39;s auc: 0.77879
[900]	valid&#39;s binary_logloss: 0.23946	valid&#39;s auc: 0.778595
[1000]	valid&#39;s binary_logloss: 0.239462	valid&#39;s auc: 0.77852
[1100]	valid&#39;s binary_logloss: 0.239593	valid&#39;s auc: 0.778224
[1200]	valid&#39;s binary_logloss: 0.239603	valid&#39;s auc: 0.778297
Early stopping, best iteration is:
[711]	valid&#39;s binary_logloss: 0.239457	valid&#39;s auc: 0.778948
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248629	valid&#39;s auc: 0.76368
[200]	valid&#39;s binary_logloss: 0.243283	valid&#39;s auc: 0.770736
[300]	valid&#39;s binary_logloss: 0.241187	valid&#39;s auc: 0.774326
[400]	valid&#39;s binary_logloss: 0.240311	valid&#39;s auc: 0.776245
[500]	valid&#39;s binary_logloss: 0.240011	valid&#39;s auc: 0.776472
[600]	valid&#39;s binary_logloss: 0.239876	valid&#39;s auc: 0.776605
[700]	valid&#39;s binary_logloss: 0.239789	valid&#39;s auc: 0.776727
[800]	valid&#39;s binary_logloss: 0.239777	valid&#39;s auc: 0.776668
[900]	valid&#39;s binary_logloss: 0.239834	valid&#39;s auc: 0.776571
[1000]	valid&#39;s binary_logloss: 0.239982	valid&#39;s auc: 0.776132
[1100]	valid&#39;s binary_logloss: 0.240017	valid&#39;s auc: 0.776058
Early stopping, best iteration is:
[687]	valid&#39;s binary_logloss: 0.239762	valid&#39;s auc: 0.776856
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.24876	valid&#39;s auc: 0.763746
[200]	valid&#39;s binary_logloss: 0.243482	valid&#39;s auc: 0.771031
[300]	valid&#39;s binary_logloss: 0.241142	valid&#39;s auc: 0.775442
[400]	valid&#39;s binary_logloss: 0.24028	valid&#39;s auc: 0.777181
[500]	valid&#39;s binary_logloss: 0.239937	valid&#39;s auc: 0.777671
[600]	valid&#39;s binary_logloss: 0.239751	valid&#39;s auc: 0.778027
[700]	valid&#39;s binary_logloss: 0.239752	valid&#39;s auc: 0.777975
[800]	valid&#39;s binary_logloss: 0.239825	valid&#39;s auc: 0.77791
[900]	valid&#39;s binary_logloss: 0.239857	valid&#39;s auc: 0.777802
[1000]	valid&#39;s binary_logloss: 0.239857	valid&#39;s auc: 0.777786
Early stopping, best iteration is:
[571]	valid&#39;s binary_logloss: 0.239717	valid&#39;s auc: 0.778256
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248405	valid&#39;s auc: 0.764039
[200]	valid&#39;s binary_logloss: 0.24314	valid&#39;s auc: 0.771366
[300]	valid&#39;s binary_logloss: 0.240982	valid&#39;s auc: 0.775209
[400]	valid&#39;s binary_logloss: 0.24017	valid&#39;s auc: 0.776831
[500]	valid&#39;s binary_logloss: 0.239979	valid&#39;s auc: 0.777037
[600]	valid&#39;s binary_logloss: 0.239762	valid&#39;s auc: 0.777569
[700]	valid&#39;s binary_logloss: 0.239733	valid&#39;s auc: 0.777573
[800]	valid&#39;s binary_logloss: 0.23967	valid&#39;s auc: 0.777672
[900]	valid&#39;s binary_logloss: 0.239792	valid&#39;s auc: 0.777313
[1000]	valid&#39;s binary_logloss: 0.239781	valid&#39;s auc: 0.777311
Early stopping, best iteration is:
[578]	valid&#39;s binary_logloss: 0.239709	valid&#39;s auc: 0.777728
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.244662	valid&#39;s auc: 0.766532
[200]	valid&#39;s binary_logloss: 0.241869	valid&#39;s auc: 0.772067
[300]	valid&#39;s binary_logloss: 0.240899	valid&#39;s auc: 0.77393
[400]	valid&#39;s binary_logloss: 0.24087	valid&#39;s auc: 0.773606
[500]	valid&#39;s binary_logloss: 0.241168	valid&#39;s auc: 0.772505
[600]	valid&#39;s binary_logloss: 0.241366	valid&#39;s auc: 0.771911
[700]	valid&#39;s binary_logloss: 0.241559	valid&#39;s auc: 0.77135
[800]	valid&#39;s binary_logloss: 0.241797	valid&#39;s auc: 0.770753
Early stopping, best iteration is:
[307]	valid&#39;s binary_logloss: 0.240828	valid&#39;s auc: 0.774147
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.244777	valid&#39;s auc: 0.76654
[200]	valid&#39;s binary_logloss: 0.241929	valid&#39;s auc: 0.772139
[300]	valid&#39;s binary_logloss: 0.240921	valid&#39;s auc: 0.774248
[400]	valid&#39;s binary_logloss: 0.240724	valid&#39;s auc: 0.774797
[500]	valid&#39;s binary_logloss: 0.2408	valid&#39;s auc: 0.774602
[600]	valid&#39;s binary_logloss: 0.241117	valid&#39;s auc: 0.773465
[700]	valid&#39;s binary_logloss: 0.241397	valid&#39;s auc: 0.772935
[800]	valid&#39;s binary_logloss: 0.241778	valid&#39;s auc: 0.772374
[900]	valid&#39;s binary_logloss: 0.242203	valid&#39;s auc: 0.771207
Early stopping, best iteration is:
[427]	valid&#39;s binary_logloss: 0.240692	valid&#39;s auc: 0.774988
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.244442	valid&#39;s auc: 0.76867
[200]	valid&#39;s binary_logloss: 0.24114	valid&#39;s auc: 0.774617
[300]	valid&#39;s binary_logloss: 0.240184	valid&#39;s auc: 0.776164
[400]	valid&#39;s binary_logloss: 0.240088	valid&#39;s auc: 0.776043
[500]	valid&#39;s binary_logloss: 0.240088	valid&#39;s auc: 0.77576
[600]	valid&#39;s binary_logloss: 0.240314	valid&#39;s auc: 0.775265
[700]	valid&#39;s binary_logloss: 0.240774	valid&#39;s auc: 0.774
[800]	valid&#39;s binary_logloss: 0.241208	valid&#39;s auc: 0.772592
Early stopping, best iteration is:
[318]	valid&#39;s binary_logloss: 0.240036	valid&#39;s auc: 0.776574
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.244911	valid&#39;s auc: 0.766705
[200]	valid&#39;s binary_logloss: 0.241884	valid&#39;s auc: 0.773229
[300]	valid&#39;s binary_logloss: 0.240958	valid&#39;s auc: 0.774712
[400]	valid&#39;s binary_logloss: 0.240773	valid&#39;s auc: 0.774927
[500]	valid&#39;s binary_logloss: 0.2409	valid&#39;s auc: 0.774296
[600]	valid&#39;s binary_logloss: 0.241224	valid&#39;s auc: 0.773106
[700]	valid&#39;s binary_logloss: 0.241578	valid&#39;s auc: 0.772154
[800]	valid&#39;s binary_logloss: 0.242055	valid&#39;s auc: 0.771087
[900]	valid&#39;s binary_logloss: 0.242471	valid&#39;s auc: 0.77039
Early stopping, best iteration is:
[423]	valid&#39;s binary_logloss: 0.240672	valid&#39;s auc: 0.775192
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.244502	valid&#39;s auc: 0.767897
[200]	valid&#39;s binary_logloss: 0.241569	valid&#39;s auc: 0.773756
[300]	valid&#39;s binary_logloss: 0.240648	valid&#39;s auc: 0.775307
[400]	valid&#39;s binary_logloss: 0.240737	valid&#39;s auc: 0.774655
[500]	valid&#39;s binary_logloss: 0.240828	valid&#39;s auc: 0.774232
[600]	valid&#39;s binary_logloss: 0.241303	valid&#39;s auc: 0.77303
[700]	valid&#39;s binary_logloss: 0.241618	valid&#39;s auc: 0.772145
[800]	valid&#39;s binary_logloss: 0.241986	valid&#39;s auc: 0.77135
Early stopping, best iteration is:
[315]	valid&#39;s binary_logloss: 0.240525	valid&#39;s auc: 0.775627
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.253646	valid&#39;s auc: 0.754782
[200]	valid&#39;s binary_logloss: 0.246081	valid&#39;s auc: 0.766137
[300]	valid&#39;s binary_logloss: 0.243014	valid&#39;s auc: 0.77129
[400]	valid&#39;s binary_logloss: 0.241332	valid&#39;s auc: 0.774429
[500]	valid&#39;s binary_logloss: 0.240491	valid&#39;s auc: 0.776168
[600]	valid&#39;s binary_logloss: 0.240016	valid&#39;s auc: 0.777255
[700]	valid&#39;s binary_logloss: 0.239766	valid&#39;s auc: 0.777574
[800]	valid&#39;s binary_logloss: 0.239606	valid&#39;s auc: 0.778024
[900]	valid&#39;s binary_logloss: 0.239545	valid&#39;s auc: 0.777995
[1000]	valid&#39;s binary_logloss: 0.239504	valid&#39;s auc: 0.777944
[1100]	valid&#39;s binary_logloss: 0.239485	valid&#39;s auc: 0.77798
[1200]	valid&#39;s binary_logloss: 0.239484	valid&#39;s auc: 0.777877
[1300]	valid&#39;s binary_logloss: 0.239537	valid&#39;s auc: 0.777676
Early stopping, best iteration is:
[860]	valid&#39;s binary_logloss: 0.239542	valid&#39;s auc: 0.778127
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.253151	valid&#39;s auc: 0.755766
[200]	valid&#39;s binary_logloss: 0.246504	valid&#39;s auc: 0.766366
[300]	valid&#39;s binary_logloss: 0.243314	valid&#39;s auc: 0.772148
[400]	valid&#39;s binary_logloss: 0.241505	valid&#39;s auc: 0.775349
[500]	valid&#39;s binary_logloss: 0.240509	valid&#39;s auc: 0.777112
[600]	valid&#39;s binary_logloss: 0.240027	valid&#39;s auc: 0.777885
[700]	valid&#39;s binary_logloss: 0.239739	valid&#39;s auc: 0.778496
[800]	valid&#39;s binary_logloss: 0.239604	valid&#39;s auc: 0.778662
[900]	valid&#39;s binary_logloss: 0.239592	valid&#39;s auc: 0.778482
[1000]	valid&#39;s binary_logloss: 0.239527	valid&#39;s auc: 0.778661
[1100]	valid&#39;s binary_logloss: 0.239562	valid&#39;s auc: 0.778478
[1200]	valid&#39;s binary_logloss: 0.239612	valid&#39;s auc: 0.778347
[1300]	valid&#39;s binary_logloss: 0.239552	valid&#39;s auc: 0.778473
[1400]	valid&#39;s binary_logloss: 0.23964	valid&#39;s auc: 0.778201
[1500]	valid&#39;s binary_logloss: 0.239704	valid&#39;s auc: 0.778073
Early stopping, best iteration is:
[1016]	valid&#39;s binary_logloss: 0.239502	valid&#39;s auc: 0.778752
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.253795	valid&#39;s auc: 0.75465
[200]	valid&#39;s binary_logloss: 0.246229	valid&#39;s auc: 0.765829
[300]	valid&#39;s binary_logloss: 0.243129	valid&#39;s auc: 0.771201
[400]	valid&#39;s binary_logloss: 0.241505	valid&#39;s auc: 0.774077
[500]	valid&#39;s binary_logloss: 0.240776	valid&#39;s auc: 0.775405
[600]	valid&#39;s binary_logloss: 0.240357	valid&#39;s auc: 0.776184
[700]	valid&#39;s binary_logloss: 0.240035	valid&#39;s auc: 0.776856
[800]	valid&#39;s binary_logloss: 0.23992	valid&#39;s auc: 0.777118
[900]	valid&#39;s binary_logloss: 0.239796	valid&#39;s auc: 0.77737
[1000]	valid&#39;s binary_logloss: 0.239751	valid&#39;s auc: 0.777318
[1100]	valid&#39;s binary_logloss: 0.23973	valid&#39;s auc: 0.777465
[1200]	valid&#39;s binary_logloss: 0.239689	valid&#39;s auc: 0.777645
[1300]	valid&#39;s binary_logloss: 0.239794	valid&#39;s auc: 0.777298
[1400]	valid&#39;s binary_logloss: 0.239819	valid&#39;s auc: 0.777298
[1500]	valid&#39;s binary_logloss: 0.239867	valid&#39;s auc: 0.777147
[1600]	valid&#39;s binary_logloss: 0.239892	valid&#39;s auc: 0.777004
Early stopping, best iteration is:
[1163]	valid&#39;s binary_logloss: 0.239683	valid&#39;s auc: 0.777674
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.253596	valid&#39;s auc: 0.754435
[200]	valid&#39;s binary_logloss: 0.246248	valid&#39;s auc: 0.765736
[300]	valid&#39;s binary_logloss: 0.243183	valid&#39;s auc: 0.771244
[400]	valid&#39;s binary_logloss: 0.241541	valid&#39;s auc: 0.774482
[500]	valid&#39;s binary_logloss: 0.240736	valid&#39;s auc: 0.776228
[600]	valid&#39;s binary_logloss: 0.240428	valid&#39;s auc: 0.776721
[700]	valid&#39;s binary_logloss: 0.240199	valid&#39;s auc: 0.777059
[800]	valid&#39;s binary_logloss: 0.240156	valid&#39;s auc: 0.777122
[900]	valid&#39;s binary_logloss: 0.240092	valid&#39;s auc: 0.777203
[1000]	valid&#39;s binary_logloss: 0.240085	valid&#39;s auc: 0.777102
[1100]	valid&#39;s binary_logloss: 0.2401	valid&#39;s auc: 0.776982
[1200]	valid&#39;s binary_logloss: 0.24018	valid&#39;s auc: 0.776838
[1300]	valid&#39;s binary_logloss: 0.240221	valid&#39;s auc: 0.776824
Early stopping, best iteration is:
[869]	valid&#39;s binary_logloss: 0.240078	valid&#39;s auc: 0.777315
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.253729	valid&#39;s auc: 0.754521
[200]	valid&#39;s binary_logloss: 0.246043	valid&#39;s auc: 0.766308
[300]	valid&#39;s binary_logloss: 0.24291	valid&#39;s auc: 0.771948
[400]	valid&#39;s binary_logloss: 0.241171	valid&#39;s auc: 0.775579
[500]	valid&#39;s binary_logloss: 0.240429	valid&#39;s auc: 0.777038
[600]	valid&#39;s binary_logloss: 0.240097	valid&#39;s auc: 0.777592
[700]	valid&#39;s binary_logloss: 0.239882	valid&#39;s auc: 0.778115
[800]	valid&#39;s binary_logloss: 0.23977	valid&#39;s auc: 0.778208
[900]	valid&#39;s binary_logloss: 0.239679	valid&#39;s auc: 0.778296
[1000]	valid&#39;s binary_logloss: 0.239604	valid&#39;s auc: 0.778442
[1100]	valid&#39;s binary_logloss: 0.239637	valid&#39;s auc: 0.778269
[1200]	valid&#39;s binary_logloss: 0.239662	valid&#39;s auc: 0.778062
[1300]	valid&#39;s binary_logloss: 0.23965	valid&#39;s auc: 0.778103
[1400]	valid&#39;s binary_logloss: 0.239725	valid&#39;s auc: 0.777911
[1500]	valid&#39;s binary_logloss: 0.239779	valid&#39;s auc: 0.777874
Early stopping, best iteration is:
[1000]	valid&#39;s binary_logloss: 0.239604	valid&#39;s auc: 0.778442
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 60.3min finished
C:\Users\stefanie\Anaconda3\lib\site-packages\lightgbm\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  warnings.warn(&#34;Found `{}` in params. Will use it instead of argument&#34;.format(alias))
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[100]	valid&#39;s binary_logloss: 0.248558	valid&#39;s auc: 0.764351
[200]	valid&#39;s binary_logloss: 0.243086	valid&#39;s auc: 0.772002
[300]	valid&#39;s binary_logloss: 0.240801	valid&#39;s auc: 0.776275
[400]	valid&#39;s binary_logloss: 0.239875	valid&#39;s auc: 0.778201
[500]	valid&#39;s binary_logloss: 0.239545	valid&#39;s auc: 0.778898
[600]	valid&#39;s binary_logloss: 0.239433	valid&#39;s auc: 0.778966
[700]	valid&#39;s binary_logloss: 0.239355	valid&#39;s auc: 0.779001
[800]	valid&#39;s binary_logloss: 0.239293	valid&#39;s auc: 0.779131
[900]	valid&#39;s binary_logloss: 0.239274	valid&#39;s auc: 0.779086
[1000]	valid&#39;s binary_logloss: 0.239308	valid&#39;s auc: 0.778852
[1100]	valid&#39;s binary_logloss: 0.239477	valid&#39;s auc: 0.778431
Early stopping, best iteration is:
[667]	valid&#39;s binary_logloss: 0.239292	valid&#39;s auc: 0.779229
Elapsed time: 3687.3838391304016 seconds
Wall time: 1h 1min 27s
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Support-vector-machine">Support vector machine<a class="anchor-link" href="#Support-vector-machine">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">num_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CNT_CHILDREN&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_INCOME_TOTAL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_CREDIT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_ANNUITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_GOODS_PRICE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_POPULATION_RELATIVE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_BIRTH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_EMPLOYED&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_REGISTRATION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_ID_PUBLISH&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OWN_CAR_AGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CNT_FAM_MEMBERS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUR_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EXT_SOURCE_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_AVG&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;APARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;BASEMENTAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BEGINEXPLUATATION_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;YEARS_BUILD_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;COMMONAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ELEVATORS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ENTRANCES_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMAX_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLOORSMIN_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LANDAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAPARTMENTS_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NONLIVINGAREA_MEDI&#39;</span><span class="p">,</span>
 <span class="s1">&#39;TOTALAREA_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;DAYS_LAST_PHONE_CHANGE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_MON&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_approved_prev_appl&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;no_of_loans&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ave_creditLimit&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_creditLimit_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;utilization_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;payment_ratio_CC&#39;</span><span class="p">,</span>
 <span class="s1">&#39;past_due_times&#39;</span><span class="p">,</span>
 <span class="s1">&#39;credit_income_ratio&#39;</span><span class="p">,</span>
 <span class="s1">&#39;annuity_income_ratio&#39;</span><span class="p">]</span>

<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;NAME_CONTRACT_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;CODE_GENDER&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_CAR&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_OWN_REALTY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_TYPE_SUITE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_INCOME_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_EDUCATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_FAMILY_STATUS&#39;</span><span class="p">,</span>
 <span class="s1">&#39;NAME_HOUSING_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_MOBIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMP_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_WORK_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_CONT_MOBILE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_PHONE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_EMAIL&#39;</span><span class="p">,</span>
 <span class="s1">&#39;OCCUPATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REGION_RATING_CLIENT_W_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WEEKDAY_APPR_PROCESS_START&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_LIVE_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_REGION_NOT_WORK_REGION&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_LIVE_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;REG_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;LIVE_CITY_NOT_WORK_CITY&#39;</span><span class="p">,</span>
 <span class="s1">&#39;ORGANIZATION_TYPE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FONDKAPREMONT_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;HOUSETYPE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;WALLSMATERIAL_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;EMERGENCYSTATE_MODE&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_2&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_4&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_5&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_6&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_7&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_8&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_9&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_10&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_11&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_12&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_13&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_14&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_15&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_16&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_17&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_18&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_19&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_20&#39;</span><span class="p">,</span>
 <span class="s1">&#39;FLAG_DOCUMENT_21&#39;</span><span class="p">]</span>


<span class="n">num_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="c1">#         (&#39;selector&#39;, DataFrameSelector(num_attribs)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;std_scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">])</span>

<span class="n">cat_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="c1">#         (&#39;selector&#39;, DataFrameSelector(cat_attribs)),</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">)),</span>  <span class="c1"># most_frequent</span>
        <span class="p">(</span><span class="s1">&#39;ohe&#39;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">))</span>
    <span class="p">])</span>


<span class="n">feature_eng_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;feature_eng&#39;</span><span class="p">,</span> <span class="n">FeatureEngineering</span><span class="p">())</span>
<span class="p">])</span>


<span class="n">num_cat_pipeline</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;num_pipeline&#39;</span><span class="p">,</span> <span class="n">num_pipeline</span><span class="p">,</span> <span class="n">num_attribs</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;cat_pipeline&#39;</span><span class="p">,</span> <span class="n">cat_pipeline</span><span class="p">,</span> <span class="n">cat_attribs</span><span class="p">),</span>
<span class="p">],</span> <span class="n">remainder</span> <span class="o">=</span> <span class="s1">&#39;drop&#39;</span> <span class="p">)</span>


<span class="n">data_prep_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="c1">#     (&#39;feature_eng_pipe&#39;, feature_eng_pipeline),</span>
    <span class="p">(</span><span class="s1">&#39;num_cat_pipe&#39;</span><span class="p">,</span> <span class="n">num_cat_pipeline</span><span class="p">)</span>        
<span class="p">])</span>    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;workingdir.config&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">WORKING_DIR</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
    <span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">WORKING_DIR</span><span class="p">,</span> <span class="s1">&#39;Data&#39;</span><span class="p">)</span>
    <span class="n">LOG_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">WORKING_DIR</span><span class="p">,</span> <span class="s1">&#39;runs&#39;</span><span class="p">)</span>

<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s1">&#39;.&#39;</span>
<span class="c1"># Data loading and feature engineering    </span>
<span class="n">datasets_train</span> <span class="o">=</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">phase</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">feature_eng_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">datasets_train</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">datasets_train</span><span class="p">[</span><span class="s1">&#39;application&#39;</span><span class="p">][</span><span class="s1">&#39;TARGET&#39;</span><span class="p">]</span>

<span class="n">datasets_test</span> <span class="o">=</span> <span class="n">get_datasets</span><span class="p">(</span><span class="n">phase</span> <span class="o">=</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">X_kaggle_test</span> <span class="o">=</span> <span class="n">feature_eng_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">datasets_test</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>loaded 307511 records from application_train
loaded 1716428 records from bureau
loaded 27299925 records from bureau_balance
loaded 3840312 records from credit_card_balance
loaded 13605401 records from installments_payments
loaded 1670214 records from previous_application
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Train test split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X train           shape: </span><span class="si">{X_train.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X validation      shape: </span><span class="si">{X_valid.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X test            shape: </span><span class="si">{X_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X X_kaggle_test   shape: </span><span class="si">{X_kaggle_test.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">PCA</span>


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;preparation&quot;</span><span class="p">,</span> <span class="n">data_prep_pipeline</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">PCA</span><span class="p">(</span><span class="mi">30</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">200</span><span class="p">))</span>
<span class="c1">#                         validation_fraction=0.2,</span>
<span class="c1">#                         verbose = 1, </span>
<span class="c1">#                         n_iter_no_change=5,</span>
<span class="c1">#                         tol=0.005 ))  # iterations=100,learning_rate=0.03,</span>
    <span class="p">],</span> <span class="n">memory</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>


<span class="n">Cs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">gammas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">probability</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;svm__C&#39;</span><span class="p">:</span> <span class="n">Cs</span><span class="p">,</span> <span class="s1">&#39;svm__probability&#39;</span><span class="p">:</span> <span class="n">probability</span><span class="p">}</span>

<span class="n">model_svm</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> 
                               <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span> <span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
                               <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> 
                               <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                               <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span>
                              <span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">PCA</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;preparation&quot;</span><span class="p">,</span> <span class="n">data_prep_pipeline</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">PCA</span><span class="p">(</span><span class="mi">30</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">sv</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 5 folds for each of 10 candidates, totalling 50 fits

[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-f81803e5bf114a3dadb0adb6fc18b362.pkl

Memmapping (shape=(177740,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-eb68a483b2bc46c59ffa2817ecd772d7.pkl

Pickling array (shape=(44436,), dtype=int64).

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-dc860f609aaa4921a72d27a563cded1b.pkl

Memmapping (shape=(177741,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-6220ab54673647e1b968aae5ca0cb128.pkl

Pickling array (shape=(44435,), dtype=int64).

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-a3b8e4929ff5451bb8313e9965ad4816.pkl

Memmapping (shape=(177741,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61cdf929f99f4d5eabe554070bba8296.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed: 50.4min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-06dba58f9da94495a1b5e855bd8da0f7.pkl

Memmapping (shape=(177741,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1200c3999c704df9a01133deaa85aeb6.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed: 50.4min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-97f8f8e46b124527b1c72cd99e67b4e9.pkl

Memmapping (shape=(177741,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-680ac800494741bca8137d1672ce476a.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed: 100.4min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-3fe10500eb014501bacf4a1df9fbbc81.pkl

Memmapping (shape=(177740,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-eb68a483b2bc46c59ffa2817ecd772d7.pkl

Pickling array (shape=(44436,), dtype=int64).

[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed: 100.5min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-0b3747df63924276a5778438f3f12169.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-6220ab54673647e1b968aae5ca0cb128.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed: 106.1min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-be38d921e04742b2b55eaf3a67e8adf6.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61cdf929f99f4d5eabe554070bba8296.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed: 111.6min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-e35eaef2f3c94f929fc5603339133e2c.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1200c3999c704df9a01133deaa85aeb6.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed: 117.2min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-bddd56c655104cb5a83f60721441d0de.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-680ac800494741bca8137d1672ce476a.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed: 122.8min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-52828803171141c88e922ea1a85479a2.pkl

Memmapping (shape=(177740,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-eb68a483b2bc46c59ffa2817ecd772d7.pkl

Pickling array (shape=(44436,), dtype=int64).

[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed: 128.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-837048e486f4422e8d52ccf3d3bada6b.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-6220ab54673647e1b968aae5ca0cb128.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed: 150.2min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-c4ab65df415a42d99a3e244d927d9268.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61cdf929f99f4d5eabe554070bba8296.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed: 177.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-751e17be2e5346a1b4fb72961b00d360.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1200c3999c704df9a01133deaa85aeb6.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed: 199.1min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-87576a3e8bd64c2d894d37abef9c0614.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-680ac800494741bca8137d1672ce476a.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed: 226.0min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-52bd28dd52584924a501d2b8afa0e050.pkl

Memmapping (shape=(177740,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-eb68a483b2bc46c59ffa2817ecd772d7.pkl

Pickling array (shape=(44436,), dtype=int64).

[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed: 250.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-6c3bba609237421a8a1f680aae406afe.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-6220ab54673647e1b968aae5ca0cb128.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed: 256.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-04e71c391200444783985f4da60b4aeb.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61cdf929f99f4d5eabe554070bba8296.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed: 262.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-b9d5414d8c0248a993ec918da4540025.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1200c3999c704df9a01133deaa85aeb6.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed: 268.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-69616ec3c5324ca6a114f80ae520da04.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-680ac800494741bca8137d1672ce476a.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed: 274.4min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-5627c371f5704c7aadbf522c75d06374.pkl

Memmapping (shape=(177740,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-eb68a483b2bc46c59ffa2817ecd772d7.pkl

Pickling array (shape=(44436,), dtype=int64).

[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed: 274.9min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-886563157b144c759edd10c17abbbf84.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-6220ab54673647e1b968aae5ca0cb128.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed: 280.4min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-c3131845c2274940a90257a4cb3a6784.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61cdf929f99f4d5eabe554070bba8296.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed: 347.1min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-c66726b2804641f3b7940ff2a208ca85.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1200c3999c704df9a01133deaa85aeb6.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed: 347.2min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-df57bc01d7264c359e905e6695acae9a.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-680ac800494741bca8137d1672ce476a.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed: 408.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-8181e636e0ed4196b62871c8ea1bec00.pkl

Memmapping (shape=(177740,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-eb68a483b2bc46c59ffa2817ecd772d7.pkl

Pickling array (shape=(44436,), dtype=int64).

[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed: 416.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-ae78299362b44f6585993c1475c2f04f.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-6220ab54673647e1b968aae5ca0cb128.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed: 427.1min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-dda1f81283cb4421a6adccc33eb99852.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61cdf929f99f4d5eabe554070bba8296.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed: 437.7min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-ae345eaebfb643298be58bd5b72aab5d.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1200c3999c704df9a01133deaa85aeb6.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed: 448.3min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-5de078b6e06c4d9db61035a9efdd42c2.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-680ac800494741bca8137d1672ce476a.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed: 459.0min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-7f1d82ad1006469681d75c8eab41d7d2.pkl

Memmapping (shape=(177740,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-eb68a483b2bc46c59ffa2817ecd772d7.pkl

Pickling array (shape=(44436,), dtype=int64).

[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed: 470.6min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-cea38629d8b74ed88b9857c8cae2fb20.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-6220ab54673647e1b968aae5ca0cb128.pkl

Pickling array (shape=(44435,), dtype=int64).

[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed: 476.7min

Pickling array (shape=(143,), dtype=object).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-d1a3939749de4b3f85339b5261bcaec0.pkl

Memmapping (shape=(85, 222176), dtype=float64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61e34dc5ba3f49499288e45a81b41c63.pkl

Memmapping (shape=(42, 222176), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-03a152b32a7d4bc9a7362d24e9b3c03d.pkl

Pickling array (shape=(16, 222176), dtype=object).

Pickling array (shape=(85,), dtype=object).

Pickling array (shape=(42,), dtype=object).

Pickling array (shape=(16,), dtype=object).

Pickling array (shape=(85,), dtype=int64).

Pickling array (shape=(42,), dtype=int64).

Pickling array (shape=(16,), dtype=int64).

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-edacf8f8ada94af8ae941f5da2f6e283.pkl

Memmapping (shape=(222176,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-1920a2bb50004f2c9983324a5eff6c90.pkl

Memmapping (shape=(222176,), dtype=int64) to new file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-29142faa98094a1dae4b82ae6ede5f8a.pkl

Memmapping (shape=(177741,), dtype=int64) to old file /var/folders/4v/1kvzptt551s7zjkp6j9sftf8lc6bgy/T/joblib_memmapping_folder_6168_9083572922/6168-4660478136-61cdf929f99f4d5eabe554070bba8296.pkl

Pickling array (shape=(44435,), dtype=int64).
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_svm</span><span class="p">,</span> <span class="s1">&#39;model_svm.pkl&#39;</span><span class="p">)</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-metrics">Evaluation metrics<a class="anchor-link" href="#Evaluation-metrics">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="k">import</span> <span class="n">listdir</span>

<span class="nb">dir</span> <span class="o">=</span> <span class="s1">&#39;/Users/DL/Documents/gDrive/Kaggle/trained/svm&#39;</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">fnames</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">fn</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">fn</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)])</span>
<span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">fnames</span> <span class="p">:</span> 
    <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">dir</span><span class="p">,</span> <span class="n">fname</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">printIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">),</span> <span class="n">append</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[6]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train AUC</th>
      <th>Valid AUC</th>
      <th>Test  AUC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline_14_features</td>
      <td>0.9198</td>
      <td>0.9192</td>
      <td>0.9159</td>
      <td>0.7359</td>
      <td>0.7361</td>
      <td>0.7362</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SVM_SVC</td>
      <td>0.8383</td>
      <td>0.8275</td>
      <td>0.8283</td>
      <td>0.6383</td>
      <td>0.6373</td>
      <td>0.6354</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logIt</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">experiemnt</span> <span class="o">=</span> <span class="s1">&#39;Randomforest&#39;</span><span class="p">,</span> <span class="n">test_description</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>All models have been successfully recorded! 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Discussion">Discussion<a class="anchor-link" href="#Discussion">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this last phase, the support vector machine algorithm was used for classification problem as planned. We trained a Sklearn SVC and used RandomizedSearchCV for hyperparameter optimization. Because, the dataset has sample size (300,000) far exceeding the feature dimension (&lt; 300), a linear kernel was chosen for training. The SVM as a non-parametric model takes long time to train. In practice, it took us &gt; 48 hours to train without yielding satisfactory results with the best performance score (AUC score) below 0.7. Theoretically, the classification performance could be improved by using a SVC with other non-linear kernels such as Polynomial, Gaussian RBF, etc. The downside, however, is that a SVC with non-linear kernels is generally not scalable to large dataset, because it takes O(N^2) ~ O(N^3) to train.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Kaggle-submission-via-the-command-line-API">Kaggle submission via the command line API<a class="anchor-link" href="#Kaggle-submission-via-the-command-line-API">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[167]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span> kaggle competitions submit -c home-credit-default-risk -f submission.csv -m <span class="s2">&quot;baseline submission&quot;</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Successfully submitted to Home Credit Default Risk
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
  0%|          | 0.00/1.31M [00:00&lt;?, ?B/s]
  1%|          | 8.00k/1.31M [00:00&lt;00:34, 39.6kB/s]
 13%|#3        | 176k/1.31M [00:00&lt;00:21, 56.0kB/s] 
 28%|##8       | 376k/1.31M [00:00&lt;00:12, 79.0kB/s]
 52%|#####2    | 704k/1.31M [00:00&lt;00:05, 112kB/s] 
 64%|######4   | 864k/1.31M [00:01&lt;00:03, 135kB/s]
 73%|#######3  | 984k/1.31M [00:01&lt;00:02, 141kB/s]
 93%|#########3| 1.22M/1.31M [00:02&lt;00:00, 197kB/s]
100%|##########| 1.31M/1.31M [00:04&lt;00:00, 319kB/s]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="report-submission">report submission<a class="anchor-link" href="#report-submission">&#182;</a></h2><p>Click on this <a href="https://www.kaggle.com/c/home-credit-default-risk/submissions?sortBy=date&amp;group=all&amp;page=1">link</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="attachment:image.png" alt="image.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">References<a class="anchor-link" href="#References">&#182;</a></h1><p>Some of the material in this notebook has been adopted from <a href="https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction/notebook">here</a></p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
